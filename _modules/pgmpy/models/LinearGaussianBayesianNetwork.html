


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../_static/logo_favi.ico">
    
    
      
        <title>pgmpy.models.LinearGaussianBayesianNetwork - pgmpy</title>
      
    
    
      
        
      
      


    
    
      
    
    
      
        
        
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
        <link rel="stylesheet" type="text/css" href="../../../_static/sphinx_immaterial_theme.acf80fe7f4d9ef9e2.min.css?v=9e56d0d2" />
        <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
        <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  
  <!-- SEO meta tags -->
  <meta name="description" content="pgmpy: A Python library for causal inference and probabilistic inference using Directed Acyclic Graphs (DAGs) and Bayesian Networks.">
  <meta name="keywords" content="pgmpy, Bayesian Networks, causal inference, probabilistic graphical models, structure learning, parameter estimation, Python">
  <meta property="og:type" content="website">
  <meta property="og:site_name" content="pgmpy">
  <meta property="og:title" content="pgmpy.models.LinearGaussianBayesianNetwork">
  <meta property="og:description" content="pgmpy: A Python library for causal inference and probabilistic inference using Directed Acyclic Graphs (DAGs) and Bayesian Networks.">
  <meta property="og:url" content="https://pgmpy.org/_modules/pgmpy/models/LinearGaussianBayesianNetwork.html">
  <meta property="og:image" content="https://pgmpy.org/_static/logo.png">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="pgmpy.models.LinearGaussianBayesianNetwork">
  <meta name="twitter:description" content="pgmpy: A Python library for causal inference and probabilistic inference using Directed Acyclic Graphs (DAGs) and Bayesian Networks.">
  <meta name="twitter:image" content="https://pgmpy.org/_static/logo.png">
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-HCFR07M31W"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-HCFR07M31W');
  </script>
  <!-- EthicalAds -->
  <script async src="https://media.ethicalads.io/media/client/ethicalads.min.js"></script>
  <!-- Header social links styling -->
  <style>
    .md-header__social {
      display: flex;
      align-items: center;
      gap: 0.1rem;
      margin-left: 0.4rem;
    }
    .md-header__social a {
      display: inline-flex;
      align-items: center;
      justify-content: center;
      padding: 0.4rem;
      color: var(--md-default-fg-color--light);
      opacity: 0.7;
      transition: opacity 0.25s;
    }
    .md-header__social a:hover {
      opacity: 1;
    }
    .md-header__social svg {
      width: 1.2rem;
      height: 1.2rem;
      fill: currentColor;
    }
    [data-md-color-scheme="slate"] .md-header__social a {
      color: var(--md-default-fg-color--light);
    }
    /* Center content when right sidebar (toc) is hidden */
    .md-sidebar--secondary[hidden] ~ .md-content {
      margin-left: auto;
      margin-right: auto;
    }
  </style>

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../index.html" title="pgmpy" class="md-header__button md-logo" aria-label="pgmpy" data-md-component="logo">
      <img src="../../../_static/logo.png" alt="logo">
    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            pgmpy
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              pgmpy.models.LinearGaussianBayesianNetwork
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/pgmpy/pgmpy" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    pgmpy/pgmpy
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../started/base.html" class="md-tabs__link">
        
  
    
  
  <span title="/started/base.rst (reference label)"><span>Getting Started</span></span>

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../documentation.html" class="md-tabs__link">
        
  
    
  
  <span title="/documentation.rst (reference label)"><span>Documentation</span></span>

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../examples.html" class="md-tabs__link">
        
  
    
  
  <span title="/examples.rst (reference label)"><span>Examples</span></span>

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../api.html" class="md-tabs__link">
        
  
    
  
  <span title="/api.rst (reference label)"><span>API Reference</span></span>

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../development.html" class="md-tabs__link">
        
  
    
  
  <span title="/development.rst (reference label)"><span>Development</span></span>

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../index.html" title="pgmpy" class="md-nav__button md-logo" aria-label="pgmpy" data-md-component="logo">
      <img src="../../../_static/logo.png" alt="logo">
    </a>
    pgmpy
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/pgmpy/pgmpy" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    pgmpy/pgmpy
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../started/base.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/started/base.rst (reference label)"><span>Getting Started</span></span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../documentation.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/documentation.rst (reference label)"><span>Documentation</span></span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/examples.rst (reference label)"><span>Examples</span></span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../api.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/api.rst (reference label)"><span>API Reference</span></span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../development.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/development.rst (reference label)"><span>Development</span></span>
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary">
  
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset" role="main">
                
                
  
                  


<h1>Source code for pgmpy.models.LinearGaussianBayesianNetwork</h1><div class="highlight"><pre>
<span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Hashable</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Set</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">networkx</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nx</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">multivariate_normal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">pgmpy.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">DAG</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pgmpy.factors.continuous</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearGaussianCPD</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pgmpy.global_vars</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LinearGaussianBayesianNetwork</span><span class="p">(</span><span class="n">DAG</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class to represent Linear Gaussian Bayesian Networks (LGBN).</span>

<span class="sd">    A LGBN is a graphical model that represents a set of continuous random variables and their conditional dependencies</span>
<span class="sd">    via a directed acyclic graph (DAG). In a LGBN, each variable is assumed to be conditionally normally distributed,</span>
<span class="sd">    and the conditional probability distribution (CPD) of each variable given its parents is modeled as a linear</span>
<span class="sd">    function of the parents&#39; values plus Gaussian noise. This is equivalent to assumptions of a Linear Structural</span>
<span class="sd">    Equation Model (SEM) with Gaussian noise.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    ebunch : input graph, optional</span>
<span class="sd">        Data to initialize graph. If None (default) an empty</span>
<span class="sd">        graph is created.  The data can be any format that is supported</span>
<span class="sd">        by the to_networkx_graph() function, currently including edge list,</span>
<span class="sd">        dict of dicts, dict of lists, NetworkX graph, 2D NumPy array, SciPy</span>
<span class="sd">        sparse matrix, or PyGraphviz graph.</span>

<span class="sd">    latents : set of nodes, default=None</span>
<span class="sd">        A set of latent variables in the graph. These are not observed</span>
<span class="sd">        variables but are used to represent unobserved confounding or</span>
<span class="sd">        other latent structures.</span>

<span class="sd">    exposures : set, default=set()</span>
<span class="sd">        Set of exposure variables in the graph. These are the variables</span>
<span class="sd">        that represent the treatment or intervention being studied in a</span>
<span class="sd">        causal analysis. Default is an empty set.</span>

<span class="sd">    outcomes : set, optional (default: None)</span>
<span class="sd">        Set of outcome variables in the graph. These are the variables</span>
<span class="sd">        that represent the response or dependent variables being studied</span>
<span class="sd">        in a causal analysis. If None, an empty set is used.</span>

<span class="sd">    roles : dict, optional (default: None)</span>
<span class="sd">        A dictionary mapping roles to node names.</span>
<span class="sd">        The keys are roles, and the values are role names (strings or iterables of str).</span>
<span class="sd">        If provided, this will automatically assign roles to the nodes in the graph.</span>
<span class="sd">        Passing a key-value pair via ``roles`` is equivalent to calling</span>
<span class="sd">        ``with_role(role, variables)`` for each key-value pair in the dictionary.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    # Defining a Linear Gaussian Bayesian Network.</span>

<span class="sd">    &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.factors.continuous import LinearGaussianCPD</span>
<span class="sd">    &gt;&gt;&gt; model = LinearGaussianBayesianNetwork([(&quot;x1&quot;, &quot;x2&quot;), (&quot;x2&quot;, &quot;x3&quot;)])</span>
<span class="sd">    &gt;&gt;&gt; cpd1 = LinearGaussianCPD(&quot;x1&quot;, [1], 4)</span>
<span class="sd">    &gt;&gt;&gt; cpd2 = LinearGaussianCPD(&quot;x2&quot;, [-5, 0.5], 4, [&quot;x1&quot;])</span>
<span class="sd">    &gt;&gt;&gt; cpd3 = LinearGaussianCPD(&quot;x3&quot;, [4, -1], 3, [&quot;x2&quot;])</span>
<span class="sd">    &gt;&gt;&gt; model.add_cpds(cpd1, cpd2, cpd3)</span>
<span class="sd">    &gt;&gt;&gt; for cpd in model.cpds:</span>
<span class="sd">    ...     print(cpd)</span>
<span class="sd">    ...</span>
<span class="sd">    P(x1) = N(1; 4)</span>
<span class="sd">    P(x2 | x1) = N(-5 + 0.5*x1; 4)</span>
<span class="sd">    P(x3 | x2) = N(4 + -1*x2; 3)</span>

<span class="sd">    # Simulating data from the model.</span>

<span class="sd">    &gt;&gt;&gt; df = model.simulate(n_samples=100, seed=42)</span>
<span class="sd">    &gt;&gt;&gt; print(df.columns)</span>
<span class="sd">    Index([&#39;x1&#39;, &#39;x2&#39;, &#39;x3&#39;], dtype=&#39;object&#39;)</span>

<span class="sd">    # Fitting the model to the simulated data.</span>

<span class="sd">    &gt;&gt;&gt; model.fit(df)</span>

<span class="sd">    # Predicting missing variables.</span>

<span class="sd">    &gt;&gt;&gt; df_missing = df.drop(columns=[&quot;x3&quot;])</span>
<span class="sd">    &gt;&gt;&gt; missing_vars, mu_cond, cov_cond = model.predict(df_missing)</span>
<span class="sd">    &gt;&gt;&gt; print(missing_vars)</span>
<span class="sd">    [&#39;x3&#39;]</span>
<span class="sd">    &gt;&gt;&gt; print(mu_cond)</span>
<span class="sd">    [[ 0.13440001]</span>
<span class="sd">     [-0.39458728]</span>
<span class="sd">     [ 0.60606023]</span>
<span class="sd">     [ 0.0732233 ]</span>
<span class="sd">     [-0.07241039]</span>
<span class="sd">     [ 0.43420811]</span>
<span class="sd">     [ 0.23197845]</span>
<span class="sd">     [ 0.35382335]</span>
<span class="sd">     [ 0.11859155]</span>
<span class="sd">     [ 0.18397848]]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">ebunch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Hashable</span><span class="p">,</span> <span class="n">Hashable</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">latents</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Set</span><span class="p">[</span><span class="n">Hashable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">exposures</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Set</span><span class="p">[</span><span class="n">Hashable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">outcomes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Set</span><span class="p">[</span><span class="n">Hashable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">roles</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearGaussianBayesianNetwork</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">ebunch</span><span class="o">=</span><span class="n">ebunch</span><span class="p">,</span>
            <span class="n">latents</span><span class="o">=</span><span class="n">latents</span><span class="p">,</span>
            <span class="n">exposures</span><span class="o">=</span><span class="n">exposures</span><span class="p">,</span>
            <span class="n">outcomes</span><span class="o">=</span><span class="n">outcomes</span><span class="p">,</span>
            <span class="n">roles</span><span class="o">=</span><span class="n">roles</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span> <span class="o">=</span> <span class="p">[]</span>

<div class="viewcode-block" id="LinearGaussianBayesianNetwork.add_cpds">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.add_cpds">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">add_cpds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">cpds</span><span class="p">:</span> <span class="n">LinearGaussianCPD</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add Linear Gaussian CPDs (Conditional Probability Distributions)</span>
<span class="sd">        to the Bayesian Network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        cpds : instances of LinearGaussianCPD</span>
<span class="sd">            LinearGaussianCPDs which will be associated with the model.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.continuous import LinearGaussianCPD</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork([(&quot;x1&quot;, &quot;x2&quot;), (&quot;x2&quot;, &quot;x3&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; cpd1 = LinearGaussianCPD(&quot;x1&quot;, [1], 4)</span>
<span class="sd">        &gt;&gt;&gt; cpd2 = LinearGaussianCPD(&quot;x2&quot;, [-5, 0.5], 4, [&quot;x1&quot;])</span>
<span class="sd">        &gt;&gt;&gt; cpd3 = LinearGaussianCPD(&quot;x3&quot;, [4, -1], 3, [&quot;x2&quot;])</span>
<span class="sd">        &gt;&gt;&gt; model.add_cpds(cpd1, cpd2, cpd3)</span>
<span class="sd">        &gt;&gt;&gt; for cpd in model.cpds:</span>
<span class="sd">        ...     print(cpd)</span>
<span class="sd">        ...</span>
<span class="sd">        P(x1) = N(1; 4)</span>
<span class="sd">        P(x2 | x1) = N(-5 + 0.5*x1; 4)</span>
<span class="sd">        P(x3 | x2) = N(4 + -1*x2; 3)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="n">cpds</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cpd</span><span class="p">,</span> <span class="n">LinearGaussianCPD</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only LinearGaussianCPD can be added.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">cpd</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">cpd</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;CPD defined on variable not in the model&quot;</span><span class="p">,</span> <span class="n">cpd</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">prev_cpd_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cpds</span><span class="p">)):</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span><span class="p">[</span><span class="n">prev_cpd_index</span><span class="p">]</span><span class="o">.</span><span class="n">variable</span> <span class="o">==</span> <span class="n">cpd</span><span class="o">.</span><span class="n">variable</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Replacing existing CPD for </span><span class="si">{</span><span class="n">cpd</span><span class="o">.</span><span class="n">variable</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span><span class="p">[</span><span class="n">prev_cpd_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">cpd</span>
                    <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cpd</span><span class="p">)</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.get_cpds">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.get_cpds">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_cpds</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Hashable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">LinearGaussianCPD</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">LinearGaussianCPD</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the CPD of the specified node. If node is not specified, returns all CPDs</span>
<span class="sd">        that have been added so far to the graph.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        node: any hashable python object (optional)</span>
<span class="sd">            The node whose CPD we want. If node not specified returns all the</span>
<span class="sd">            CPDs added to the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list[LinearGaussianCPD] or LinearGaussianCPD</span>
<span class="sd">            A CPD or list of Linear Gaussian CPDs.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.continuous import LinearGaussianCPD</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork([(&quot;x1&quot;, &quot;x2&quot;), (&quot;x2&quot;, &quot;x3&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; cpd1 = LinearGaussianCPD(&quot;x1&quot;, [1], 4)</span>
<span class="sd">        &gt;&gt;&gt; cpd2 = LinearGaussianCPD(&quot;x2&quot;, [-5, 0.5], 4, [&quot;x1&quot;])</span>
<span class="sd">        &gt;&gt;&gt; cpd3 = LinearGaussianCPD(&quot;x3&quot;, [4, -1], 3, [&quot;x2&quot;])</span>
<span class="sd">        &gt;&gt;&gt; model.add_cpds(cpd1, cpd2, cpd3)</span>
<span class="sd">        &gt;&gt;&gt; model.get_cpds()</span>
<span class="sd">        [P(x1) = N(1; 4), P(x2 | x1) = N(-5 + 0.5*x1; 4), P(x3 | x2) = N(4 + -1*x2; 3)]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">node</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">node</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Node not present in the Directed Graph&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">cpd</span><span class="o">.</span><span class="n">variable</span> <span class="o">==</span> <span class="n">node</span><span class="p">:</span>
                        <span class="k">return</span> <span class="n">cpd</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.remove_cpds">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.remove_cpds">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">remove_cpds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">cpds</span><span class="p">:</span> <span class="n">LinearGaussianCPD</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Removes the CPDs provided in the arguments.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        *cpds: LinearGaussianCPD</span>
<span class="sd">            LinearGaussianCPD objects (or their variable names) to remove.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.continuous import LinearGaussianCPD</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork([(&quot;x1&quot;, &quot;x2&quot;), (&quot;x2&quot;, &quot;x3&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; cpd1 = LinearGaussianCPD(&quot;x1&quot;, [1], 4)</span>
<span class="sd">        &gt;&gt;&gt; cpd2 = LinearGaussianCPD(&quot;x2&quot;, [-5, 0.5], 4, [&quot;x1&quot;])</span>
<span class="sd">        &gt;&gt;&gt; cpd3 = LinearGaussianCPD(&quot;x3&quot;, [4, -1], 3, [&quot;x2&quot;])</span>
<span class="sd">        &gt;&gt;&gt; model.add_cpds(cpd1, cpd2, cpd3)</span>
<span class="sd">        &gt;&gt;&gt; for cpd in model.get_cpds():</span>
<span class="sd">        ...     print(cpd)</span>
<span class="sd">        ...</span>
<span class="sd">        P(x1) = N(1; 4)</span>
<span class="sd">        P(x2 | x1) = N(-5 + 0.5*x1; 4)</span>
<span class="sd">        P(x3 | x2) = N(4 + -1*x2; 3)</span>

<span class="sd">        &gt;&gt;&gt; model.remove_cpds(cpd2, cpd3)</span>
<span class="sd">        &gt;&gt;&gt; for cpd in model.get_cpds():</span>
<span class="sd">        ...     print(cpd)</span>
<span class="sd">        ...</span>
<span class="sd">        P(x1) = N(1; 4)</span>


<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="n">cpds</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cpd</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
                <span class="n">cpd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">(</span><span class="n">cpd</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">cpd</span><span class="p">)</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.get_random_cpds">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.get_random_cpds">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_random_cpds</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">loc</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">LinearGaussianCPD</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates random Linear Gaussian CPDs for the model. The coefficients</span>
<span class="sd">        are sampled from a normal distribution with mean `loc` and standard</span>
<span class="sd">        deviation `scale`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        loc: float</span>
<span class="sd">            Mean of the normal from which coefficients are sampled.</span>
<span class="sd">        scale: float</span>
<span class="sd">            Std dev of the normal from which coefficients are sampled.</span>
<span class="sd">        inplace: bool (default: False)</span>
<span class="sd">            If True, adds the generated LinearGaussianCPDs to the model;</span>
<span class="sd">            otherwise returns them.</span>
<span class="sd">        seed: int (optional)</span>
<span class="sd">            Seed for the random number generator.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork([(&quot;x1&quot;, &quot;x2&quot;), (&quot;x2&quot;, &quot;x3&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; model.get_random_cpds(loc=0, scale=1, seed=42)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># We want a different seed for each CPD; increment an integer seed in the loop.</span>
        <span class="c1"># We want to provide a different seed for each cpd, therefore we force it to be integer and increment in a loop.</span>
        <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span> <span class="k">if</span> <span class="n">seed</span> <span class="k">else</span> <span class="mi">42</span>

        <span class="n">cpds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">()):</span>
            <span class="n">parents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_parents</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
            <span class="n">cpds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">LinearGaussianCPD</span><span class="o">.</span><span class="n">get_random</span><span class="p">(</span>
                    <span class="n">variable</span><span class="o">=</span><span class="n">var</span><span class="p">,</span>
                    <span class="n">evidence</span><span class="o">=</span><span class="n">parents</span><span class="p">,</span>
                    <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span>
                    <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span>
                    <span class="n">seed</span><span class="o">=</span><span class="p">(</span><span class="n">seed</span> <span class="o">+</span> <span class="n">i</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_cpds</span><span class="p">(</span><span class="o">*</span><span class="n">cpds</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">cpds</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.to_joint_gaussian">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.to_joint_gaussian">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to_joint_gaussian</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Represents the Linear Gaussian Bayesian Network as a joint</span>
<span class="sd">        Linear Gaussian Bayesian Networks can be represented using a joint</span>
<span class="sd">        Gaussian distribution over all the variables. This method gives</span>
<span class="sd">        the mean and covariance of this equivalent joint gaussian distribution.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        mean, cov: np.ndarray, np.ndarray</span>
<span class="sd">            Mean vector and covariance matrix of the joint Gaussian.</span>
<span class="sd">            The mean and the covariance matrix of the joint gaussian distribution.</span>
<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; mean, cov = model.to_joint_gaussian()</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.continuous import LinearGaussianCPD</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork([(&quot;x1&quot;, &quot;x2&quot;), (&quot;x2&quot;, &quot;x3&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; cpd1 = LinearGaussianCPD(&quot;x1&quot;, [1], 4)</span>
<span class="sd">        &gt;&gt;&gt; cpd2 = LinearGaussianCPD(&quot;x2&quot;, [-5, 0.5], 4, [&quot;x1&quot;])</span>
<span class="sd">        &gt;&gt;&gt; cpd3 = LinearGaussianCPD(&quot;x3&quot;, [4, -1], 3, [&quot;x2&quot;])</span>
<span class="sd">        &gt;&gt;&gt; model.add_cpds(cpd1, cpd2, cpd3)</span>
<span class="sd">        &gt;&gt;&gt; mean</span>
<span class="sd">        array([ 1. , -4.5,  8.5])</span>
<span class="sd">        &gt;&gt;&gt; cov</span>
<span class="sd">        array([[ 16.,   8.,  -8.],</span>
<span class="sd">               [  8.,  20., -20.],</span>
<span class="sd">               [ -8., -20.,  29.]])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">variables</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">topological_sort</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="n">var_to_index</span> <span class="o">=</span> <span class="p">{</span><span class="n">var</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">variables</span><span class="p">)}</span>
        <span class="n">n_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>

        <span class="c1"># Step 1: Compute the mean for each variable.</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">:</span>
            <span class="n">cpd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">(</span><span class="n">node</span><span class="o">=</span><span class="n">var</span><span class="p">)</span>
            <span class="n">mean</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">cpd</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">mean</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">cpd</span><span class="o">.</span><span class="n">evidence</span><span class="p">]))</span>
            <span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mean</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">])</span>

        <span class="c1"># Step 2: Populate the adjacency matrix, and variance matrix</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">))</span>
        <span class="n">omega</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">:</span>
            <span class="n">cpd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">(</span><span class="n">node</span><span class="o">=</span><span class="n">var</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">evidence_var</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cpd</span><span class="o">.</span><span class="n">evidence</span><span class="p">):</span>
                <span class="n">B</span><span class="p">[</span><span class="n">var_to_index</span><span class="p">[</span><span class="n">evidence_var</span><span class="p">],</span> <span class="n">var_to_index</span><span class="p">[</span><span class="n">var</span><span class="p">]]</span> <span class="o">=</span> <span class="n">cpd</span><span class="o">.</span><span class="n">beta</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">omega</span><span class="p">[</span><span class="n">var_to_index</span><span class="p">[</span><span class="n">var</span><span class="p">],</span> <span class="n">var_to_index</span><span class="p">[</span><span class="n">var</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span><span class="n">cpd</span><span class="o">.</span><span class="n">std</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>

        <span class="c1"># Step 3: Compute the implied covariance matrix</span>
        <span class="n">identity_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">)</span>
        <span class="n">inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">((</span><span class="n">identity_matrix</span> <span class="o">-</span> <span class="n">B</span><span class="p">))</span>
        <span class="n">implied_cov</span> <span class="o">=</span> <span class="n">inv</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">omega</span> <span class="o">@</span> <span class="n">inv</span>

        <span class="c1"># Round because numerical errors can lead to non-symmetric cov matrix.</span>
        <span class="k">return</span> <span class="n">mean</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">decimals</span><span class="o">=</span><span class="mi">8</span><span class="p">),</span> <span class="n">implied_cov</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">decimals</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.log_likelihood">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.log_likelihood">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the log-likelihood of the given dataset under the current</span>
<span class="sd">        Linear Gaussian Bayesian Network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : pandas.DataFrame</span>
<span class="sd">            Observations for all variables (columns must match model variables).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            Total log-likelihood of the data under the model.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.continuous import LinearGaussianCPD</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork([(&quot;x1&quot;, &quot;x2&quot;), (&quot;x2&quot;, &quot;x3&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; cpd1 = LinearGaussianCPD(&quot;x1&quot;, [1], 4)</span>
<span class="sd">        &gt;&gt;&gt; cpd2 = LinearGaussianCPD(&quot;x2&quot;, [-5, 0.5], 4, [&quot;x1&quot;])</span>
<span class="sd">        &gt;&gt;&gt; cpd3 = LinearGaussianCPD(&quot;x3&quot;, [4, -1], 3, [&quot;x2&quot;])</span>
<span class="sd">        &gt;&gt;&gt; model.add_cpds(cpd1, cpd2, cpd3)</span>
<span class="sd">        &gt;&gt;&gt; df = pd.DataFrame(</span>
<span class="sd">        ...     np.random.normal(0, 1, size=(100, 3)), columns=[&quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; model.log_likelihood(df)</span>
<span class="sd">        -1128.66</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ordering</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">topological_sort</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="n">missing</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">ordering</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">missing</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Missing required columns in DataFrame: </span><span class="si">{</span><span class="n">missing</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">ordering</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_joint_gaussian</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">multivariate_normal</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov</span><span class="p">))</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.copy">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.copy">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a copy of the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Model&#39;s copy: pgmpy.models.LinearGaussianBayesianNetwork</span>
<span class="sd">            Copy of the model on which the method was called.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.continuous import LinearGaussianCPD</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork([(&quot;A&quot;, &quot;B&quot;), (&quot;B&quot;, &quot;C&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; cpd_a = LinearGaussianCPD(variable=&quot;A&quot;, beta=[1], std=4)</span>
<span class="sd">        &gt;&gt;&gt; cpd_b = LinearGaussianCPD(</span>
<span class="sd">        ...     variable=&quot;B&quot;, beta=[-5, 0.5], std=4, evidence=[&quot;A&quot;]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; cpd_c = LinearGaussianCPD(</span>
<span class="sd">        ...     variable=&quot;C&quot;, beta=[4, -1], std=3, evidence=[&quot;x2&quot;]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; model.add_cpds(cpd_a, cpd_b, cpd_c)</span>
<span class="sd">        &gt;&gt;&gt; copy_model = model.copy()</span>
<span class="sd">        &gt;&gt;&gt; copy_model.nodes()</span>
<span class="sd">        NodeView((&#39;A&#39;, &#39;B&#39;, &#39;C&#39;))</span>
<span class="sd">        &gt;&gt;&gt; copy_model.edges()</span>
<span class="sd">        OutEdgeView([(&#39;A&#39;, &#39;B&#39;), (&#39;B&#39;, &#39;C&#39;)])</span>
<span class="sd">        &gt;&gt;&gt; len(copy_model.get_cpds())</span>
<span class="sd">        3</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model_copy</span> <span class="o">=</span> <span class="n">LinearGaussianBayesianNetwork</span><span class="p">()</span>
        <span class="n">model_copy</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
        <span class="n">model_copy</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="p">())</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span><span class="p">:</span>
            <span class="n">model_copy</span><span class="o">.</span><span class="n">add_cpds</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">cpd</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">model_copy</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.simulate">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.simulate">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">simulate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">do</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">evidence</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">virtual_intervention</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">LinearGaussianCPD</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">include_latents</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Simulates data from the model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_samples: int</span>
<span class="sd">            Number of samples to draw.</span>
<span class="sd">            The number of samples to draw from the model.</span>

<span class="sd">        do: dict (default: None)</span>
<span class="sd">            The interventions to apply to the model. dict should be of the form</span>
<span class="sd">            {variable_name: value}</span>

<span class="sd">        evidence: dict (default: None)</span>
<span class="sd">            Observed evidence to apply to the model. dict should be of the form</span>
<span class="sd">            {variable_name: value}</span>

<span class="sd">        virtual_intervention: list</span>
<span class="sd">            Also known as soft intervention. `virtual_intervention` should be a list</span>
<span class="sd">            of `pgmpy.factors.discrete.LinearGaussianCPD` objects specifying the virtual/soft</span>
<span class="sd">            intervention probabilities.</span>

<span class="sd">        include_latents: boolean</span>
<span class="sd">            Whether to include the latent variable values in the generated samples.</span>

<span class="sd">        seed: int (default: None)</span>
<span class="sd">            Seed for the random number generator.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        pandas.DataFrame</span>
<span class="sd">        pandas.DataFrame: generated samples</span>
<span class="sd">            A pandas data frame with the generated samples.</span>
<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; model.simulate(n_samples=3, seed=42)</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.continuous import LinearGaussianCPD</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork([(&quot;x1&quot;, &quot;x2&quot;), (&quot;x2&quot;, &quot;x3&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; cpd1 = LinearGaussianCPD(&quot;x1&quot;, [1], 4)</span>
<span class="sd">        &gt;&gt;&gt; cpd2 = LinearGaussianCPD(&quot;x2&quot;, [-5, 0.5], 4, [&quot;x1&quot;])</span>
<span class="sd">        &gt;&gt;&gt; cpd3 = LinearGaussianCPD(&quot;x3&quot;, [4, -1], 3, [&quot;x2&quot;])</span>
<span class="sd">        &gt;&gt;&gt; model.add_cpds(cpd1, cpd2, cpd3)</span>

<span class="sd">        Simple forward sampling</span>
<span class="sd">        &gt;&gt;&gt; model.simulate(n_samples=3, seed=42, do={&quot;x2&quot;: 0.0})</span>

<span class="sd">        Sampling with intervention (do)</span>
<span class="sd">        &gt;&gt;&gt; model.simulate(n_samples=3, seed=42, evidence={&quot;x1&quot;: 2.0})</span>

<span class="sd">        Sampling with evidence</span>
<span class="sd">        &gt;&gt;&gt; model.simulate(n_samples=3, seed=42, do={&quot;x2&quot;: 1.0}, evidence={&quot;x1&quot;: 0.0})</span>

<span class="sd">        Sampling with both intervention and evidence</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Step 1: Check if all arguments are specified and valid</span>
        <span class="n">evidence</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">evidence</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">evidence</span>

        <span class="n">do</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">do</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">do</span>

        <span class="n">virtual_intervention</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">[]</span> <span class="k">if</span> <span class="n">virtual_intervention</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">virtual_intervention</span>
        <span class="p">)</span>

        <span class="n">do_nodes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">do</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">evidence_nodes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">evidence</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

        <span class="n">invalid_nodes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">do_nodes</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="n">do_nodes</span><span class="p">)</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The following do-nodes are not present in the model: </span><span class="si">{</span><span class="n">invalid_nodes</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;do argument contains: </span><span class="si">{</span><span class="n">do_nodes</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">invalid_nodes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">evidence_nodes</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="n">evidence_nodes</span><span class="p">)</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The following evidence-nodes are not present in the model: </span><span class="si">{</span><span class="n">invalid_nodes</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;evidence argument contains: </span><span class="si">{</span><span class="n">evidence_nodes</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">check_model</span><span class="p">()</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">common_vars</span> <span class="o">:=</span> <span class="nb">set</span><span class="p">(</span><span class="n">do</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">&amp;</span> <span class="nb">set</span><span class="p">(</span><span class="n">evidence</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Variable(s) can&#39;t be in both do and evidence: </span><span class="si">{</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">common_vars</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">virtual_intervention</span> <span class="o">!=</span> <span class="p">[]:</span>
            <span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="n">virtual_intervention</span><span class="p">:</span>
                <span class="n">var</span> <span class="o">=</span> <span class="n">cpd</span><span class="o">.</span><span class="n">variable</span>
                <span class="k">if</span> <span class="n">var</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">():</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Virtual intervention provided for variable which is not in the model: </span><span class="si">{</span><span class="n">var</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;The following nodes are present in the model: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

        <span class="c1"># Step 2: If do is specified, modify the network structure.</span>
        <span class="k">if</span> <span class="n">do</span> <span class="o">!=</span> <span class="p">{}:</span>
            <span class="k">for</span> <span class="n">var</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">do</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="c1"># Step 2.1: Remove incoming edges to the intervened</span>
                <span class="c1">#  node as well as remove the CPD&#39;s of the intervened nodes.</span>
                <span class="k">for</span> <span class="n">parent</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_parents</span><span class="p">(</span><span class="n">var</span><span class="p">)):</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">remove_edge</span><span class="p">(</span><span class="n">parent</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>

                <span class="n">model</span><span class="o">.</span><span class="n">remove_cpds</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">(</span><span class="n">var</span><span class="p">))</span>

                <span class="c1"># Step 2.2 : For each child of an intervened node, change its CPD to remove</span>
                <span class="c1">#  the parent (intervened node) from the evidence and update its intercept accordingly</span>
                <span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">get_children</span><span class="p">(</span><span class="n">var</span><span class="p">):</span>
                    <span class="n">child_cpd</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">(</span><span class="n">child</span><span class="p">)</span>

                    <span class="n">new_evidence</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">child_cpd</span><span class="o">.</span><span class="n">evidence</span><span class="p">)</span>
                    <span class="n">new_beta</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">child_cpd</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>

                    <span class="n">parent_idx</span> <span class="o">=</span> <span class="n">child_cpd</span><span class="o">.</span><span class="n">evidence</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
                    <span class="n">new_beta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">new_beta</span><span class="p">[</span><span class="n">parent_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">val</span>

                    <span class="k">del</span> <span class="n">new_evidence</span><span class="p">[</span><span class="n">parent_idx</span><span class="p">]</span>
                    <span class="k">del</span> <span class="n">new_beta</span><span class="p">[</span><span class="n">parent_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>

                    <span class="n">new_cpd</span> <span class="o">=</span> <span class="n">LinearGaussianCPD</span><span class="p">(</span>
                        <span class="n">variable</span><span class="o">=</span><span class="n">child_cpd</span><span class="o">.</span><span class="n">variable</span><span class="p">,</span>
                        <span class="n">beta</span><span class="o">=</span><span class="n">new_beta</span><span class="p">,</span>
                        <span class="n">std</span><span class="o">=</span><span class="n">child_cpd</span><span class="o">.</span><span class="n">std</span><span class="p">,</span>
                        <span class="n">evidence</span><span class="o">=</span><span class="n">new_evidence</span><span class="p">,</span>
                    <span class="p">)</span>

                    <span class="n">model</span><span class="o">.</span><span class="n">remove_cpds</span><span class="p">(</span><span class="n">child_cpd</span><span class="p">)</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">add_cpds</span><span class="p">(</span><span class="n">new_cpd</span><span class="p">)</span>

                <span class="n">model</span><span class="o">.</span><span class="n">remove_node</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>

        <span class="c1"># Step 3: If virtual_interventions are specified, change the CPD&#39;s of intervened variables</span>
        <span class="c1"># to specified ones and remove the incoming nodes</span>
        <span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="n">virtual_intervention</span><span class="p">:</span>
            <span class="n">var</span> <span class="o">=</span> <span class="n">cpd</span><span class="o">.</span><span class="n">variable</span>
            <span class="n">old_cpd</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">remove_cpds</span><span class="p">(</span><span class="n">old_cpd</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add_cpds</span><span class="p">(</span><span class="n">cpd</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">parent</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_parents</span><span class="p">(</span><span class="n">var</span><span class="p">)):</span>
                <span class="n">model</span><span class="o">.</span><span class="n">remove_edge</span><span class="p">(</span><span class="n">parent</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>

        <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to_joint_gaussian</span><span class="p">()</span>
        <span class="n">variables</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">topological_sort</span><span class="p">(</span><span class="n">model</span><span class="p">))</span>

        <span class="c1"># Step 4: Sample according to evidence</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">evidence</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="n">rng</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_samples</span><span class="p">),</span>
                <span class="n">columns</span><span class="o">=</span><span class="n">variables</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">df_evidence</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">evidence</span><span class="p">])</span>
            <span class="n">missing_vars</span><span class="p">,</span> <span class="n">mean_cond</span><span class="p">,</span> <span class="n">cov_cond</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_evidence</span><span class="p">)</span>

            <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">missing_vars</span><span class="p">)</span>
            <span class="n">missing_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">missing_vars</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sorted_indices</span><span class="p">]</span>
            <span class="n">mean_cond</span> <span class="o">=</span> <span class="n">mean_cond</span><span class="p">[:,</span> <span class="n">sorted_indices</span><span class="p">]</span>
            <span class="n">cov_cond</span> <span class="o">=</span> <span class="n">cov_cond</span><span class="p">[</span><span class="n">sorted_indices</span><span class="p">][:,</span> <span class="n">sorted_indices</span><span class="p">]</span>

            <span class="n">samples_missing</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span>
                <span class="n">mean</span><span class="o">=</span><span class="n">mean_cond</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov_cond</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_samples</span>
            <span class="p">)</span>
            <span class="n">df_missing</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">samples_missing</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">missing_vars</span><span class="p">)</span>

            <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">variables</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">ev_var</span><span class="p">,</span> <span class="n">ev_val</span> <span class="ow">in</span> <span class="n">evidence</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">df</span><span class="p">[</span><span class="n">ev_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">ev_val</span>

            <span class="k">for</span> <span class="n">mv</span> <span class="ow">in</span> <span class="n">missing_vars</span><span class="p">:</span>
                <span class="n">df</span><span class="p">[</span><span class="n">mv</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_missing</span><span class="p">[</span><span class="n">mv</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">variables</span><span class="p">]</span>

        <span class="c1"># Step 5: Add do variables to the final dataframe</span>
        <span class="k">for</span> <span class="n">do_var</span><span class="p">,</span> <span class="n">do_val</span> <span class="ow">in</span> <span class="n">do</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">df</span><span class="p">[</span><span class="n">do_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">do_val</span>

        <span class="c1"># Step 6: Remove latent variables if specified</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">include_latents</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">latents</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">df</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.check_model">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.check_model">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">check_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks the model for structural/parameter consistency.</span>

<span class="sd">        Currently checks:</span>
<span class="sd">        * Each CPD&#39;s listed parents match the graph&#39;s parents.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bool</span>
<span class="sd">            True if all checks pass; raises ValueError otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">():</span>
            <span class="n">cpd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">(</span><span class="n">node</span><span class="o">=</span><span class="n">node</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cpd</span><span class="p">,</span> <span class="n">LinearGaussianCPD</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">cpd</span><span class="o">.</span><span class="n">evidence</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_parents</span><span class="p">(</span><span class="n">node</span><span class="p">)):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;CPD associated with </span><span class="si">%s</span><span class="s2"> doesn&#39;t have &quot;</span>
                        <span class="s2">&quot;proper parents associated with it.&quot;</span> <span class="o">%</span> <span class="n">node</span>
                    <span class="p">)</span>
        <span class="k">return</span> <span class="kc">True</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.get_cardinality">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.get_cardinality">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_cardinality</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Cardinality is not defined for continuous variables.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cardinality is not defined for continuous variables.&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.fit">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">estimator</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;mle&quot;</span><span class="p">,</span>
        <span class="n">std_estimator</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;unbiased&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;LinearGaussianBayesianNetwork&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Estimates (fits) the Linear Gaussian CPDs from data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data: pd.DataFrame</span>
<span class="sd">            Continuous-valued data containing all model variables.</span>
<span class="sd">            A pandas DataFrame with the data to which to fit the model</span>
<span class="sd">            structure. All variables must be continuously valued.</span>
<span class="sd">            Currently only &#39;mle&#39; (OLS) supported.</span>
<span class="sd">            The estimator to use for estimating the parameters. Currently, MLE via OLS is the</span>
<span class="sd">            only supported method.</span>
<span class="sd">            &#39;mle&#39; uses ddof=0; &#39;unbiased&#39; uses ddof = 1 + number_of_parents.</span>
<span class="sd">            Whether to use maximum likelihood estimate (MLE) or unbiased estimate for standard</span>
<span class="sd">            deviation. If &#39;mle&#39;, then ddof=0 is used while calculating standard deviation. If</span>
<span class="sd">            unbiased, ddof = 1 + number of parents.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self</span>
<span class="sd">        None: The estimated LinearGaussianCPDs are added to the model. They can</span>
<span class="sd">            be accessed using `model.cpds`.</span>
<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; df = pd.DataFrame(</span>
<span class="sd">        ...     np.random.normal(0, 1, (100, 3)), columns=[&quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork([(&quot;x1&quot;, &quot;x2&quot;), (&quot;x2&quot;, &quot;x3&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; model.fit(df)</span>
<span class="sd">        &gt;&gt;&gt; model.cpds</span>
<span class="sd">        [&lt;LinearGaussianCPD: P(x1) = N(-0.114; 0.911) at 0x7eb77d30cec0&gt;,</span>
<span class="sd">        [&lt;LinearGaussianCPD: P(x1) = N(-0.114; 0.911) at 0x7eb77d30cec0,</span>
<span class="sd">         &lt;LinearGaussianCPD: P(x2 | x1) = N(0.07*x1 + -0.075; 1.172) at 0x7eb77171fb60,</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Step 1: Check the input</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">missing_vars</span> <span class="o">:=</span> <span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">)))</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Following variables are missing in the data: </span><span class="si">{</span><span class="n">missing_vars</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">estimator</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span>
            <span class="s2">&quot;mle&quot;</span><span class="p">,</span>
        <span class="p">}:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;estimator must be one of {&#39;mle&#39;, &#39;unbiased&#39;}&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">std_estimator</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;mle&quot;</span><span class="p">,</span> <span class="s2">&quot;unbiased&quot;</span><span class="p">}:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;std_estimator must be one of {&#39;mle&#39;, &#39;unbiased&#39;}&quot;</span><span class="p">)</span>

        <span class="c1"># Step 2: Estimate the LinearGaussianCPDs</span>
        <span class="n">cpds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">():</span>
            <span class="n">parents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_parents</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
            <span class="c1"># Step 2.1: If node doesn&#39;t have any parents (i.e. root node),</span>
            <span class="c1">#  simply take the mean and variance.</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">ddof</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">std_estimator</span> <span class="o">==</span> <span class="s2">&quot;mle&quot;</span> <span class="k">else</span> <span class="mi">1</span>
                <span class="n">cpds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">LinearGaussianCPD</span><span class="p">(</span>
                        <span class="n">variable</span><span class="o">=</span><span class="n">node</span><span class="p">,</span>
                        <span class="n">beta</span><span class="o">=</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">node</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()],</span>
                        <span class="n">std</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">node</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">),</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="c1"># Step 2.2: Else, fit a linear regression model and take the coefficients and intercept.</span>
            <span class="c1"># Compute error variance using predicted values.</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">lm</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">parents</span><span class="p">],</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">node</span><span class="p">])</span>
                <span class="n">residuals</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">node</span><span class="p">]</span> <span class="o">-</span> <span class="n">lm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">parents</span><span class="p">])</span>
                <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span>  <span class="c1"># intercept + coefficients</span>
                <span class="n">ddof</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">std_estimator</span> <span class="o">==</span> <span class="s2">&quot;mle&quot;</span> <span class="k">else</span> <span class="n">p</span>
                <span class="n">cpds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">LinearGaussianCPD</span><span class="p">(</span>
                        <span class="n">variable</span><span class="o">=</span><span class="n">node</span><span class="p">,</span>
                        <span class="n">beta</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">lm</span><span class="o">.</span><span class="n">intercept_</span><span class="p">],</span> <span class="n">lm</span><span class="o">.</span><span class="n">coef_</span><span class="p">),</span>
                        <span class="n">std</span><span class="o">=</span><span class="n">residuals</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">),</span>
                        <span class="n">evidence</span><span class="o">=</span><span class="n">parents</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>

        <span class="c1"># Step 3: Add the estimated CPDs to the model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_cpds</span><span class="p">(</span><span class="o">*</span><span class="n">cpds</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.predict">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.predict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">distribution</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;joint&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predicts the conditional distribution of missing variables</span>

<span class="sd">        Predicts the distribution of the missing variable (i.e. missing</span>
<span class="sd">        columns) in the given dataset and returns its mean and covariance.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data: pandas.DataFrame</span>
<span class="sd">            DataFrame with a subset of model variables observed.</span>
<span class="sd">            The dataframe with missing variable which to predict.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        variables: list</span>
<span class="sd">            Missing variables (order matches returned distribution).</span>
<span class="sd">            The list of variables on which the returned conditional distribution is defined on.</span>

<span class="sd">        mu: np.array</span>
<span class="sd">            The mean array of the conditional joint distribution over</span>
<span class="sd">              the missing variables corresponding to each row of data.</span>

<span class="sd">        cov: np.array</span>
<span class="sd">            The covariance of the conditional joint distribution over the missing variables.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; # Drop a column you want to predict (avoid inplace=True to keep return value)</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.utils import get_example_model</span>
<span class="sd">        &gt;&gt;&gt; model = get_example_model(&quot;ecoli70&quot;)</span>
<span class="sd">        &gt;&gt;&gt; df = model.simulate(n_samples=5)</span>
<span class="sd">        &gt;&gt;&gt; # Drop a column that we want to predict.</span>
<span class="sd">        &gt;&gt;&gt; df = df.drop(columns=[&quot;folK&quot;], axis=1, inplace=True)</span>
<span class="sd">        &gt;&gt;&gt; model.predict(df)</span>
<span class="sd">                   array([[0.13440001]]))</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Step 0: Check the inputs</span>
        <span class="n">missing_vars</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">missing_vars</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No missing variables in the data&quot;</span><span class="p">)</span>

        <span class="c1"># Step 1: Create separate mean and cov matrices for missing and known variables.</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_joint_gaussian</span><span class="p">()</span>
        <span class="n">variable_order</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">topological_sort</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>

        <span class="n">missing_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">variable_order</span> <span class="k">if</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">missing_vars</span><span class="p">]</span>
        <span class="n">observed_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">variable_order</span> <span class="k">if</span> <span class="n">var</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">missing_vars</span><span class="p">]</span>
        <span class="n">missing_indexes</span> <span class="o">=</span> <span class="p">[</span><span class="n">variable_order</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">missing_vars</span><span class="p">]</span>
        <span class="n">observed_indexes</span> <span class="o">=</span> <span class="p">[</span><span class="n">variable_order</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">observed_vars</span><span class="p">]</span>

        <span class="n">mu_a</span> <span class="o">=</span> <span class="n">mu</span><span class="p">[</span><span class="n">missing_indexes</span><span class="p">]</span>
        <span class="n">mu_b</span> <span class="o">=</span> <span class="n">mu</span><span class="p">[</span><span class="n">observed_indexes</span><span class="p">]</span>

        <span class="n">cov_aa</span> <span class="o">=</span> <span class="n">cov</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">missing_indexes</span><span class="p">,</span> <span class="n">missing_indexes</span><span class="p">)]</span>  <span class="c1"># Full |a||a| submatrix</span>
        <span class="n">cov_bb</span> <span class="o">=</span> <span class="n">cov</span><span class="p">[</span>
            <span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">observed_indexes</span><span class="p">,</span> <span class="n">observed_indexes</span><span class="p">)</span>
        <span class="p">]</span>  <span class="c1"># Full |b||b| submatrix</span>
        <span class="n">cov_ab</span> <span class="o">=</span> <span class="n">cov</span><span class="p">[</span>
            <span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">missing_indexes</span><span class="p">,</span> <span class="n">observed_indexes</span><span class="p">)</span>
        <span class="p">]</span>  <span class="c1"># Full |a||b| submatrix</span>

        <span class="c1"># Step 2: Compute the conditional distributions</span>
        <span class="n">X_b</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">observed_vars</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># shape: (n_samples, |observed|)</span>
        <span class="n">centered_b</span> <span class="o">=</span> <span class="n">X_b</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">mu_b</span><span class="p">)</span>  <span class="c1"># shape: (n_samples, |observed|).</span>
        <span class="n">mu_cond</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">mu_a</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">cov_ab</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">cov_bb</span><span class="p">,</span> <span class="n">centered_b</span><span class="o">.</span><span class="n">T</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
        <span class="p">)</span>
        <span class="n">cov_cond</span> <span class="o">=</span> <span class="n">cov_aa</span> <span class="o">-</span> <span class="n">cov_ab</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">cov_bb</span><span class="p">,</span> <span class="n">cov_ab</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="c1"># Step 3: Return values</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">missing_vars</span><span class="p">,</span> <span class="n">mu_cond</span><span class="p">,</span> <span class="n">cov_cond</span><span class="p">)</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.to_markov_model">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.to_markov_model">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to_markov_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        For now, to_markov_model method has not been implemented for LinearGaussianBayesianNetwork.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;to_markov_model method has not been implemented for LinearGaussianBayesianNetwork.&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.is_imap">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.is_imap">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">is_imap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">JPD</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        For now, is_imap method has not been implemented for LinearGaussianBayesianNetwork.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;is_imap method has not been implemented for LinearGaussianBayesianNetwork.&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.get_random">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.get_random">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_random</span><span class="p">(</span>
        <span class="n">n_nodes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">edge_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">node_names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">latents</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">loc</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;LinearGaussianBayesianNetwork&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a randomly generated Linear Gaussian Bayesian Network on `n_nodes`</span>
<span class="sd">        Returns a randomly generated Linear Gaussian Bayesian Network on `n_nodes` variables</span>
<span class="sd">        with edge probabiliy of `edge_prob` between variables.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_nodes: int</span>
<span class="sd">            Number of nodes.</span>
<span class="sd">            The number of nodes in the randomly generated DAG.</span>

<span class="sd">            Probability of an edge (consistent with a topological order).</span>
<span class="sd">            The probability of edge between any two nodes in the topologically</span>
<span class="sd">            sorted DAG.</span>

<span class="sd">        node_names: list (default: None)</span>
<span class="sd">            A list of variables names to use in the random graph.</span>
<span class="sd">            If None, the node names are integer values starting from 0.</span>

<span class="sd">        latents: bool (default: False)</span>
<span class="sd">        loc: float</span>

<span class="sd">            Mean of normal for coefficients.</span>
<span class="sd">            The mean of the normal distribution from which the coefficients are</span>
<span class="sd">            sampled.</span>

<span class="sd">            Std dev of normal for coefficients.</span>
<span class="sd">            The standard deviation of the normal distribution from which the</span>
<span class="sd">            coefficients are sampled.</span>

<span class="sd">        seed: int</span>
<span class="sd">            The seed for the random number generator.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        LinearGaussianBayesianNetwork</span>
<span class="sd">            The randomly generated model.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork.get_random(n_nodes=5)</span>
<span class="sd">        &gt;&gt;&gt; model.nodes()</span>
<span class="sd">        NodeView((0, 3, 1, 2, 4))</span>
<span class="sd">        &gt;&gt;&gt; model.edges()</span>
<span class="sd">        OutEdgeView([(0, 3), (3, 4), (1, 3), (2, 4)])</span>
<span class="sd">        &gt;&gt;&gt; model.cpds</span>
<span class="sd">        [&lt;LinearGaussianCPD: P(0) = N(1.764; 1.613) at 0x2732f41aae0,</span>
<span class="sd">        &lt;LinearGaussianCPD: P(3 | 0, 1) = N(-0.721*0 + -0.079*1 + 0.943; 0.12) at 0x2732f16db20,</span>
<span class="sd">        &lt;LinearGaussianCPD: P(1) = N(-0.534; 0.208) at 0x2732f320b30,</span>
<span class="sd">        &lt;LinearGaussianCPD: P(2) = N(-0.023; 0.166) at 0x2732d8d5f40,</span>
<span class="sd">        &lt;LinearGaussianCPD: P(4 | 2, 3) = N(-0.24*2 + -0.907*3 + 0.625; 0.48) at 0x2737fecdaf0]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dag</span> <span class="o">=</span> <span class="n">DAG</span><span class="o">.</span><span class="n">get_random</span><span class="p">(</span>
            <span class="n">n_nodes</span><span class="o">=</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">edge_prob</span><span class="o">=</span><span class="n">edge_prob</span><span class="p">,</span> <span class="n">node_names</span><span class="o">=</span><span class="n">node_names</span><span class="p">,</span> <span class="n">latents</span><span class="o">=</span><span class="n">latents</span>
        <span class="p">)</span>
        <span class="n">lgbn_model</span> <span class="o">=</span> <span class="n">LinearGaussianBayesianNetwork</span><span class="p">(</span><span class="n">dag</span><span class="o">.</span><span class="n">edges</span><span class="p">(),</span> <span class="n">latents</span><span class="o">=</span><span class="n">dag</span><span class="o">.</span><span class="n">latents</span><span class="p">)</span>
        <span class="n">lgbn_model</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">(</span><span class="n">dag</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>

        <span class="n">cpds</span> <span class="o">=</span> <span class="n">lgbn_model</span><span class="o">.</span><span class="n">get_random_cpds</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

        <span class="n">lgbn_model</span><span class="o">.</span><span class="n">add_cpds</span><span class="p">(</span><span class="o">*</span><span class="n">cpds</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lgbn_model</span></div>
</div>

</code></pre></div>







  
  






                
  <div data-ea-publisher="pgmpyorg" data-ea-type="image" data-ea-style="stickybox"></div>
  <script>
    (function() {
      var nav = document.querySelector('.md-header__inner');
      if (!nav) return;

      var socialDiv = document.createElement('div');
      socialDiv.className = 'md-header__social';

      socialDiv.innerHTML =
        '<a href="https://github.com/pgmpy/pgmpy" target="_blank" rel="noopener" title="GitHub">' +
          '<svg viewBox="0 0 496 512" xmlns="http://www.w3.org/2000/svg">' +
            '<path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.8-14.9-112.8-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/>' +
          '</svg>' +
        '</a>' +
        '<a href="https://discord.gg/DRkdKaumBs" target="_blank" rel="noopener" title="Discord">' +
          '<svg viewBox="0 0 640 512" xmlns="http://www.w3.org/2000/svg">' +
            '<path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485.065 485.065 0 0 0 404.081 32.03a1.816 1.816 0 0 0-1.923.91 337.461 337.461 0 0 0-14.9 30.6 447.848 447.848 0 0 0-134.426 0 309.541 309.541 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91A483.689 483.689 0 0 0 116.085 69.137a1.712 1.712 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.016 2.016 0 0 0 .765 1.375A487.666 487.666 0 0 0 176.02 479.918a1.9 1.9 0 0 0 2.063-.676A348.2 348.2 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321.173 321.173 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126c3.082-2.309 6.166-4.711 9.109-7.137a1.819 1.819 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.812 1.812 0 0 1 1.924.233c2.944 2.426 6.027 4.851 9.132 7.16a1.884 1.884 0 0 1-.162 3.126 301.407 301.407 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391.055 391.055 0 0 0 30.014 48.815 1.864 1.864 0 0 0 2.063.7A486.048 486.048 0 0 0 610.7 405.729a1.882 1.882 0 0 0 .765-1.352C623.729 277.594 590.933 167.465 524.531 69.836zM222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239S193.056 219.1 222.491 219.1c29.665 0 53.306 26.82 52.843 59.239C275.334 310.993 251.924 337.58 222.491 337.58zm195.38 0c-28.971 0-52.843-26.587-52.843-59.239S388.437 219.1 417.871 219.1c29.667 0 53.307 26.82 52.844 59.239C470.715 310.993 447.538 337.58 417.871 337.58z"/>' +
          '</svg>' +
        '</a>' +
        '<a href="https://www.linkedin.com/company/pgmpy/" target="_blank" rel="noopener" title="LinkedIn">' +
          '<svg viewBox="0 0 448 512" xmlns="http://www.w3.org/2000/svg">' +
            '<path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/>' +
          '</svg>' +
        '</a>';

      nav.appendChild(socialDiv);
    })();
  </script>

              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  
  
  <div class="md-footer-meta md-typeset">
    
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-footer-copyright__highlight">
        &#169; Copyright 2025, Ankur Ankan.
        
    </div>
  
    Created using
    <a href="https://www.sphinx-doc.org/" target="_blank" rel="noopener">Sphinx</a>
    9.1.0.
     and
    <a href="https://github.com/jbms/sphinx-immaterial/" target="_blank" rel="noopener">Sphinx-Immaterial</a>
  
</div>
      
    </div>
    
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.top", "search.highlight", "search.share", "toc.follow", "content.tabs.link"], "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike", "staticVersions": [{"aliases": [], "title": "1.0.0 (stable)", "version": "https://pgmpy.org"}, {"aliases": [], "title": "dev", "version": "https://pgmpy.org/dev"}], "versionPath": null}}</script>
    
      
        <script src="../../../_static/sphinx_immaterial_theme.32136f45f91ae6956.min.js?v=a7a9472a"></script>
        <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../../_static/copybutton.js?v=f281be69"></script>
        <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
  </body>
</html>
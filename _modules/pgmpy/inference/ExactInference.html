


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../_static/logo_favi.ico">
    
    
      
        <title>pgmpy.inference.ExactInference - pgmpy</title>
      
    
    
      
        
      
      


    
    
      
    
    
      
        
        
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
        <link rel="stylesheet" type="text/css" href="../../../_static/sphinx_immaterial_theme.acf80fe7f4d9ef9e2.min.css?v=9e56d0d2" />
        <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
        <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  
  <!-- SEO meta tags -->
  <meta name="description" content="pgmpy: A Python library for causal inference and probabilistic inference using Directed Acyclic Graphs (DAGs) and Bayesian Networks.">
  <meta name="keywords" content="pgmpy, Bayesian Networks, causal inference, probabilistic graphical models, structure learning, parameter estimation, Python">
  <meta property="og:type" content="website">
  <meta property="og:site_name" content="pgmpy">
  <meta property="og:title" content="pgmpy.inference.ExactInference">
  <meta property="og:description" content="pgmpy: A Python library for causal inference and probabilistic inference using Directed Acyclic Graphs (DAGs) and Bayesian Networks.">
  <meta property="og:url" content="https://pgmpy.org/_modules/pgmpy/inference/ExactInference.html">
  <meta property="og:image" content="https://pgmpy.org/_static/logo.png">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="pgmpy.inference.ExactInference">
  <meta name="twitter:description" content="pgmpy: A Python library for causal inference and probabilistic inference using Directed Acyclic Graphs (DAGs) and Bayesian Networks.">
  <meta name="twitter:image" content="https://pgmpy.org/_static/logo.png">
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-HCFR07M31W"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-HCFR07M31W');
  </script>
  <!-- EthicalAds -->
  <script async src="https://media.ethicalads.io/media/client/ethicalads.min.js"></script>
  <!-- Header social links styling -->
  <style>
    .md-header__social {
      display: flex;
      align-items: center;
      gap: 0.1rem;
      margin-left: 0.4rem;
    }
    .md-header__social a {
      display: inline-flex;
      align-items: center;
      justify-content: center;
      padding: 0.4rem;
      color: var(--md-default-fg-color--light);
      opacity: 0.7;
      transition: opacity 0.25s;
    }
    .md-header__social a:hover {
      opacity: 1;
    }
    .md-header__social svg {
      width: 1.2rem;
      height: 1.2rem;
      fill: currentColor;
    }
    [data-md-color-scheme="slate"] .md-header__social a {
      color: var(--md-default-fg-color--light);
    }
    /* Center content when right sidebar (toc) is hidden */
    .md-sidebar--secondary[hidden] ~ .md-content {
      margin-left: auto;
      margin-right: auto;
    }
  </style>

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../index.html" title="pgmpy" class="md-header__button md-logo" aria-label="pgmpy" data-md-component="logo">
      <img src="../../../_static/logo.png" alt="logo">
    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            pgmpy
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              pgmpy.inference.ExactInference
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/pgmpy/pgmpy" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    pgmpy/pgmpy
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../started/base.html" class="md-tabs__link">
        
  
    
  
  <span title="/started/base.rst (reference label)"><span>Getting Started</span></span>

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../documentation.html" class="md-tabs__link">
        
  
    
  
  <span title="/documentation.rst (reference label)"><span>Documentation</span></span>

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../examples.html" class="md-tabs__link">
        
  
    
  
  <span title="/examples.rst (reference label)"><span>Examples</span></span>

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../api.html" class="md-tabs__link">
        
  
    
  
  <span title="/api.rst (reference label)"><span>API Reference</span></span>

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../development.html" class="md-tabs__link">
        
  
    
  
  <span title="/development.rst (reference label)"><span>Development</span></span>

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../index.html" title="pgmpy" class="md-nav__button md-logo" aria-label="pgmpy" data-md-component="logo">
      <img src="../../../_static/logo.png" alt="logo">
    </a>
    pgmpy
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/pgmpy/pgmpy" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    pgmpy/pgmpy
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../started/base.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/started/base.rst (reference label)"><span>Getting Started</span></span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../documentation.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/documentation.rst (reference label)"><span>Documentation</span></span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/examples.rst (reference label)"><span>Examples</span></span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../api.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/api.rst (reference label)"><span>API Reference</span></span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../development.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/development.rst (reference label)"><span>Development</span></span>
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary">
  
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset" role="main">
                
                
  
                  


<h1>Source code for pgmpy.inference.ExactInference</h1><div class="highlight"><pre>
<span></span><code><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">copy</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">itertools</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">reduce</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Hashable</span><span class="p">,</span> <span class="n">Optional</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">networkx</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nx</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">opt_einsum</span><span class="w"> </span><span class="kn">import</span> <span class="n">contract</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm.auto</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">pgmpy</span><span class="w"> </span><span class="kn">import</span> <span class="n">config</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pgmpy.factors</span><span class="w"> </span><span class="kn">import</span> <span class="n">factor_product</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pgmpy.factors.discrete</span><span class="w"> </span><span class="kn">import</span> <span class="n">DiscreteFactor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pgmpy.inference</span><span class="w"> </span><span class="kn">import</span> <span class="n">Inference</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pgmpy.inference.EliminationOrder</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">MinFill</span><span class="p">,</span>
    <span class="n">MinNeighbors</span><span class="p">,</span>
    <span class="n">MinWeight</span><span class="p">,</span>
    <span class="n">WeightedMinFill</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pgmpy.models</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">DiscreteBayesianNetwork</span><span class="p">,</span>
    <span class="n">DynamicBayesianNetwork</span><span class="p">,</span>
    <span class="n">FactorGraph</span><span class="p">,</span>
    <span class="n">FunctionalBayesianNetwork</span><span class="p">,</span>
    <span class="n">JunctionTree</span><span class="p">,</span>
    <span class="n">LinearGaussianBayesianNetwork</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pgmpy.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">compat_fns</span>


<div class="viewcode-block" id="VariableElimination">
<a class="viewcode-back" href="../../../infer/ve.html#pgmpy.inference.ExactInference.VariableElimination">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">VariableElimination</span><span class="p">(</span><span class="n">Inference</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_get_working_factors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">evidence</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Uses the evidence given to the query methods to modify the factors before running</span>
<span class="sd">        the variable elimination algorithm.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        evidence: dict</span>
<span class="sd">            Dict of the form {variable: state}</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict: Modified working factors.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">working_factors</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">node</span><span class="p">:</span> <span class="p">{(</span><span class="n">factor</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">factor</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">factors</span><span class="p">[</span><span class="n">node</span><span class="p">]}</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">factors</span>
        <span class="p">}</span>

        <span class="c1"># Dealing with evidence. Reducing factors over it before VE is run.</span>
        <span class="k">if</span> <span class="n">evidence</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">evidence_var</span> <span class="ow">in</span> <span class="n">evidence</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">factor</span><span class="p">,</span> <span class="n">origin</span> <span class="ow">in</span> <span class="n">working_factors</span><span class="p">[</span><span class="n">evidence_var</span><span class="p">]:</span>
                    <span class="n">factor_reduced</span> <span class="o">=</span> <span class="n">factor</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span>
                        <span class="p">[(</span><span class="n">evidence_var</span><span class="p">,</span> <span class="n">evidence</span><span class="p">[</span><span class="n">evidence_var</span><span class="p">])],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">factor_reduced</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
                        <span class="n">working_factors</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">remove</span><span class="p">((</span><span class="n">factor</span><span class="p">,</span> <span class="n">origin</span><span class="p">))</span>
                        <span class="n">working_factors</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">factor_reduced</span><span class="p">,</span> <span class="n">evidence_var</span><span class="p">))</span>
                <span class="k">del</span> <span class="n">working_factors</span><span class="p">[</span><span class="n">evidence_var</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">working_factors</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_elimination_order</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">variables</span><span class="p">,</span> <span class="n">evidence</span><span class="p">,</span> <span class="n">elimination_order</span><span class="p">,</span> <span class="n">show_progress</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Deals with all elimination order parameters given to _variable_elimination method</span>
<span class="sd">        and returns a list of variables that are to be eliminated</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        elimination_order: str or list</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list: A list of variables names in the order they need to be eliminated.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">to_eliminate</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span>
            <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span>
            <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">evidence</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">evidence</span> <span class="k">else</span> <span class="p">[])</span>
        <span class="p">)</span>

        <span class="c1"># Step 1: If elimination_order is a list, verify it&#39;s correct and return.</span>
        <span class="c1"># Step 1.1: Check that not of the `variables` and `evidence` is in the elimination_order.</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">elimination_order</span><span class="p">,</span> <span class="s2">&quot;__iter__&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">elimination_order</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span>
                <span class="n">var</span> <span class="ow">in</span> <span class="n">elimination_order</span>
                <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span><span class="o">.</span><span class="n">union</span><span class="p">(</span>
                    <span class="nb">set</span><span class="p">(</span><span class="n">evidence</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">evidence</span> <span class="k">else</span> <span class="p">[])</span>
                <span class="p">)</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Elimination order contains variables which are in&quot;</span>
                    <span class="s2">&quot; variables or evidence args&quot;</span>
                <span class="p">)</span>
            <span class="c1"># Step 1.2: Check if elimination_order has variables which are not in the model.</span>
            <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="n">var</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">nodes</span><span class="p">()</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">elimination_order</span><span class="p">):</span>
                <span class="n">elimination_order</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                    <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">nodes</span><span class="p">(),</span> <span class="n">elimination_order</span><span class="p">)</span>
                <span class="p">)</span>

            <span class="c1"># Step 1.3: Check if the elimination_order has all the variables that need to be eliminated.</span>
            <span class="k">elif</span> <span class="n">to_eliminate</span> <span class="o">!=</span> <span class="nb">set</span><span class="p">(</span><span class="n">elimination_order</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Elimination order doesn&#39;t contain all the variables&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;which need to be eliminated. The variables which need to&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;be eliminated are </span><span class="si">{</span><span class="n">to_eliminate</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="k">return</span> <span class="n">elimination_order</span>

        <span class="c1"># Step 2: If elimination order is None or a Markov model, return a random order.</span>
        <span class="k">elif</span> <span class="p">(</span><span class="n">elimination_order</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">DiscreteBayesianNetwork</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="n">to_eliminate</span>

        <span class="c1"># Step 3: If elimination order is a str, compute the order using the specified heuristic.</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">elimination_order</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">DiscreteBayesianNetwork</span>
        <span class="p">):</span>
            <span class="n">heuristic_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;weightedminfill&quot;</span><span class="p">:</span> <span class="n">WeightedMinFill</span><span class="p">,</span>
                <span class="s2">&quot;minneighbors&quot;</span><span class="p">:</span> <span class="n">MinNeighbors</span><span class="p">,</span>
                <span class="s2">&quot;minweight&quot;</span><span class="p">:</span> <span class="n">MinWeight</span><span class="p">,</span>
                <span class="s2">&quot;minfill&quot;</span><span class="p">:</span> <span class="n">MinFill</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="n">elimination_order</span> <span class="o">=</span> <span class="n">heuristic_dict</span><span class="p">[</span><span class="n">elimination_order</span><span class="o">.</span><span class="n">lower</span><span class="p">()](</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span>
            <span class="p">)</span><span class="o">.</span><span class="n">get_elimination_order</span><span class="p">(</span><span class="n">nodes</span><span class="o">=</span><span class="n">to_eliminate</span><span class="p">,</span> <span class="n">show_progress</span><span class="o">=</span><span class="n">show_progress</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">elimination_order</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_variable_elimination</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">variables</span><span class="p">,</span>
        <span class="n">operation</span><span class="p">,</span>
        <span class="n">evidence</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">elimination_order</span><span class="o">=</span><span class="s2">&quot;MinFill&quot;</span><span class="p">,</span>
        <span class="n">joint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">show_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implementation of a generalized variable elimination.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variables: list, array-like</span>
<span class="sd">            variables that are not to be eliminated.</span>

<span class="sd">        operation: str (&#39;marginalize&#39; | &#39;maximize&#39;)</span>
<span class="sd">            The operation to do for eliminating the variable.</span>

<span class="sd">        evidence: dict</span>
<span class="sd">            a dict key, value pair as {var: state_of_var_observed}</span>
<span class="sd">            None if no evidence</span>

<span class="sd">        elimination_order: str or list (array-like)</span>
<span class="sd">            If str: Heuristic to use to find the elimination order.</span>
<span class="sd">            If array-like: The elimination order to use.</span>
<span class="sd">            If None: A random elimination order is used.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Step 1: Deal with the input arguments.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;variables must be a list of strings&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">evidence</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;evidence must be a list of strings&quot;</span><span class="p">)</span>

        <span class="c1"># Dealing with the case when variables are not provided.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">variables</span><span class="p">:</span>
            <span class="n">all_factors</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">factor_li</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">factors</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                <span class="n">all_factors</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">factor_li</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">joint</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">factor_product</span><span class="p">(</span><span class="o">*</span><span class="nb">set</span><span class="p">(</span><span class="n">all_factors</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="nb">set</span><span class="p">(</span><span class="n">all_factors</span><span class="p">)</span>

        <span class="c1"># Step 2: Prepare data structures to run the algorithm.</span>
        <span class="n">eliminated_variables</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="c1"># Get working factors and elimination order</span>
        <span class="n">working_factors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_working_factors</span><span class="p">(</span><span class="n">evidence</span><span class="p">)</span>
        <span class="n">elimination_order</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_elimination_order</span><span class="p">(</span>
            <span class="n">variables</span><span class="p">,</span> <span class="n">evidence</span><span class="p">,</span> <span class="n">elimination_order</span><span class="p">,</span> <span class="n">show_progress</span><span class="o">=</span><span class="n">show_progress</span>
        <span class="p">)</span>

        <span class="c1"># Step 3: Run variable elimination</span>
        <span class="k">if</span> <span class="n">show_progress</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">SHOW_PROGRESS</span><span class="p">:</span>
            <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">elimination_order</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pbar</span> <span class="o">=</span> <span class="n">elimination_order</span>

        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">show_progress</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">SHOW_PROGRESS</span><span class="p">:</span>
                <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Eliminating: </span><span class="si">{</span><span class="n">var</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="c1"># Removing all the factors containing the variables which are</span>
            <span class="c1"># eliminated (as all the factors should be considered only once)</span>
            <span class="n">factors</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">factor</span>
                <span class="k">for</span> <span class="n">factor</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">working_factors</span><span class="p">[</span><span class="n">var</span><span class="p">]</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="n">factor</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">eliminated_variables</span><span class="p">)</span>
            <span class="p">]</span>
            <span class="n">phi</span> <span class="o">=</span> <span class="n">factor_product</span><span class="p">(</span><span class="o">*</span><span class="n">factors</span><span class="p">)</span>
            <span class="n">phi</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">operation</span><span class="p">)([</span><span class="n">var</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">del</span> <span class="n">working_factors</span><span class="p">[</span><span class="n">var</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">variable</span> <span class="ow">in</span> <span class="n">phi</span><span class="o">.</span><span class="n">variables</span><span class="p">:</span>
                <span class="n">working_factors</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">phi</span><span class="p">,</span> <span class="n">var</span><span class="p">))</span>
            <span class="n">eliminated_variables</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>

        <span class="c1"># Step 4: Prepare variables to be returned.</span>
        <span class="n">final_distribution</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">working_factors</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">factor</span><span class="p">,</span> <span class="n">origin</span> <span class="ow">in</span> <span class="n">working_factors</span><span class="p">[</span><span class="n">node</span><span class="p">]:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="n">factor</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">eliminated_variables</span><span class="p">):</span>
                    <span class="n">final_distribution</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">factor</span><span class="p">,</span> <span class="n">origin</span><span class="p">))</span>
        <span class="n">final_distribution</span> <span class="o">=</span> <span class="p">[</span><span class="n">factor</span> <span class="k">for</span> <span class="n">factor</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">final_distribution</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">joint</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">DiscreteBayesianNetwork</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">factor_product</span><span class="p">(</span><span class="o">*</span><span class="n">final_distribution</span><span class="p">)</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">factor_product</span><span class="p">(</span><span class="o">*</span><span class="n">final_distribution</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">query_var_factor</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">DiscreteBayesianNetwork</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">query_var</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">:</span>
                    <span class="n">phi</span> <span class="o">=</span> <span class="n">factor_product</span><span class="p">(</span><span class="o">*</span><span class="n">final_distribution</span><span class="p">)</span>
                    <span class="n">query_var_factor</span><span class="p">[</span><span class="n">query_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">phi</span><span class="o">.</span><span class="n">marginalize</span><span class="p">(</span>
                        <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">([</span><span class="n">query_var</span><span class="p">])),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">query_var</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">:</span>
                    <span class="n">phi</span> <span class="o">=</span> <span class="n">factor_product</span><span class="p">(</span><span class="o">*</span><span class="n">final_distribution</span><span class="p">)</span>
                    <span class="n">query_var_factor</span><span class="p">[</span><span class="n">query_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">phi</span><span class="o">.</span><span class="n">marginalize</span><span class="p">(</span>
                        <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">([</span><span class="n">query_var</span><span class="p">])),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span>
                    <span class="p">)</span>
            <span class="k">return</span> <span class="n">query_var_factor</span>

<div class="viewcode-block" id="VariableElimination.query">
<a class="viewcode-back" href="../../../infer/ve.html#pgmpy.inference.ExactInference.VariableElimination.query">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">query</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">variables</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Hashable</span><span class="p">],</span>
        <span class="n">evidence</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="n">Hashable</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">virtual_evidence</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">elimination_order</span><span class="o">=</span><span class="s2">&quot;greedy&quot;</span><span class="p">,</span>
        <span class="n">joint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">show_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variables: list</span>
<span class="sd">            list of variables for which you want to compute the probability</span>

<span class="sd">        evidence: dict</span>
<span class="sd">            a dict key, value pair as {var: state_of_var_observed}</span>
<span class="sd">            None if no evidence</span>

<span class="sd">        virtual_evidence: list (default:None)</span>
<span class="sd">            A list of pgmpy.factors.discrete.TabularCPD representing the virtual</span>
<span class="sd">            evidences.</span>

<span class="sd">        elimination_order: str or list (default=&#39;greedy&#39;)</span>
<span class="sd">            Order in which to eliminate the variables in the algorithm. If list is provided,</span>
<span class="sd">            should contain all variables in the model except the ones in `variables`. str options</span>
<span class="sd">            are: `greedy`, `WeightedMinFill`, `MinNeighbors`, `MinWeight`, `MinFill`. Please</span>
<span class="sd">            refer https://pgmpy.org/exact_infer/ve.html#module-pgmpy.inference.EliminationOrder</span>
<span class="sd">            for details.</span>

<span class="sd">        joint: boolean (default: True)</span>
<span class="sd">            If True, returns a Joint Distribution over `variables`.</span>
<span class="sd">            If False, returns a dict of distributions over each of the `variables`.</span>

<span class="sd">        show_progress: boolean</span>
<span class="sd">            If True, shows a progress bar.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.inference import VariableElimination</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; values = pd.DataFrame(</span>
<span class="sd">        ...     np.random.randint(low=0, high=2, size=(1000, 5)),</span>
<span class="sd">        ...     columns=[&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;],</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; model = DiscreteBayesianNetwork(</span>
<span class="sd">        ...     [(&quot;A&quot;, &quot;B&quot;), (&quot;C&quot;, &quot;B&quot;), (&quot;C&quot;, &quot;D&quot;), (&quot;B&quot;, &quot;E&quot;)]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; model.fit(values)</span>
<span class="sd">        &gt;&gt;&gt; inference = VariableElimination(model)</span>
<span class="sd">        &gt;&gt;&gt; phi_query = inference.query([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">evidence</span> <span class="o">=</span> <span class="n">evidence</span> <span class="k">if</span> <span class="n">evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">LinearGaussianBayesianNetwork</span><span class="p">,</span> <span class="n">FunctionalBayesianNetwork</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Variable Elimination is not supported for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Please use the &#39;predict&#39; method of the </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> class instead.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Step 1: Parameter Checks</span>
        <span class="n">common_vars</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">evidence</span> <span class="k">if</span> <span class="n">evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[])</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span>
            <span class="nb">set</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">common_vars</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Can&#39;t have the same variables in both `variables` and `evidence`. Found in both: </span><span class="si">{</span><span class="n">common_vars</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">variables</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The `variables` argument to query() must contain at least one variable.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Step 2: If virtual_evidence is provided, modify the network.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">DiscreteBayesianNetwork</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="n">virtual_evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_virtual_evidence</span><span class="p">(</span><span class="n">virtual_evidence</span><span class="p">)</span>
            <span class="n">virt_evidence</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;__&quot;</span> <span class="o">+</span> <span class="n">cpd</span><span class="o">.</span><span class="n">variables</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="n">virtual_evidence</span><span class="p">}</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">query</span><span class="p">(</span>
                <span class="n">variables</span><span class="o">=</span><span class="n">variables</span><span class="p">,</span>
                <span class="n">evidence</span><span class="o">=</span><span class="p">{</span><span class="o">**</span><span class="n">evidence</span><span class="p">,</span> <span class="o">**</span><span class="n">virt_evidence</span><span class="p">},</span>
                <span class="n">virtual_evidence</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">elimination_order</span><span class="o">=</span><span class="n">elimination_order</span><span class="p">,</span>
                <span class="n">joint</span><span class="o">=</span><span class="n">joint</span><span class="p">,</span>
                <span class="n">show_progress</span><span class="o">=</span><span class="n">show_progress</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Step 3: Prune the network based on variables and evidence.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">DiscreteBayesianNetwork</span><span class="p">):</span>
            <span class="n">model_reduced</span><span class="p">,</span> <span class="n">evidence</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prune_bayesian_model</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="n">evidence</span><span class="p">)</span>
            <span class="n">factors</span> <span class="o">=</span> <span class="n">model_reduced</span><span class="o">.</span><span class="n">cpds</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model_reduced</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span>
            <span class="n">factors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">factors</span>

        <span class="c1"># Step 4: If elimination_order is greedy, do a tensor contraction approach</span>
        <span class="c1">#         else do the classic Variable Elimination.</span>
        <span class="k">if</span> <span class="n">elimination_order</span> <span class="o">==</span> <span class="s2">&quot;greedy&quot;</span><span class="p">:</span>
            <span class="c1"># Step 5.1: Compute the values array for factors after reducing them to provided</span>
            <span class="c1">#           evidence.</span>
            <span class="n">evidence_vars</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">evidence</span><span class="p">)</span>
            <span class="n">reduce_indexes</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">reshape_indexes</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">phi</span> <span class="ow">in</span> <span class="n">factors</span><span class="p">:</span>
                <span class="n">indexes_to_reduce</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">phi</span><span class="o">.</span><span class="n">variables</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">phi</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">evidence_vars</span><span class="p">)</span>
                <span class="p">]</span>
                <span class="n">indexer</span> <span class="o">=</span> <span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">phi</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indexes_to_reduce</span><span class="p">:</span>
                    <span class="n">indexer</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">phi</span><span class="o">.</span><span class="n">get_state_no</span><span class="p">(</span>
                        <span class="n">phi</span><span class="o">.</span><span class="n">variables</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">evidence</span><span class="p">[</span><span class="n">phi</span><span class="o">.</span><span class="n">variables</span><span class="p">[</span><span class="n">index</span><span class="p">]]</span>
                    <span class="p">)</span>
                <span class="n">reduce_indexes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">indexer</span><span class="p">))</span>

            <span class="c1"># Step 5.2: Prepare values and index arrays to do use in einsum</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">JunctionTree</span><span class="p">):</span>
                <span class="n">var_int_map</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">var</span><span class="p">:</span> <span class="n">i</span>
                    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                        <span class="nb">set</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">model_reduced</span><span class="o">.</span><span class="n">nodes</span><span class="p">()))</span>
                    <span class="p">)</span>
                <span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">var_int_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">var</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model_reduced</span><span class="o">.</span><span class="n">nodes</span><span class="p">())}</span>

            <span class="n">evidence_var_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">evidence</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="n">einsum_expr</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">DiscreteBayesianNetwork</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">phi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">factors</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">phi</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span> <span class="o">-</span> <span class="n">evidence_var_set</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="c1"># if phi.variable not in evidence_var_set:</span>
                        <span class="n">einsum_expr</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">phi</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">reduce_indexes</span><span class="p">[</span><span class="n">index</span><span class="p">]]))</span>
                        <span class="n">einsum_expr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="p">[</span>
                                <span class="n">var_int_map</span><span class="p">[</span><span class="n">var</span><span class="p">]</span>
                                <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">phi</span><span class="o">.</span><span class="n">variables</span>
                                <span class="k">if</span> <span class="n">var</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">evidence</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                            <span class="p">]</span>
                        <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">phi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">factors</span><span class="p">):</span>
                    <span class="n">einsum_expr</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">phi</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">reduce_indexes</span><span class="p">[</span><span class="n">index</span><span class="p">]]))</span>
                    <span class="n">einsum_expr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="p">[</span>
                            <span class="n">var_int_map</span><span class="p">[</span><span class="n">var</span><span class="p">]</span>
                            <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">phi</span><span class="o">.</span><span class="n">variables</span>
                            <span class="k">if</span> <span class="n">var</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">evidence</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                        <span class="p">]</span>
                    <span class="p">)</span>

            <span class="n">result_values</span> <span class="o">=</span> <span class="n">contract</span><span class="p">(</span>
                <span class="o">*</span><span class="n">einsum_expr</span><span class="p">,</span> <span class="p">[</span><span class="n">var_int_map</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">],</span> <span class="n">optimize</span><span class="o">=</span><span class="s2">&quot;greedy&quot;</span>
            <span class="p">)</span>

            <span class="c1"># Step 5.3: Prepare return values.</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">DiscreteFactor</span><span class="p">(</span>
                <span class="n">variables</span><span class="p">,</span>
                <span class="n">result_values</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                <span class="n">result_values</span><span class="p">,</span>
                <span class="n">state_names</span><span class="o">=</span><span class="p">{</span><span class="n">var</span><span class="p">:</span> <span class="n">model_reduced</span><span class="o">.</span><span class="n">states</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">},</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">joint</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="p">(</span><span class="n">DiscreteBayesianNetwork</span><span class="p">,</span> <span class="n">JunctionTree</span><span class="p">,</span> <span class="n">DynamicBayesianNetwork</span><span class="p">),</span>
                <span class="p">):</span>
                    <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">result</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">result_dict</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="n">all_vars</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="p">(</span><span class="n">DiscreteBayesianNetwork</span><span class="p">,</span> <span class="n">JunctionTree</span><span class="p">,</span> <span class="n">DynamicBayesianNetwork</span><span class="p">),</span>
                <span class="p">):</span>
                    <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">:</span>
                        <span class="n">result_dict</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">marginalize</span><span class="p">(</span>
                            <span class="n">all_vars</span> <span class="o">-</span> <span class="p">{</span><span class="n">var</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span>
                        <span class="p">)</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">:</span>
                        <span class="n">result_dict</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">marginalize</span><span class="p">(</span>
                            <span class="n">all_vars</span> <span class="o">-</span> <span class="p">{</span><span class="n">var</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span>
                        <span class="p">)</span>

                <span class="k">return</span> <span class="n">result_dict</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Step 5.1: Initialize data structures for the reduced bn.</span>
            <span class="n">reduced_ve</span> <span class="o">=</span> <span class="n">VariableElimination</span><span class="p">(</span><span class="n">model_reduced</span><span class="p">)</span>
            <span class="n">reduced_ve</span><span class="o">.</span><span class="n">_initialize_structures</span><span class="p">()</span>

            <span class="c1"># Step 5.2: Do the actual variable elimination</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">reduced_ve</span><span class="o">.</span><span class="n">_variable_elimination</span><span class="p">(</span>
                <span class="n">variables</span><span class="o">=</span><span class="n">variables</span><span class="p">,</span>
                <span class="n">operation</span><span class="o">=</span><span class="s2">&quot;marginalize&quot;</span><span class="p">,</span>
                <span class="n">evidence</span><span class="o">=</span><span class="n">evidence</span><span class="p">,</span>
                <span class="n">elimination_order</span><span class="o">=</span><span class="n">elimination_order</span><span class="p">,</span>
                <span class="n">joint</span><span class="o">=</span><span class="n">joint</span><span class="p">,</span>
                <span class="n">show_progress</span><span class="o">=</span><span class="n">show_progress</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="VariableElimination.max_marginal">
<a class="viewcode-back" href="../../../infer/ve.html#pgmpy.inference.ExactInference.VariableElimination.max_marginal">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">max_marginal</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">variables</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">evidence</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">elimination_order</span><span class="o">=</span><span class="s2">&quot;MinFill&quot;</span><span class="p">,</span>
        <span class="n">show_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the max-marginal over the variables given the evidence.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variables: list</span>
<span class="sd">            list of variables over which we want to compute the max-marginal.</span>

<span class="sd">        evidence: dict</span>
<span class="sd">            a dict key, value pair as {var: state_of_var_observed}</span>
<span class="sd">            None if no evidence</span>

<span class="sd">        elimination_order: list</span>
<span class="sd">            order of variable eliminations (if nothing is provided) order is</span>
<span class="sd">            computed automatically</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.inference import VariableElimination</span>
<span class="sd">        &gt;&gt;&gt; values = pd.DataFrame(</span>
<span class="sd">        ...     np.random.randint(low=0, high=2, size=(1000, 5)),</span>
<span class="sd">        ...     columns=[&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;],</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; model = DiscreteBayesianNetwork(</span>
<span class="sd">        ...     [(&quot;A&quot;, &quot;B&quot;), (&quot;C&quot;, &quot;B&quot;), (&quot;C&quot;, &quot;D&quot;), (&quot;B&quot;, &quot;E&quot;)]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; model.fit(values)</span>
<span class="sd">        &gt;&gt;&gt; inference = VariableElimination(model)</span>
<span class="sd">        &gt;&gt;&gt; phi_query = inference.max_marginal([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">variables</span><span class="p">:</span>
            <span class="n">variables</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">common_vars</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">evidence</span> <span class="k">if</span> <span class="n">evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[])</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span>
            <span class="nb">set</span><span class="p">(</span><span class="n">variables</span> <span class="k">if</span> <span class="n">variables</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[])</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">common_vars</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Can&#39;t have the same variables in both `variables` and `evidence`. Found in both: </span><span class="si">{</span><span class="n">common_vars</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">DiscreteBayesianNetwork</span><span class="p">):</span>
            <span class="n">model_reduced</span><span class="p">,</span> <span class="n">evidence</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prune_bayesian_model</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="n">evidence</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model_reduced</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span>

        <span class="n">reduced_ve</span> <span class="o">=</span> <span class="n">VariableElimination</span><span class="p">(</span><span class="n">model_reduced</span><span class="p">)</span>
        <span class="n">reduced_ve</span><span class="o">.</span><span class="n">_initialize_structures</span><span class="p">()</span>

        <span class="n">final_distribution</span> <span class="o">=</span> <span class="n">reduced_ve</span><span class="o">.</span><span class="n">_variable_elimination</span><span class="p">(</span>
            <span class="n">variables</span><span class="o">=</span><span class="n">variables</span><span class="p">,</span>
            <span class="n">operation</span><span class="o">=</span><span class="s2">&quot;maximize&quot;</span><span class="p">,</span>
            <span class="n">evidence</span><span class="o">=</span><span class="n">evidence</span><span class="p">,</span>
            <span class="n">elimination_order</span><span class="o">=</span><span class="n">elimination_order</span><span class="p">,</span>
            <span class="n">show_progress</span><span class="o">=</span><span class="n">show_progress</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">compat_fns</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">final_distribution</span><span class="o">.</span><span class="n">values</span><span class="p">)</span></div>


<div class="viewcode-block" id="VariableElimination.map_query">
<a class="viewcode-back" href="../../../infer/ve.html#pgmpy.inference.ExactInference.VariableElimination.map_query">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">map_query</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">variables</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">evidence</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">virtual_evidence</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">elimination_order</span><span class="o">=</span><span class="s2">&quot;MinFill&quot;</span><span class="p">,</span>
        <span class="n">show_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the MAP Query over the variables given the evidence. Returns the</span>
<span class="sd">        highest probable state in the joint distribution of `variables`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variables: list</span>
<span class="sd">            list of variables over which we want to compute the max-marginal.</span>

<span class="sd">        evidence: dict</span>
<span class="sd">            a dict key, value pair as {var: state_of_var_observed}</span>
<span class="sd">            None if no evidence</span>

<span class="sd">        virtual_evidence: list (default:None)</span>
<span class="sd">            A list of pgmpy.factors.discrete.TabularCPD representing the virtual</span>
<span class="sd">            evidences.</span>

<span class="sd">        elimination_order: list</span>
<span class="sd">            order of variable eliminations (if nothing is provided) order is</span>
<span class="sd">            computed automatically</span>

<span class="sd">        show_progress: boolean</span>
<span class="sd">            If True, shows a progress bar.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.inference import VariableElimination</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; values = pd.DataFrame(</span>
<span class="sd">        ...     np.random.randint(low=0, high=2, size=(1000, 5)),</span>
<span class="sd">        ...     columns=[&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;],</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; model = DiscreteBayesianNetwork(</span>
<span class="sd">        ...     [(&quot;A&quot;, &quot;B&quot;), (&quot;C&quot;, &quot;B&quot;), (&quot;C&quot;, &quot;D&quot;), (&quot;B&quot;, &quot;E&quot;)]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; model.fit(values)</span>
<span class="sd">        &gt;&gt;&gt; inference = VariableElimination(model)</span>
<span class="sd">        &gt;&gt;&gt; phi_query = inference.map_query([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">variables</span> <span class="o">=</span> <span class="p">[]</span> <span class="k">if</span> <span class="n">variables</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">variables</span>
        <span class="n">evidence</span> <span class="o">=</span> <span class="n">evidence</span> <span class="k">if</span> <span class="n">evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">common_vars</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">evidence</span> <span class="k">if</span> <span class="n">evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[])</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span>
            <span class="n">variables</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">common_vars</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Can&#39;t have the same variables in both `variables` and `evidence`. Found in both: </span><span class="si">{</span><span class="n">common_vars</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">DiscreteBayesianNetwork</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="n">virtual_evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_virtual_evidence</span><span class="p">(</span><span class="n">virtual_evidence</span><span class="p">)</span>
            <span class="n">virt_evidence</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;__&quot;</span> <span class="o">+</span> <span class="n">cpd</span><span class="o">.</span><span class="n">variables</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="n">virtual_evidence</span><span class="p">}</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_query</span><span class="p">(</span>
                <span class="n">variables</span><span class="o">=</span><span class="n">variables</span><span class="p">,</span>
                <span class="n">evidence</span><span class="o">=</span><span class="p">{</span><span class="o">**</span><span class="n">evidence</span><span class="p">,</span> <span class="o">**</span><span class="n">virt_evidence</span><span class="p">},</span>
                <span class="n">virtual_evidence</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">elimination_order</span><span class="o">=</span><span class="n">elimination_order</span><span class="p">,</span>
                <span class="n">show_progress</span><span class="o">=</span><span class="n">show_progress</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">DiscreteBayesianNetwork</span><span class="p">):</span>
            <span class="n">model_reduced</span><span class="p">,</span> <span class="n">evidence</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prune_bayesian_model</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="n">evidence</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model_reduced</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span>

        <span class="n">reduced_ve</span> <span class="o">=</span> <span class="n">VariableElimination</span><span class="p">(</span><span class="n">model_reduced</span><span class="p">)</span>
        <span class="n">reduced_ve</span><span class="o">.</span><span class="n">_initialize_structures</span><span class="p">()</span>

        <span class="n">final_distribution</span> <span class="o">=</span> <span class="n">reduced_ve</span><span class="o">.</span><span class="n">_variable_elimination</span><span class="p">(</span>
            <span class="n">variables</span><span class="o">=</span><span class="n">variables</span><span class="p">,</span>
            <span class="n">operation</span><span class="o">=</span><span class="s2">&quot;marginalize&quot;</span><span class="p">,</span>
            <span class="n">evidence</span><span class="o">=</span><span class="n">evidence</span><span class="p">,</span>
            <span class="n">elimination_order</span><span class="o">=</span><span class="n">elimination_order</span><span class="p">,</span>
            <span class="n">joint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">show_progress</span><span class="o">=</span><span class="n">show_progress</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">argmax</span> <span class="o">=</span> <span class="n">compat_fns</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">final_distribution</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">assignment</span> <span class="o">=</span> <span class="n">final_distribution</span><span class="o">.</span><span class="n">assignment</span><span class="p">([</span><span class="n">argmax</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">map_query_results</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">var_assignment</span> <span class="ow">in</span> <span class="n">assignment</span><span class="p">:</span>
            <span class="n">var</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="n">var_assignment</span>
            <span class="n">map_query_results</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

        <span class="k">return</span> <span class="n">map_query_results</span></div>


<div class="viewcode-block" id="VariableElimination.induced_graph">
<a class="viewcode-back" href="../../../infer/ve.html#pgmpy.inference.ExactInference.VariableElimination.induced_graph">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">induced_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">elimination_order</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the induced graph formed by running Variable Elimination on the network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        elimination_order: list, array like</span>
<span class="sd">            List of variables in the order in which they are to be eliminated.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.inference import VariableElimination</span>
<span class="sd">        &gt;&gt;&gt; values = pd.DataFrame(</span>
<span class="sd">        ...     np.random.randint(low=0, high=2, size=(1000, 5)),</span>
<span class="sd">        ...     columns=[&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;],</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; model = DiscreteBayesianNetwork(</span>
<span class="sd">        ...     [(&quot;A&quot;, &quot;B&quot;), (&quot;C&quot;, &quot;B&quot;), (&quot;C&quot;, &quot;D&quot;), (&quot;B&quot;, &quot;E&quot;)]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; model.fit(values)</span>
<span class="sd">        &gt;&gt;&gt; inference = VariableElimination(model)</span>
<span class="sd">        &gt;&gt;&gt; inference.induced_graph([&quot;C&quot;, &quot;D&quot;, &quot;A&quot;, &quot;B&quot;, &quot;E&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_structures</span><span class="p">()</span>

        <span class="c1"># If the elimination order does not contain the same variables as the model</span>
        <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">elimination_order</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">variables</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Set of variables in elimination order&quot;</span>
                <span class="s2">&quot; different from variables in model&quot;</span>
            <span class="p">)</span>

        <span class="n">eliminated_variables</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">working_factors</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">node</span><span class="p">:</span> <span class="p">[</span><span class="n">factor</span><span class="o">.</span><span class="n">scope</span><span class="p">()</span> <span class="k">for</span> <span class="n">factor</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">factors</span><span class="p">[</span><span class="n">node</span><span class="p">]]</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">factors</span>
        <span class="p">}</span>

        <span class="c1"># The set of cliques that should be in the induced graph</span>
        <span class="n">cliques</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">factors</span> <span class="ow">in</span> <span class="n">working_factors</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">factor</span> <span class="ow">in</span> <span class="n">factors</span><span class="p">:</span>
                <span class="n">cliques</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">factor</span><span class="p">))</span>

        <span class="c1"># Removing all the factors containing the variables which are</span>
        <span class="c1"># eliminated (as all the factors should be considered only once)</span>
        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">elimination_order</span><span class="p">:</span>
            <span class="n">factors</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">factor</span>
                <span class="k">for</span> <span class="n">factor</span> <span class="ow">in</span> <span class="n">working_factors</span><span class="p">[</span><span class="n">var</span><span class="p">]</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="n">factor</span><span class="p">)</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">eliminated_variables</span><span class="p">)</span>
            <span class="p">]</span>
            <span class="n">phi</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">factors</span><span class="p">))</span><span class="o">.</span><span class="n">difference</span><span class="p">({</span><span class="n">var</span><span class="p">})</span>
            <span class="n">cliques</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">phi</span><span class="p">))</span>
            <span class="k">del</span> <span class="n">working_factors</span><span class="p">[</span><span class="n">var</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">variable</span> <span class="ow">in</span> <span class="n">phi</span><span class="p">:</span>
                <span class="n">working_factors</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">phi</span><span class="p">))</span>
            <span class="n">eliminated_variables</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>

        <span class="n">edges_comb</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">itertools</span><span class="o">.</span><span class="n">combinations</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cliques</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">edges_comb</span><span class="p">))</span></div>


<div class="viewcode-block" id="VariableElimination.induced_width">
<a class="viewcode-back" href="../../../infer/ve.html#pgmpy.inference.ExactInference.VariableElimination.induced_width">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">induced_width</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">elimination_order</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the width (integer) of the induced graph formed by running Variable Elimination on the network.</span>
<span class="sd">        The width is the defined as the number of nodes in the largest clique in the graph minus 1.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        elimination_order: list, array like</span>
<span class="sd">            List of variables in the order in which they are to be eliminated.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.inference import VariableElimination</span>
<span class="sd">        &gt;&gt;&gt; values = pd.DataFrame(</span>
<span class="sd">        ...     np.random.randint(low=0, high=2, size=(1000, 5)),</span>
<span class="sd">        ...     columns=[&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;],</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; model = DiscreteBayesianNetwork(</span>
<span class="sd">        ...     [(&quot;A&quot;, &quot;B&quot;), (&quot;C&quot;, &quot;B&quot;), (&quot;C&quot;, &quot;D&quot;), (&quot;B&quot;, &quot;E&quot;)]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; model.fit(values)</span>
<span class="sd">        &gt;&gt;&gt; inference = VariableElimination(model)</span>
<span class="sd">        &gt;&gt;&gt; inference.induced_width([&quot;C&quot;, &quot;D&quot;, &quot;A&quot;, &quot;B&quot;, &quot;E&quot;])</span>
<span class="sd">        3</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">induced_graph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">induced_graph</span><span class="p">(</span><span class="n">elimination_order</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">max</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">clique</span><span class="p">)</span> <span class="k">for</span> <span class="n">clique</span> <span class="ow">in</span> <span class="n">nx</span><span class="o">.</span><span class="n">find_cliques</span><span class="p">(</span><span class="n">induced_graph</span><span class="p">)))</span> <span class="o">-</span> <span class="mi">1</span></div>
</div>



<div class="viewcode-block" id="BeliefPropagation">
<a class="viewcode-back" href="../../../infer/bp.html#pgmpy.inference.ExactInference.BeliefPropagation">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BeliefPropagation</span><span class="p">(</span><span class="n">Inference</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class for performing inference using Belief Propagation method.</span>

<span class="sd">    Creates a Junction Tree or Clique Tree (JunctionTree class) for the input</span>
<span class="sd">    probabilistic graphical model and performs calibration of the junction tree</span>
<span class="sd">    so formed using belief propagation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model: DiscreteBayesianNetwork, DiscreteMarkovNetwork, FactorGraph, JunctionTree</span>
<span class="sd">        model for which inference is to performed</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BeliefPropagation</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">JunctionTree</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">junction_tree</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to_junction_tree</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">junction_tree</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">clique_beliefs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sepset_beliefs</span> <span class="o">=</span> <span class="p">{}</span>

<div class="viewcode-block" id="BeliefPropagation.get_cliques">
<a class="viewcode-back" href="../../../infer/bp.html#pgmpy.inference.ExactInference.BeliefPropagation.get_cliques">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_cliques</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns cliques used for belief propagation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">junction_tree</span><span class="o">.</span><span class="n">nodes</span><span class="p">()</span></div>


<div class="viewcode-block" id="BeliefPropagation.get_clique_beliefs">
<a class="viewcode-back" href="../../../infer/bp.html#pgmpy.inference.ExactInference.BeliefPropagation.get_clique_beliefs">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_clique_beliefs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns clique beliefs. Should be called after the clique tree (or</span>
<span class="sd">        junction tree) is calibrated.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">clique_beliefs</span></div>


<div class="viewcode-block" id="BeliefPropagation.get_sepset_beliefs">
<a class="viewcode-back" href="../../../infer/bp.html#pgmpy.inference.ExactInference.BeliefPropagation.get_sepset_beliefs">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_sepset_beliefs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns sepset beliefs. Should be called after clique tree (or junction</span>
<span class="sd">        tree) is calibrated.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sepset_beliefs</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_update_beliefs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sending_clique</span><span class="p">,</span> <span class="n">receiving_clique</span><span class="p">,</span> <span class="n">operation</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This is belief-update method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        sending_clique: node (as the operation is on junction tree, node should be a tuple)</span>
<span class="sd">            Node sending the message</span>

<span class="sd">        receiving_clique: node (as the operation is on junction tree, node should be a tuple)</span>
<span class="sd">            Node receiving the message</span>

<span class="sd">        operation: str (&#39;marginalize&#39; | &#39;maximize&#39;)</span>
<span class="sd">            The operation to do for passing messages between nodes.</span>

<span class="sd">        Takes belief of one clique and uses it to update the belief of the</span>
<span class="sd">        neighboring ones.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sepset</span> <span class="o">=</span> <span class="nb">frozenset</span><span class="p">(</span><span class="n">sending_clique</span><span class="p">)</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="nb">frozenset</span><span class="p">(</span><span class="n">receiving_clique</span><span class="p">))</span>
        <span class="n">sepset_key</span> <span class="o">=</span> <span class="nb">frozenset</span><span class="p">((</span><span class="n">sending_clique</span><span class="p">,</span> <span class="n">receiving_clique</span><span class="p">))</span>

        <span class="c1"># \sigma_{i \rightarrow j} = \sum_{C_i - S_{i, j}} \beta_i</span>
        <span class="c1"># marginalize the clique over the sepset</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clique_beliefs</span><span class="p">[</span><span class="n">sending_clique</span><span class="p">],</span> <span class="n">operation</span><span class="p">)(</span>
            <span class="nb">list</span><span class="p">(</span><span class="nb">frozenset</span><span class="p">(</span><span class="n">sending_clique</span><span class="p">)</span> <span class="o">-</span> <span class="n">sepset</span><span class="p">),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="c1"># \beta_j = \beta_j * \frac{\sigma_{i \rightarrow j}}{\mu_{i, j}}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clique_beliefs</span><span class="p">[</span><span class="n">receiving_clique</span><span class="p">]</span> <span class="o">*=</span> <span class="p">(</span>
            <span class="n">sigma</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">sepset_beliefs</span><span class="p">[</span><span class="n">sepset_key</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sepset_beliefs</span><span class="p">[</span><span class="n">sepset_key</span><span class="p">]</span>
            <span class="k">else</span> <span class="n">sigma</span>
        <span class="p">)</span>

        <span class="c1"># \mu_{i, j} = \sigma_{i \rightarrow j}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sepset_beliefs</span><span class="p">[</span><span class="n">sepset_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">sigma</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_is_converged</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">operation</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks whether the calibration has converged or not. At convergence</span>
<span class="sd">        the sepset belief would be precisely the sepset marginal.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        operation: str (&#39;marginalize&#39; | &#39;maximize&#39;)</span>
<span class="sd">            The operation to do for passing messages between nodes.</span>
<span class="sd">            if operation == marginalize, it checks whether the junction tree is calibrated or not</span>
<span class="sd">            else if operation == maximize, it checks whether the junction tree is max calibrated or not</span>

<span class="sd">        Formally, at convergence or at calibration this condition would be satisfied for</span>

<span class="sd">        .. math:: \sum_{C_i - S_{i, j}} \beta_i = \sum_{C_j - S_{i, j}} \beta_j = \mu_{i, j}</span>

<span class="sd">        and at max calibration this condition would be satisfied</span>

<span class="sd">        .. math:: \max_{C_i - S_{i, j}} \beta_i = \max_{C_j - S_{i, j}} \beta_j = \mu_{i, j}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># If no clique belief, then the clique tree is not calibrated</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">clique_beliefs</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">junction_tree</span><span class="o">.</span><span class="n">edges</span><span class="p">():</span>
            <span class="n">sepset</span> <span class="o">=</span> <span class="nb">frozenset</span><span class="p">(</span><span class="n">edge</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="nb">frozenset</span><span class="p">(</span><span class="n">edge</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">sepset_key</span> <span class="o">=</span> <span class="nb">frozenset</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">edge</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">clique_beliefs</span>
                <span class="ow">or</span> <span class="n">edge</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">clique_beliefs</span>
                <span class="ow">or</span> <span class="n">sepset_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">sepset_beliefs</span>
            <span class="p">):</span>
                <span class="k">return</span> <span class="kc">False</span>

            <span class="n">marginal_1</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clique_beliefs</span><span class="p">[</span><span class="n">edge</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">operation</span><span class="p">)(</span>
                <span class="nb">list</span><span class="p">(</span><span class="nb">frozenset</span><span class="p">(</span><span class="n">edge</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="n">sepset</span><span class="p">),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="n">marginal_2</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clique_beliefs</span><span class="p">[</span><span class="n">edge</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">operation</span><span class="p">)(</span>
                <span class="nb">list</span><span class="p">(</span><span class="nb">frozenset</span><span class="p">(</span><span class="n">edge</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="n">sepset</span><span class="p">),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">marginal_1</span> <span class="o">!=</span> <span class="n">marginal_2</span>
                <span class="ow">or</span> <span class="n">marginal_1</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sepset_beliefs</span><span class="p">[</span><span class="n">sepset_key</span><span class="p">]</span>
            <span class="p">):</span>
                <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_calibrate_junction_tree</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">operation</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generalized calibration of junction tree or clique using belief propagation. This method can be used for both</span>
<span class="sd">        calibrating as well as max-calibrating.</span>
<span class="sd">        Uses Lauritzen-Spiegelhalter algorithm or belief-update message passing.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        operation: str (&#39;marginalize&#39; | &#39;maximize&#39;)</span>
<span class="sd">            The operation to do for passing messages between nodes.</span>

<span class="sd">        Reference</span>
<span class="sd">        ---------</span>
<span class="sd">        Algorithm 10.3 Calibration using belief propagation in clique tree</span>
<span class="sd">        Probabilistic Graphical Models: Principles and Techniques</span>
<span class="sd">        Daphne Koller and Nir Friedman.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Initialize clique beliefs as well as sepset beliefs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clique_beliefs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">clique</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">junction_tree</span><span class="o">.</span><span class="n">get_factors</span><span class="p">(</span><span class="n">clique</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">clique</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">junction_tree</span><span class="o">.</span><span class="n">nodes</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sepset_beliefs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="nb">frozenset</span><span class="p">(</span><span class="n">edge</span><span class="p">):</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">junction_tree</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>
        <span class="p">}</span>

        <span class="k">for</span> <span class="n">clique</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">junction_tree</span><span class="o">.</span><span class="n">nodes</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_converged</span><span class="p">(</span><span class="n">operation</span><span class="o">=</span><span class="n">operation</span><span class="p">):</span>
                <span class="n">neighbors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">junction_tree</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">clique</span><span class="p">)</span>
                <span class="c1"># update root&#39;s belief using neighbor clique&#39;s beliefs</span>
                <span class="c1"># upward pass</span>
                <span class="k">for</span> <span class="n">neighbor_clique</span> <span class="ow">in</span> <span class="n">neighbors</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_update_beliefs</span><span class="p">(</span><span class="n">neighbor_clique</span><span class="p">,</span> <span class="n">clique</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="n">operation</span><span class="p">)</span>
                <span class="n">bfs_edges</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">algorithms</span><span class="o">.</span><span class="n">breadth_first_search</span><span class="o">.</span><span class="n">bfs_edges</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">junction_tree</span><span class="p">,</span> <span class="n">clique</span>
                <span class="p">)</span>
                <span class="c1"># update the beliefs of all the nodes starting from the root to leaves using root&#39;s belief</span>
                <span class="c1"># downward pass</span>
                <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">bfs_edges</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_update_beliefs</span><span class="p">(</span><span class="n">edge</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">edge</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">operation</span><span class="o">=</span><span class="n">operation</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">break</span>

<div class="viewcode-block" id="BeliefPropagation.calibrate">
<a class="viewcode-back" href="../../../infer/bp.html#pgmpy.inference.ExactInference.BeliefPropagation.calibrate">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">calibrate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calibration using belief propagation in junction tree or clique tree.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.discrete import TabularCPD</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.inference import BeliefPropagation</span>
<span class="sd">        &gt;&gt;&gt; G = DiscreteBayesianNetwork(</span>
<span class="sd">        ...     [</span>
<span class="sd">        ...         (&quot;diff&quot;, &quot;grade&quot;),</span>
<span class="sd">        ...         (&quot;intel&quot;, &quot;grade&quot;),</span>
<span class="sd">        ...         (&quot;intel&quot;, &quot;SAT&quot;),</span>
<span class="sd">        ...         (&quot;grade&quot;, &quot;letter&quot;),</span>
<span class="sd">        ...     ]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; diff_cpd = TabularCPD(&quot;diff&quot;, 2, [[0.2], [0.8]])</span>
<span class="sd">        &gt;&gt;&gt; intel_cpd = TabularCPD(&quot;intel&quot;, 3, [[0.5], [0.3], [0.2]])</span>
<span class="sd">        &gt;&gt;&gt; grade_cpd = TabularCPD(</span>
<span class="sd">        ...     &quot;grade&quot;,</span>
<span class="sd">        ...     3,</span>
<span class="sd">        ...     [</span>
<span class="sd">        ...         [0.1, 0.1, 0.1, 0.1, 0.1, 0.1],</span>
<span class="sd">        ...         [0.1, 0.1, 0.1, 0.1, 0.1, 0.1],</span>
<span class="sd">        ...         [0.8, 0.8, 0.8, 0.8, 0.8, 0.8],</span>
<span class="sd">        ...     ],</span>
<span class="sd">        ...     evidence=[&quot;diff&quot;, &quot;intel&quot;],</span>
<span class="sd">        ...     evidence_card=[2, 3],</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; sat_cpd = TabularCPD(</span>
<span class="sd">        ...     &quot;SAT&quot;,</span>
<span class="sd">        ...     2,</span>
<span class="sd">        ...     [[0.1, 0.2, 0.7], [0.9, 0.8, 0.3]],</span>
<span class="sd">        ...     evidence=[&quot;intel&quot;],</span>
<span class="sd">        ...     evidence_card=[3],</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; letter_cpd = TabularCPD(</span>
<span class="sd">        ...     &quot;letter&quot;,</span>
<span class="sd">        ...     2,</span>
<span class="sd">        ...     [[0.1, 0.4, 0.8], [0.9, 0.6, 0.2]],</span>
<span class="sd">        ...     evidence=[&quot;grade&quot;],</span>
<span class="sd">        ...     evidence_card=[3],</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; G.add_cpds(diff_cpd, intel_cpd, grade_cpd, sat_cpd, letter_cpd)</span>
<span class="sd">        &gt;&gt;&gt; bp = BeliefPropagation(G)</span>
<span class="sd">        &gt;&gt;&gt; bp.calibrate()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_calibrate_junction_tree</span><span class="p">(</span><span class="n">operation</span><span class="o">=</span><span class="s2">&quot;marginalize&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="BeliefPropagation.max_calibrate">
<a class="viewcode-back" href="../../../infer/bp.html#pgmpy.inference.ExactInference.BeliefPropagation.max_calibrate">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">max_calibrate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Max-calibration of the junction tree using belief propagation.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.discrete import TabularCPD</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.inference import BeliefPropagation</span>
<span class="sd">        &gt;&gt;&gt; G = DiscreteBayesianNetwork(</span>
<span class="sd">        ...     [</span>
<span class="sd">        ...         (&quot;diff&quot;, &quot;grade&quot;),</span>
<span class="sd">        ...         (&quot;intel&quot;, &quot;grade&quot;),</span>
<span class="sd">        ...         (&quot;intel&quot;, &quot;SAT&quot;),</span>
<span class="sd">        ...         (&quot;grade&quot;, &quot;letter&quot;),</span>
<span class="sd">        ...     ]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; diff_cpd = TabularCPD(&quot;diff&quot;, 2, [[0.2], [0.8]])</span>
<span class="sd">        &gt;&gt;&gt; intel_cpd = TabularCPD(&quot;intel&quot;, 3, [[0.5], [0.3], [0.2]])</span>
<span class="sd">        &gt;&gt;&gt; grade_cpd = TabularCPD(</span>
<span class="sd">        ...     &quot;grade&quot;,</span>
<span class="sd">        ...     3,</span>
<span class="sd">        ...     [</span>
<span class="sd">        ...         [0.1, 0.1, 0.1, 0.1, 0.1, 0.1],</span>
<span class="sd">        ...         [0.1, 0.1, 0.1, 0.1, 0.1, 0.1],</span>
<span class="sd">        ...         [0.8, 0.8, 0.8, 0.8, 0.8, 0.8],</span>
<span class="sd">        ...     ],</span>
<span class="sd">        ...     evidence=[&quot;diff&quot;, &quot;intel&quot;],</span>
<span class="sd">        ...     evidence_card=[2, 3],</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; sat_cpd = TabularCPD(</span>
<span class="sd">        ...     &quot;SAT&quot;,</span>
<span class="sd">        ...     2,</span>
<span class="sd">        ...     [[0.1, 0.2, 0.7], [0.9, 0.8, 0.3]],</span>
<span class="sd">        ...     evidence=[&quot;intel&quot;],</span>
<span class="sd">        ...     evidence_card=[3],</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; letter_cpd = TabularCPD(</span>
<span class="sd">        ...     &quot;letter&quot;,</span>
<span class="sd">        ...     2,</span>
<span class="sd">        ...     [[0.1, 0.4, 0.8], [0.9, 0.6, 0.2]],</span>
<span class="sd">        ...     evidence=[&quot;grade&quot;],</span>
<span class="sd">        ...     evidence_card=[3],</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; G.add_cpds(diff_cpd, intel_cpd, grade_cpd, sat_cpd, letter_cpd)</span>
<span class="sd">        &gt;&gt;&gt; bp = BeliefPropagation(G)</span>
<span class="sd">        &gt;&gt;&gt; bp.max_calibrate()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_calibrate_junction_tree</span><span class="p">(</span><span class="n">operation</span><span class="o">=</span><span class="s2">&quot;maximize&quot;</span><span class="p">)</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_query</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">variables</span><span class="p">,</span> <span class="n">operation</span><span class="p">,</span> <span class="n">evidence</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">joint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_progress</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This is a generalized query method that can be used for both query and map query.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variables: list</span>
<span class="sd">            list of variables for which you want to compute the probability</span>
<span class="sd">        operation: str (&#39;marginalize&#39; | &#39;maximize&#39;)</span>
<span class="sd">            The operation to do for passing messages between nodes.</span>
<span class="sd">        evidence: dict</span>
<span class="sd">            a dict key, value pair as {var: state_of_var_observed}</span>
<span class="sd">            None if no evidence</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.inference import BeliefPropagation</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; values = pd.DataFrame(</span>
<span class="sd">        ...     np.random.randint(low=0, high=2, size=(1000, 5)),</span>
<span class="sd">        ...     columns=[&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;],</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; model = DiscreteBayesianNetwork(</span>
<span class="sd">        ...     [(&quot;A&quot;, &quot;B&quot;), (&quot;C&quot;, &quot;B&quot;), (&quot;C&quot;, &quot;D&quot;), (&quot;B&quot;, &quot;E&quot;)]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; model.fit(values)</span>
<span class="sd">        &gt;&gt;&gt; inference = BeliefPropagation(model)</span>
<span class="sd">        &gt;&gt;&gt; phi_query = inference.query([&quot;A&quot;, &quot;B&quot;])</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        Algorithm 10.4 Out-of-clique inference in clique tree</span>
<span class="sd">        Probabilistic Graphical Models: Principles and Techniques Daphne Koller and Nir Friedman.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">is_calibrated</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_converged</span><span class="p">(</span><span class="n">operation</span><span class="o">=</span><span class="n">operation</span><span class="p">)</span>
        <span class="c1"># Calibrate the junction tree if not calibrated</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_calibrated</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">calibrate</span><span class="p">()</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="nb">set</span><span class="p">)):</span>
            <span class="n">query_variables</span> <span class="o">=</span> <span class="p">[</span><span class="n">variables</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">query_variables</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span>
        <span class="n">query_variables</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">evidence</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">evidence</span> <span class="k">else</span> <span class="p">[])</span>

        <span class="c1"># Find a tree T&#39; such that query_variables are a subset of scope(T&#39;)</span>
        <span class="n">nodes_with_query_variables</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">query_variables</span><span class="p">:</span>
            <span class="n">nodes_with_query_variables</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">junction_tree</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
            <span class="p">)</span>
        <span class="n">subtree_nodes</span> <span class="o">=</span> <span class="n">nodes_with_query_variables</span>

        <span class="c1"># Conversion of set to tuple just for indexing</span>
        <span class="n">nodes_with_query_variables</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">nodes_with_query_variables</span><span class="p">)</span>
        <span class="c1"># As junction tree is a tree, that means that there would be only path between any two nodes in the tree</span>
        <span class="c1"># thus we can just take the path between any two nodes; no matter there order is</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">nodes_with_query_variables</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">subtree_nodes</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="n">nx</span><span class="o">.</span><span class="n">shortest_path</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">junction_tree</span><span class="p">,</span>
                    <span class="n">nodes_with_query_variables</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="n">nodes_with_query_variables</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="n">subtree_undirected_graph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">junction_tree</span><span class="o">.</span><span class="n">subgraph</span><span class="p">(</span><span class="n">subtree_nodes</span><span class="p">)</span>
        <span class="c1"># Converting subtree into a junction tree</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">subtree_nodes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">subtree</span> <span class="o">=</span> <span class="n">JunctionTree</span><span class="p">()</span>
            <span class="n">subtree</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">subtree_nodes</span><span class="o">.</span><span class="n">pop</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">subtree</span> <span class="o">=</span> <span class="n">JunctionTree</span><span class="p">(</span><span class="n">subtree_undirected_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">())</span>

        <span class="c1"># Selecting a node is root node. Root node would be having only one neighbor</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">subtree</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">root_node</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">subtree</span><span class="o">.</span><span class="n">nodes</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">root_node</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
                <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">subtree</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">subtree</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
            <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">clique_potential_list</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">clique_beliefs</span><span class="p">[</span><span class="n">root_node</span><span class="p">]]</span>

        <span class="c1"># For other nodes in the subtree compute the clique potentials as follows</span>
        <span class="c1"># As all the nodes are nothing but tuples so simple set(root_node) won&#39;t work at it would update the set with</span>
        <span class="c1"># all the elements of the tuple; instead use set([root_node]) as it would include only the tuple not the</span>
        <span class="c1"># internal elements within it.</span>
        <span class="n">parent_nodes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="n">root_node</span><span class="p">])</span>
        <span class="n">nodes_traversed</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">while</span> <span class="n">parent_nodes</span><span class="p">:</span>
            <span class="n">parent_node</span> <span class="o">=</span> <span class="n">parent_nodes</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">child_node</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">subtree</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">parent_node</span><span class="p">))</span> <span class="o">-</span> <span class="n">nodes_traversed</span><span class="p">:</span>
                <span class="n">clique_potential_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">clique_beliefs</span><span class="p">[</span><span class="n">child_node</span><span class="p">]</span>
                    <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">sepset_beliefs</span><span class="p">[</span><span class="nb">frozenset</span><span class="p">([</span><span class="n">parent_node</span><span class="p">,</span> <span class="n">child_node</span><span class="p">])]</span>
                <span class="p">)</span>
                <span class="n">parent_nodes</span><span class="o">.</span><span class="n">update</span><span class="p">([</span><span class="n">child_node</span><span class="p">])</span>
            <span class="n">nodes_traversed</span><span class="o">.</span><span class="n">update</span><span class="p">([</span><span class="n">parent_node</span><span class="p">])</span>

        <span class="c1"># Add factors to the corresponding junction tree</span>
        <span class="n">subtree</span><span class="o">.</span><span class="n">add_factors</span><span class="p">(</span><span class="o">*</span><span class="n">clique_potential_list</span><span class="p">)</span>

        <span class="c1"># Sum product variable elimination on the subtree</span>
        <span class="n">variable_elimination</span> <span class="o">=</span> <span class="n">VariableElimination</span><span class="p">(</span><span class="n">subtree</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;marginalize&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">variable_elimination</span><span class="o">.</span><span class="n">query</span><span class="p">(</span>
                <span class="n">variables</span><span class="o">=</span><span class="n">variables</span><span class="p">,</span>
                <span class="n">evidence</span><span class="o">=</span><span class="n">evidence</span><span class="p">,</span>
                <span class="n">joint</span><span class="o">=</span><span class="n">joint</span><span class="p">,</span>
                <span class="n">show_progress</span><span class="o">=</span><span class="n">show_progress</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;maximize&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">variable_elimination</span><span class="o">.</span><span class="n">map_query</span><span class="p">(</span>
                <span class="n">variables</span><span class="o">=</span><span class="n">variables</span><span class="p">,</span> <span class="n">evidence</span><span class="o">=</span><span class="n">evidence</span><span class="p">,</span> <span class="n">show_progress</span><span class="o">=</span><span class="n">show_progress</span>
            <span class="p">)</span>

<div class="viewcode-block" id="BeliefPropagation.query">
<a class="viewcode-back" href="../../../infer/bp.html#pgmpy.inference.ExactInference.BeliefPropagation.query">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">query</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">variables</span><span class="p">,</span>
        <span class="n">evidence</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">virtual_evidence</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">joint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">show_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Query method using belief propagation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variables: list</span>
<span class="sd">            list of variables for which you want to compute the probability</span>

<span class="sd">        evidence: dict</span>
<span class="sd">            a dict key, value pair as {var: state_of_var_observed}</span>
<span class="sd">            None if no evidence</span>

<span class="sd">        virtual_evidence: list (default:None)</span>
<span class="sd">            A list of pgmpy.factors.discrete.TabularCPD representing the virtual</span>
<span class="sd">            evidences.</span>

<span class="sd">        joint: boolean</span>
<span class="sd">            If True, returns a Joint Distribution over `variables`.</span>
<span class="sd">            If False, returns a dict of distributions over each of the `variables`.</span>

<span class="sd">        show_progress: boolean</span>
<span class="sd">            If True shows a progress bar.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.discrete import TabularCPD</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.inference import BeliefPropagation</span>
<span class="sd">        &gt;&gt;&gt; bayesian_model = DiscreteBayesianNetwork(</span>
<span class="sd">        ...     [(&quot;A&quot;, &quot;J&quot;), (&quot;R&quot;, &quot;J&quot;), (&quot;J&quot;, &quot;Q&quot;), (&quot;J&quot;, &quot;L&quot;), (&quot;G&quot;, &quot;L&quot;)]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; cpd_a = TabularCPD(&quot;A&quot;, 2, [[0.2], [0.8]])</span>
<span class="sd">        &gt;&gt;&gt; cpd_r = TabularCPD(&quot;R&quot;, 2, [[0.4], [0.6]])</span>
<span class="sd">        &gt;&gt;&gt; cpd_j = TabularCPD(</span>
<span class="sd">        ...     &quot;J&quot;, 2, [[0.9, 0.6, 0.7, 0.1], [0.1, 0.4, 0.3, 0.9]], [&quot;R&quot;, &quot;A&quot;], [2, 2]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; cpd_q = TabularCPD(&quot;Q&quot;, 2, [[0.9, 0.2], [0.1, 0.8]], [&quot;J&quot;], [2])</span>
<span class="sd">        &gt;&gt;&gt; cpd_l = TabularCPD(</span>
<span class="sd">        ...     &quot;L&quot;,</span>
<span class="sd">        ...     2,</span>
<span class="sd">        ...     [[0.9, 0.45, 0.8, 0.1], [0.1, 0.55, 0.2, 0.9]],</span>
<span class="sd">        ...     [&quot;G&quot;, &quot;J&quot;],</span>
<span class="sd">        ...     [2, 2],</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; cpd_g = TabularCPD(&quot;G&quot;, 2, [[0.6], [0.4]])</span>
<span class="sd">        &gt;&gt;&gt; bayesian_model.add_cpds(cpd_a, cpd_r, cpd_j, cpd_q, cpd_l, cpd_g)</span>
<span class="sd">        &gt;&gt;&gt; belief_propagation = BeliefPropagation(bayesian_model)</span>
<span class="sd">        &gt;&gt;&gt; belief_propagation.query(</span>
<span class="sd">        ...     variables=[&quot;J&quot;, &quot;Q&quot;], evidence={&quot;A&quot;: 0, &quot;R&quot;: 0, &quot;G&quot;: 0, &quot;L&quot;: 1}</span>
<span class="sd">        ... )</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">evidence</span> <span class="o">=</span> <span class="n">evidence</span> <span class="k">if</span> <span class="n">evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">orig_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># Step 1: Parameter Checks</span>
        <span class="n">common_vars</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">evidence</span> <span class="k">if</span> <span class="n">evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[])</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span>
            <span class="nb">set</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">common_vars</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Can&#39;t have the same variables in both `variables` and `evidence`. Found in both: </span><span class="si">{</span><span class="n">common_vars</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Step 2: If virtual_evidence is provided, modify model and evidence.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">DiscreteBayesianNetwork</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="n">virtual_evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_virtual_evidence</span><span class="p">(</span><span class="n">virtual_evidence</span><span class="p">)</span>
            <span class="n">virt_evidence</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;__&quot;</span> <span class="o">+</span> <span class="n">cpd</span><span class="o">.</span><span class="n">variables</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="n">virtual_evidence</span><span class="p">}</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">query</span><span class="p">(</span>
                <span class="n">variables</span><span class="o">=</span><span class="n">variables</span><span class="p">,</span>
                <span class="n">evidence</span><span class="o">=</span><span class="p">{</span><span class="o">**</span><span class="n">evidence</span><span class="p">,</span> <span class="o">**</span><span class="n">virt_evidence</span><span class="p">},</span>
                <span class="n">virtual_evidence</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">joint</span><span class="o">=</span><span class="n">joint</span><span class="p">,</span>
                <span class="n">show_progress</span><span class="o">=</span><span class="n">show_progress</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Step 3: Do network pruning.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">DiscreteBayesianNetwork</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">evidence</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prune_bayesian_model</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="n">evidence</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_structures</span><span class="p">()</span>

        <span class="c1"># Step 4: Run inference.</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_query</span><span class="p">(</span>
            <span class="n">variables</span><span class="o">=</span><span class="n">variables</span><span class="p">,</span>
            <span class="n">operation</span><span class="o">=</span><span class="s2">&quot;marginalize&quot;</span><span class="p">,</span>
            <span class="n">evidence</span><span class="o">=</span><span class="n">evidence</span><span class="p">,</span>
            <span class="n">joint</span><span class="o">=</span><span class="n">joint</span><span class="p">,</span>
            <span class="n">show_progress</span><span class="o">=</span><span class="n">show_progress</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">orig_model</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">joint</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="BeliefPropagation.map_query">
<a class="viewcode-back" href="../../../infer/bp.html#pgmpy.inference.ExactInference.BeliefPropagation.map_query">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">map_query</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">variables</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">evidence</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">virtual_evidence</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">show_progress</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        MAP Query method using belief propagation. Returns the highest probable</span>
<span class="sd">        state in the joint distributon of `variables`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variables: list</span>
<span class="sd">            list of variables for which you want to compute the probability</span>

<span class="sd">        virtual_evidence: list (default:None)</span>
<span class="sd">            A list of pgmpy.factors.discrete.TabularCPD representing the virtual</span>
<span class="sd">            evidences.</span>

<span class="sd">        evidence: dict</span>
<span class="sd">            a dict key, value pair as {var: state_of_var_observed}</span>
<span class="sd">            None if no evidence</span>

<span class="sd">        show_progress: boolean</span>
<span class="sd">            If True, shows a progress bar.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.discrete import TabularCPD</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.inference import BeliefPropagation</span>
<span class="sd">        &gt;&gt;&gt; bayesian_model = DiscreteBayesianNetwork(</span>
<span class="sd">        ...     [(&quot;A&quot;, &quot;J&quot;), (&quot;R&quot;, &quot;J&quot;), (&quot;J&quot;, &quot;Q&quot;), (&quot;J&quot;, &quot;L&quot;), (&quot;G&quot;, &quot;L&quot;)]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; cpd_a = TabularCPD(&quot;A&quot;, 2, [[0.2], [0.8]])</span>
<span class="sd">        &gt;&gt;&gt; cpd_r = TabularCPD(&quot;R&quot;, 2, [[0.4], [0.6]])</span>
<span class="sd">        &gt;&gt;&gt; cpd_j = TabularCPD(</span>
<span class="sd">        ...     &quot;J&quot;, 2, [[0.9, 0.6, 0.7, 0.1], [0.1, 0.4, 0.3, 0.9]], [&quot;R&quot;, &quot;A&quot;], [2, 2]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; cpd_q = TabularCPD(&quot;Q&quot;, 2, [[0.9, 0.2], [0.1, 0.8]], [&quot;J&quot;], [2])</span>
<span class="sd">        &gt;&gt;&gt; cpd_l = TabularCPD(</span>
<span class="sd">        ...     &quot;L&quot;,</span>
<span class="sd">        ...     2,</span>
<span class="sd">        ...     [[0.9, 0.45, 0.8, 0.1], [0.1, 0.55, 0.2, 0.9]],</span>
<span class="sd">        ...     [&quot;G&quot;, &quot;J&quot;],</span>
<span class="sd">        ...     [2, 2],</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; cpd_g = TabularCPD(&quot;G&quot;, 2, [[0.6], [0.4]])</span>
<span class="sd">        &gt;&gt;&gt; bayesian_model.add_cpds(cpd_a, cpd_r, cpd_j, cpd_q, cpd_l, cpd_g)</span>
<span class="sd">        &gt;&gt;&gt; belief_propagation = BeliefPropagation(bayesian_model)</span>
<span class="sd">        &gt;&gt;&gt; belief_propagation.map_query(</span>
<span class="sd">        ...     variables=[&quot;J&quot;, &quot;Q&quot;], evidence={&quot;A&quot;: 0, &quot;R&quot;: 0, &quot;G&quot;: 0, &quot;L&quot;: 1}</span>
<span class="sd">        ... )</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">variables</span> <span class="o">=</span> <span class="p">[]</span> <span class="k">if</span> <span class="n">variables</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">variables</span>
        <span class="n">evidence</span> <span class="o">=</span> <span class="n">evidence</span> <span class="k">if</span> <span class="n">evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">common_vars</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">evidence</span> <span class="k">if</span> <span class="n">evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[])</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span>
            <span class="n">variables</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">common_vars</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Can&#39;t have the same variables in both `variables` and `evidence`. Found in both: </span><span class="si">{</span><span class="n">common_vars</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># TODO:Check the note in docstring. Change that behavior to return the joint MAP</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">variables</span><span class="p">:</span>
            <span class="n">variables</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>

        <span class="c1"># Make a copy of the original model and then replace self.model with it later.</span>
        <span class="n">orig_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">DiscreteBayesianNetwork</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="n">virtual_evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_virtual_evidence</span><span class="p">(</span><span class="n">virtual_evidence</span><span class="p">)</span>
            <span class="n">virt_evidence</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;__&quot;</span> <span class="o">+</span> <span class="n">cpd</span><span class="o">.</span><span class="n">variables</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="n">virtual_evidence</span><span class="p">}</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_query</span><span class="p">(</span>
                <span class="n">variables</span><span class="o">=</span><span class="n">variables</span><span class="p">,</span>
                <span class="n">evidence</span><span class="o">=</span><span class="p">{</span><span class="o">**</span><span class="n">evidence</span><span class="p">,</span> <span class="o">**</span><span class="n">virt_evidence</span><span class="p">},</span>
                <span class="n">virtual_evidence</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">show_progress</span><span class="o">=</span><span class="n">show_progress</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">DiscreteBayesianNetwork</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">evidence</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prune_bayesian_model</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="n">evidence</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_structures</span><span class="p">()</span>

        <span class="n">final_distribution</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_query</span><span class="p">(</span>
            <span class="n">variables</span><span class="o">=</span><span class="n">variables</span><span class="p">,</span>
            <span class="n">operation</span><span class="o">=</span><span class="s2">&quot;maximize&quot;</span><span class="p">,</span>
            <span class="n">evidence</span><span class="o">=</span><span class="n">evidence</span><span class="p">,</span>
            <span class="n">joint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">show_progress</span><span class="o">=</span><span class="n">show_progress</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">orig_model</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">final_distribution</span></div>
</div>



<div class="viewcode-block" id="BeliefPropagationWithMessagePassing">
<a class="viewcode-back" href="../../../infer/bp_wmp.html#pgmpy.inference.ExactInference.BeliefPropagationWithMessagePassing">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BeliefPropagationWithMessagePassing</span><span class="p">(</span><span class="n">Inference</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class for performing efficient inference using Belief Propagation method on factor graphs with no loops.</span>

<span class="sd">    The message-passing algorithm recursively parses the factor graph to propagate the</span>
<span class="sd">    model&#39;s beliefs to infer the posterior distribution of the queried variable. The recursion</span>
<span class="sd">    stops when reaching an observed variable or a unobserved root/leaf variable.</span>

<span class="sd">    It does not work for loopy graphs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model: FactorGraph</span>
<span class="sd">        Model on which to run the inference.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Algorithm 2.1 in https://www.mbmlbook.com/LearningSkills_Testing_out_the_model.html</span>
<span class="sd">    by J Winn (Microsoft Research).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">FactorGraph</span><span class="p">,</span> <span class="n">check_model</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> <span class="n">FactorGraph</span>
        <span class="p">),</span> <span class="s2">&quot;Model must be an instance of FactorGraph&quot;</span>
        <span class="k">if</span> <span class="n">check_model</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">check_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="k">class</span><span class="w"> </span><span class="nc">_RecursiveMessageSchedulingQuery</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Private class used in `BeliefPropagationWithMessagePassing.query()` to efficiently</span>
<span class="sd">        manage the message scheduling across the different queried variables, in a recursive way.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Same as in the query method.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">belief_propagation</span><span class="p">,</span>
            <span class="n">variables</span><span class="p">,</span>
            <span class="n">evidence</span><span class="p">,</span>
            <span class="n">virtual_evidence</span><span class="p">,</span>
            <span class="n">get_messages</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bp</span> <span class="o">=</span> <span class="n">belief_propagation</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">variables</span> <span class="o">=</span> <span class="n">variables</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">evidence</span> <span class="o">=</span> <span class="n">evidence</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">virtual_evidence</span> <span class="o">=</span> <span class="n">virtual_evidence</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">all_messages</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">get_messages</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="n">agg_res</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">variable</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">variables</span><span class="p">:</span>
                <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schedule_variable_node_messages</span><span class="p">(</span>
                    <span class="n">variable</span><span class="p">,</span>
                    <span class="n">from_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">agg_res</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span> <span class="o">=</span> <span class="n">DiscreteFactor</span><span class="p">([</span><span class="n">variable</span><span class="p">],</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="p">)],</span> <span class="n">res</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_messages</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">agg_res</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">agg_res</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_messages</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">schedule_variable_node_messages</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">variable</span><span class="p">,</span>
            <span class="n">from_factor</span><span class="p">,</span>
        <span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Returns the message sent by the variable to the factor requesting it.</span>
<span class="sd">            For that, the variable requests the messages coming from its neighbouring</span>
<span class="sd">            factors, except the one making the request.</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            variable: str</span>
<span class="sd">                The variable node from which to compute the outgoing message</span>
<span class="sd">            from_factor: pgmpy.factors.discrete.DiscreteFactor or None.</span>
<span class="sd">                The factor requesting the message, as part of the recursion.</span>
<span class="sd">                None for the first time this function is called.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">variable</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">evidence</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="c1"># Is an observed variable</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">bp</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_point_mass_message</span><span class="p">(</span>
                    <span class="n">variable</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">evidence</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span>
                <span class="p">)</span>

            <span class="n">virtual_messages</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">virtual_evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="ow">and</span> <span class="n">variable</span>
                <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bp</span><span class="o">.</span><span class="n">_get_virtual_evidence_var_list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">virtual_evidence</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="n">virtual_messages</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">cpd</span><span class="o">.</span><span class="n">values</span>
                    <span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">virtual_evidence</span>
                    <span class="k">if</span> <span class="n">cpd</span><span class="o">.</span><span class="n">variables</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">variable</span>
                <span class="p">]</span>

            <span class="n">incoming_factors</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">factor</span>
                <span class="k">for</span> <span class="n">factor</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bp</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">variable</span><span class="p">))</span>
                <span class="k">if</span> <span class="n">factor</span> <span class="o">!=</span> <span class="n">from_factor</span>
            <span class="p">]</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">incoming_factors</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># Is an unobserved leaf variable</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">bp</span><span class="o">.</span><span class="n">calc_variable_node_message</span><span class="p">(</span>
                    <span class="n">variable</span><span class="p">,</span> <span class="p">[]</span> <span class="o">+</span> <span class="n">virtual_messages</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Else, get the incoming messages from all incoming factors</span>
                <span class="n">incoming_messages</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">factor</span> <span class="ow">in</span> <span class="n">incoming_factors</span><span class="p">:</span>
                    <span class="n">incoming_message</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schedule_factor_node_messages</span><span class="p">(</span>
                        <span class="n">factor</span><span class="p">,</span> <span class="n">variable</span>
                    <span class="p">)</span>

                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_messages</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="c1"># Store the message if it&#39;s not already stored</span>
                        <span class="n">factor_node_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">factor</span><span class="o">.</span><span class="n">variables</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">variable</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="k">if</span> <span class="n">factor_node_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_messages</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">all_messages</span><span class="p">[</span><span class="n">factor_node_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">incoming_message</span>

                    <span class="n">incoming_messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">incoming_message</span><span class="p">)</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">bp</span><span class="o">.</span><span class="n">calc_variable_node_message</span><span class="p">(</span>
                    <span class="n">variable</span><span class="p">,</span> <span class="n">incoming_messages</span> <span class="o">+</span> <span class="n">virtual_messages</span>
                <span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">schedule_factor_node_messages</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">factor</span><span class="p">,</span> <span class="n">from_variable</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Returns the message sent from the factor to the variable requesting it.</span>
<span class="sd">            For that, the factor requests the messages coming from its neighbouring</span>
<span class="sd">            variables, except the one making the request.</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            factor: pgmpy.factors.discrete.DiscreteFactor</span>
<span class="sd">                The factor from which we want to compute the outgoing message.</span>
<span class="sd">            from_variable: str</span>
<span class="sd">                The variable requesting the message, as part of the recursion.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">assert</span> <span class="n">from_variable</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;from_var must be specified&quot;</span>

            <span class="n">incoming_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">factor</span><span class="o">.</span><span class="n">variables</span> <span class="k">if</span> <span class="n">var</span> <span class="o">!=</span> <span class="n">from_variable</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">incoming_vars</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># from_var is a root variable. The factor is its prior</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">bp</span><span class="o">.</span><span class="n">calc_factor_node_message</span><span class="p">(</span><span class="n">factor</span><span class="p">,</span> <span class="p">[],</span> <span class="n">from_variable</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Else, get the incoming messages from all incoming variables</span>
                <span class="n">incoming_messages</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">incoming_vars</span><span class="p">:</span>
                    <span class="n">incoming_messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">schedule_variable_node_messages</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">factor</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">bp</span><span class="o">.</span><span class="n">calc_factor_node_message</span><span class="p">(</span>
                    <span class="n">factor</span><span class="p">,</span> <span class="n">incoming_messages</span><span class="p">,</span> <span class="n">from_variable</span>
                <span class="p">)</span>

<div class="viewcode-block" id="BeliefPropagationWithMessagePassing.query">
<a class="viewcode-back" href="../../../infer/bp_wmp.html#pgmpy.inference.ExactInference.BeliefPropagationWithMessagePassing.query">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">query</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">variables</span><span class="p">,</span> <span class="n">evidence</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">virtual_evidence</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">get_messages</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the posterior distributions for each of the queried variable,</span>
<span class="sd">        given the `evidence`, and the `virtual_evidence`. Optionally also returns</span>
<span class="sd">        the computed messages.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variables: list</span>
<span class="sd">            List of variables for which you want to compute the posterior.</span>
<span class="sd">        evidence: dict or None (default: None)</span>
<span class="sd">            A dict key, value pair as {var: state_of_var_observed}.</span>
<span class="sd">            None if no evidence.</span>
<span class="sd">        virtual_evidence: list or None (default: None)</span>
<span class="sd">            A list of pgmpy.factors.discrete.TabularCPD representing the virtual</span>
<span class="sd">            evidences. Each virtual evidence becomes a virtual message that gets added to</span>
<span class="sd">            the list of computed messages incoming to the variable node.</span>
<span class="sd">            None if no virtual evidence.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        If `get_messages` is False, returns a dict of the variables, posterior distributions</span>
<span class="sd">            pairs: {variable: pgmpy.factors.discrete.DiscreteFactor}.</span>
<span class="sd">        If `get_messages` is True, returns:</span>
<span class="sd">            1. A dict of the variables, posterior distributions pairs:</span>
<span class="sd">            {variable: pgmpy.factors.discrete.DiscreteFactor}</span>
<span class="sd">            2. A dict of all messages sent from a factor to a node:</span>
<span class="sd">            {&quot;{pgmpy.factors.discrete.DiscreteFactor.variables} -&gt; variable&quot;: np.array}.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.discrete import DiscreteFactor</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import FactorGraph</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.inference import BeliefPropagation</span>
<span class="sd">        &gt;&gt;&gt; factor_graph = FactorGraph()</span>
<span class="sd">        &gt;&gt;&gt; factor_graph.add_nodes_from([&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;])</span>
<span class="sd">        &gt;&gt;&gt; phi1 = DiscreteFactor([&quot;A&quot;], [2], [0.4, 0.6])</span>
<span class="sd">        &gt;&gt;&gt; phi2 = DiscreteFactor(</span>
<span class="sd">        ...     [&quot;B&quot;, &quot;A&quot;], [3, 2], [[0.2, 0.05], [0.3, 0.15], [0.5, 0.8]]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; phi3 = DiscreteFactor(</span>
<span class="sd">        ...     [&quot;C&quot;, &quot;B&quot;], [2, 3], [[0.4, 0.5, 0.1], [0.6, 0.5, 0.9]]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; phi4 = DiscreteFactor(</span>
<span class="sd">        ...     [&quot;D&quot;, &quot;B&quot;], [3, 3], [[0.1, 0.1, 0.2], [0.3, 0.2, 0.1], [0.6, 0.7, 0.7]]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; factor_graph.add_factors(phi1, phi2, phi3, phi4)</span>
<span class="sd">        &gt;&gt;&gt; factor_graph.add_edges_from(</span>
<span class="sd">        ...     [</span>
<span class="sd">        ...         (phi1, &quot;A&quot;),</span>
<span class="sd">        ...         (&quot;A&quot;, phi2),</span>
<span class="sd">        ...         (phi2, &quot;B&quot;),</span>
<span class="sd">        ...         (&quot;B&quot;, phi3),</span>
<span class="sd">        ...         (phi3, &quot;C&quot;),</span>
<span class="sd">        ...         (&quot;B&quot;, phi4),</span>
<span class="sd">        ...         (phi4, &quot;D&quot;),</span>
<span class="sd">        ...     ]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; belief_propagation = BeliefPropagation(factor_graph)</span>
<span class="sd">        &gt;&gt;&gt; belief_propagation.query(</span>
<span class="sd">        ...     variables=[&quot;B&quot;, &quot;C&quot;],</span>
<span class="sd">        ...     evidence={&quot;D&quot;: 0},</span>
<span class="sd">        ...     virtual_evidence=[TabularCPD([&quot;A&quot;], 2, [[0.3], [0.7]])],</span>
<span class="sd">        ... )</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">common_vars</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">evidence</span> <span class="k">if</span> <span class="n">evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[])</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span>
            <span class="nb">set</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">common_vars</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Can&#39;t have the same variables in both `variables` and `evidence`. Found in both: </span><span class="si">{</span><span class="n">common_vars</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Can&#39;t have the same variables in both `evidence` and `virtual_evidence`</span>
        <span class="k">if</span> <span class="n">evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">virtual_evidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_virtual_evidence</span><span class="p">(</span><span class="n">virtual_evidence</span><span class="p">)</span>
            <span class="n">ve_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_virtual_evidence_var_list</span><span class="p">(</span><span class="n">virtual_evidence</span><span class="p">)</span>
            <span class="n">common_vars</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">evidence</span><span class="p">)</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">ve_names</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">common_vars</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Can&#39;t have the same variables in both `evidence` and &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;`virtual_evidence`. Found in both: </span><span class="si">{</span><span class="n">common_vars</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_RecursiveMessageSchedulingQuery</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">variables</span><span class="p">,</span> <span class="n">evidence</span><span class="p">,</span> <span class="n">virtual_evidence</span><span class="p">,</span> <span class="n">get_messages</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">query</span><span class="o">.</span><span class="n">run</span><span class="p">()</span></div>


<div class="viewcode-block" id="BeliefPropagationWithMessagePassing.calc_variable_node_message">
<a class="viewcode-back" href="../../../infer/bp_wmp.html#pgmpy.inference.ExactInference.BeliefPropagationWithMessagePassing.calc_variable_node_message">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">calc_variable_node_message</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">incoming_messages</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The outgoing message is the element wise product of all incoming messages</span>

<span class="sd">        If there are no incoming messages, returns a uniform message</span>
<span class="sd">        If there is only one incoming message, returns that message</span>
<span class="sd">        Otherwise, returns the product of all incoming messages</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable: str</span>
<span class="sd">            the variable node from which to compute the outgoing message</span>
<span class="sd">        incoming_messages: list</span>
<span class="sd">            list of messages coming to this variable node</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">incoming_messages</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_uniform_message</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">incoming_messages</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">incoming_messages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">outgoing_message</span> <span class="o">=</span> <span class="n">reduce</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">,</span> <span class="n">incoming_messages</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outgoing_message</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">outgoing_message</span><span class="p">)</span></div>


<div class="viewcode-block" id="BeliefPropagationWithMessagePassing.calc_factor_node_message">
<a class="viewcode-back" href="../../../infer/bp_wmp.html#pgmpy.inference.ExactInference.BeliefPropagationWithMessagePassing.calc_factor_node_message">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calc_factor_node_message</span><span class="p">(</span><span class="n">factor</span><span class="p">,</span> <span class="n">incoming_messages</span><span class="p">,</span> <span class="n">target_var</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the outgoing message for a factor node, which is the</span>
<span class="sd">        multiplication of the incoming messages with the factor function (CPT).</span>

<span class="sd">        The variables&#39; order in the incoming messages list must match the</span>
<span class="sd">        variable&#39;s order in the CPT&#39;s dimensions</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        factor: str</span>
<span class="sd">            the factor node from which to compute the outgoing message</span>
<span class="sd">        incoming_messages: list</span>
<span class="sd">            list of messages coming to this factor node</span>
<span class="sd">        target_var: str</span>
<span class="sd">            the variable node to which the outgoing message is being sent to</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cpt</span> <span class="o">=</span> <span class="n">factor</span><span class="o">.</span><span class="n">values</span>

        <span class="k">assert</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">incoming_messages</span><span class="p">)</span> <span class="o">==</span> <span class="n">cpt</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Error computing factor node message for </span><span class="si">{</span><span class="n">target_var</span><span class="si">}</span><span class="s2">. &quot;</span>
        <span class="s2">&quot;The number of incoming messages must equal the card(CPT) - 1&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">incoming_messages</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">cpt</span>

        <span class="c1"># Ensure that the target var is on the CPT&#39;s 0th axis</span>
        <span class="n">target_var_idx</span> <span class="o">=</span> <span class="n">factor</span><span class="o">.</span><span class="n">variables</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">target_var</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">target_var_idx</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Move target var to the 0th axis to allow the reduction</span>
            <span class="n">cpt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">cpt</span><span class="p">,</span> <span class="n">target_var_idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Invert incoming_messages, so that the first message corresponds to the last</span>
        <span class="c1"># dimension of the CPT</span>
        <span class="n">incoming_messages</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">incoming_messages</span><span class="p">))</span>

        <span class="c1"># Reduce the CPT with the inverted list of incoming messages</span>
        <span class="n">outgoing_message</span> <span class="o">=</span> <span class="n">reduce</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">cpt_reduced</span><span class="p">,</span> <span class="n">m</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">cpt_reduced</span><span class="p">,</span> <span class="n">m</span><span class="p">),</span> <span class="n">incoming_messages</span><span class="p">,</span> <span class="n">cpt</span>
        <span class="p">)</span>
        <span class="c1"># Normalise</span>
        <span class="k">return</span> <span class="n">outgoing_message</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">outgoing_message</span><span class="p">)</span></div>
</div>

</code></pre></div>







  
  






                
  <div data-ea-publisher="pgmpyorg" data-ea-type="image" data-ea-style="stickybox"></div>
  <script>
    (function() {
      var nav = document.querySelector('.md-header__inner');
      if (!nav) return;

      var socialDiv = document.createElement('div');
      socialDiv.className = 'md-header__social';

      socialDiv.innerHTML =
        '<a href="https://github.com/pgmpy/pgmpy" target="_blank" rel="noopener" title="GitHub">' +
          '<svg viewBox="0 0 496 512" xmlns="http://www.w3.org/2000/svg">' +
            '<path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.8-14.9-112.8-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/>' +
          '</svg>' +
        '</a>' +
        '<a href="https://discord.gg/DRkdKaumBs" target="_blank" rel="noopener" title="Discord">' +
          '<svg viewBox="0 0 640 512" xmlns="http://www.w3.org/2000/svg">' +
            '<path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485.065 485.065 0 0 0 404.081 32.03a1.816 1.816 0 0 0-1.923.91 337.461 337.461 0 0 0-14.9 30.6 447.848 447.848 0 0 0-134.426 0 309.541 309.541 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91A483.689 483.689 0 0 0 116.085 69.137a1.712 1.712 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.016 2.016 0 0 0 .765 1.375A487.666 487.666 0 0 0 176.02 479.918a1.9 1.9 0 0 0 2.063-.676A348.2 348.2 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321.173 321.173 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126c3.082-2.309 6.166-4.711 9.109-7.137a1.819 1.819 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.812 1.812 0 0 1 1.924.233c2.944 2.426 6.027 4.851 9.132 7.16a1.884 1.884 0 0 1-.162 3.126 301.407 301.407 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391.055 391.055 0 0 0 30.014 48.815 1.864 1.864 0 0 0 2.063.7A486.048 486.048 0 0 0 610.7 405.729a1.882 1.882 0 0 0 .765-1.352C623.729 277.594 590.933 167.465 524.531 69.836zM222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239S193.056 219.1 222.491 219.1c29.665 0 53.306 26.82 52.843 59.239C275.334 310.993 251.924 337.58 222.491 337.58zm195.38 0c-28.971 0-52.843-26.587-52.843-59.239S388.437 219.1 417.871 219.1c29.667 0 53.307 26.82 52.844 59.239C470.715 310.993 447.538 337.58 417.871 337.58z"/>' +
          '</svg>' +
        '</a>' +
        '<a href="https://www.linkedin.com/company/pgmpy/" target="_blank" rel="noopener" title="LinkedIn">' +
          '<svg viewBox="0 0 448 512" xmlns="http://www.w3.org/2000/svg">' +
            '<path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/>' +
          '</svg>' +
        '</a>';

      nav.appendChild(socialDiv);
    })();
  </script>

              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  
  
  <div class="md-footer-meta md-typeset">
    
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-footer-copyright__highlight">
        &#169; Copyright 2025, Ankur Ankan.
        
    </div>
  
    Created using
    <a href="https://www.sphinx-doc.org/" target="_blank" rel="noopener">Sphinx</a>
    9.1.0.
     and
    <a href="https://github.com/jbms/sphinx-immaterial/" target="_blank" rel="noopener">Sphinx-Immaterial</a>
  
</div>
      
    </div>
    
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.top", "search.highlight", "search.share", "toc.follow", "content.tabs.link"], "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike", "staticVersions": [{"aliases": [], "title": "1.0.0 (stable)", "version": "https://pgmpy.org"}, {"aliases": [], "title": "dev", "version": "https://pgmpy.org/dev"}], "versionPath": null}}</script>
    
      
        <script src="../../../_static/sphinx_immaterial_theme.32136f45f91ae6956.min.js?v=a7a9472a"></script>
        <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../../_static/copybutton.js?v=f281be69"></script>
        <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
  </body>
</html>
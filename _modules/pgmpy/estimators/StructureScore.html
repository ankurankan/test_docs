


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../_static/logo_favi.ico">
    
    
      
        <title>pgmpy.estimators.StructureScore - pgmpy</title>
      
    
    
      
        
      
      


    
    
      
    
    
      
        
        
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
        <link rel="stylesheet" type="text/css" href="../../../_static/sphinx_immaterial_theme.acf80fe7f4d9ef9e2.min.css?v=9e56d0d2" />
        <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
        <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  
  <!-- SEO meta tags -->
  <meta name="description" content="pgmpy: A Python library for causal inference and probabilistic inference using Directed Acyclic Graphs (DAGs) and Bayesian Networks.">
  <meta name="keywords" content="pgmpy, Bayesian Networks, causal inference, probabilistic graphical models, structure learning, parameter estimation, Python">
  <meta property="og:type" content="website">
  <meta property="og:site_name" content="pgmpy">
  <meta property="og:title" content="pgmpy.estimators.StructureScore">
  <meta property="og:description" content="pgmpy: A Python library for causal inference and probabilistic inference using Directed Acyclic Graphs (DAGs) and Bayesian Networks.">
  <meta property="og:url" content="https://pgmpy.org/_modules/pgmpy/estimators/StructureScore.html">
  <meta property="og:image" content="https://pgmpy.org/_static/logo.png">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="pgmpy.estimators.StructureScore">
  <meta name="twitter:description" content="pgmpy: A Python library for causal inference and probabilistic inference using Directed Acyclic Graphs (DAGs) and Bayesian Networks.">
  <meta name="twitter:image" content="https://pgmpy.org/_static/logo.png">
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-HCFR07M31W"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-HCFR07M31W');
  </script>
  <!-- EthicalAds -->
  <script async src="https://media.ethicalads.io/media/client/ethicalads.min.js"></script>
  <!-- Header social links styling -->
  <style>
    @import url("https://fonts.googleapis.com/css2?family=Source+Sans+3:wght@300;400;500;600;700&family=Source+Code+Pro:wght@400;500;600&display=swap");
    :root {
      --md-text-font: "Source Sans 3", system-ui, sans-serif;
      --md-code-font: "Source Code Pro", ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", monospace;
    }
    .md-header__social {
      display: flex;
      align-items: center;
      gap: 0.1rem;
      margin-left: 0.4rem;
    }
    .md-header__social a {
      display: inline-flex;
      align-items: center;
      justify-content: center;
      padding: 0.4rem;
      color: var(--md-default-fg-color--light);
      opacity: 0.7;
      transition: opacity 0.25s;
    }
    .md-header__social a:hover {
      opacity: 1;
    }
    .md-header__social svg {
      width: 1.2rem;
      height: 1.2rem;
      fill: currentColor;
    }
    [data-md-color-scheme="slate"] .md-header__social a {
      color: var(--md-default-fg-color--light);
    }
    /* Card visibility in light/dark modes */
    .sd-card {
      background-color: var(--pgmpy-card-bg, var(--md-default-bg-color));
      border: 1px solid var(--pgmpy-card-border, rgba(0, 0, 0, 0.08));
      box-shadow: 0 1px 2px rgba(0, 0, 0, 0.04);
    }
    .sd-card .sd-card-header,
    .sd-card .sd-card-footer {
      border-color: var(--pgmpy-card-border, rgba(0, 0, 0, 0.08));
    }
    [data-md-color-scheme="slate"] .sd-card {
      --pgmpy-card-bg: rgba(255, 255, 255, 0.045);
      --pgmpy-card-border: rgba(255, 255, 255, 0.2);
      box-shadow: 0 2px 6px rgba(0, 0, 0, 0.35);
    }
    /* Hover shadow effect on feature cards */
    .sd-card-hover {
      transition: box-shadow 0.25s ease, transform 0.25s ease;
    }
    .sd-card-hover:hover {
      box-shadow: 0 6px 18px rgba(0, 0, 0, 0.12);
      transform: translateY(-2px);
    }
    [data-md-color-scheme="slate"] .sd-card-hover:hover {
      box-shadow: 0 8px 22px rgba(0, 0, 0, 0.55);
    }
    /* Center content when right sidebar (toc) is hidden */
    .md-sidebar--secondary[hidden] ~ .md-content {
      margin-left: auto;
      margin-right: auto;
    }
  </style>

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../index.html" title="pgmpy" class="md-header__button md-logo" aria-label="pgmpy" data-md-component="logo">
      <img src="../../../_static/logo.png" alt="logo">
    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            pgmpy
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              pgmpy.estimators.StructureScore
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/pgmpy/pgmpy" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    pgmpy/pgmpy
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../started/base.html" class="md-tabs__link">
        
  
    
  
  <span title="/started/base.rst (reference label)"><span>Getting Started</span></span>

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../documentation.html" class="md-tabs__link">
        
  
    
  
  <span title="/documentation.rst (reference label)"><span>Documentation</span></span>

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../examples.html" class="md-tabs__link">
        
  
    
  
  <span title="/examples.rst (reference label)"><span>Examples</span></span>

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../api.html" class="md-tabs__link">
        
  
    
  
  <span title="/api.rst (reference label)"><span>API Reference</span></span>

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../development.html" class="md-tabs__link">
        
  
    
  
  <span title="/development.rst (reference label)"><span>Development</span></span>

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../index.html" title="pgmpy" class="md-nav__button md-logo" aria-label="pgmpy" data-md-component="logo">
      <img src="../../../_static/logo.png" alt="logo">
    </a>
    pgmpy
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/pgmpy/pgmpy" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    pgmpy/pgmpy
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../started/base.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/started/base.rst (reference label)"><span>Getting Started</span></span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../documentation.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/documentation.rst (reference label)"><span>Documentation</span></span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/examples.rst (reference label)"><span>Examples</span></span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../api.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/api.rst (reference label)"><span>API Reference</span></span>
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../development.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    <span title="/development.rst (reference label)"><span>Development</span></span>
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary">
  
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset" role="main">
                
                
  
                  


<h1>Source code for pgmpy.estimators.StructureScore</h1><div class="highlight"><pre>
<span></span><code><span class="ch">#!/usr/bin/env python</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">lgamma</span><span class="p">,</span> <span class="n">log</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">statsmodels.formula.api</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">smf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.special</span><span class="w"> </span><span class="kn">import</span> <span class="n">gammaln</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">multivariate_normal</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">pgmpy.estimators</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseEstimator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pgmpy.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_dataset_type</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_scoring_method</span><span class="p">(</span>
    <span class="n">scoring_method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;StructureScore&quot;</span><span class="p">]],</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">use_cache</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="s2">&quot;StructureScore&quot;</span><span class="p">,</span> <span class="s2">&quot;StructureScore&quot;</span><span class="p">]:</span>
    <span class="n">available_methods</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;continuous&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;bic-g&quot;</span><span class="p">:</span> <span class="n">BICGauss</span><span class="p">,</span>
            <span class="s2">&quot;ll-g&quot;</span><span class="p">:</span> <span class="n">LogLikelihoodGauss</span><span class="p">,</span>
            <span class="s2">&quot;aic-g&quot;</span><span class="p">:</span> <span class="n">AICGauss</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;discrete&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;bic-d&quot;</span><span class="p">:</span> <span class="n">BIC</span><span class="p">,</span>
            <span class="s2">&quot;k2&quot;</span><span class="p">:</span> <span class="n">K2</span><span class="p">,</span>
            <span class="s2">&quot;bdeu&quot;</span><span class="p">:</span> <span class="n">BDeu</span><span class="p">,</span>
            <span class="s2">&quot;bds&quot;</span><span class="p">:</span> <span class="n">BDs</span><span class="p">,</span>
            <span class="s2">&quot;aic-d&quot;</span><span class="p">:</span> <span class="n">AIC</span><span class="p">,</span>
            <span class="s2">&quot;ll-d&quot;</span><span class="p">:</span> <span class="n">LogLikeliHood</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;mixed&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;bic-cg&quot;</span><span class="p">:</span> <span class="n">BICCondGauss</span><span class="p">,</span>
            <span class="s2">&quot;ll-cg&quot;</span><span class="p">:</span> <span class="n">LogLikelihoodCondGauss</span><span class="p">,</span>
            <span class="s2">&quot;aic-cg&quot;</span><span class="p">:</span> <span class="n">AICCondGauss</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">}</span>
    <span class="n">all_available_methods</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">key</span> <span class="k">for</span> <span class="n">subdict</span> <span class="ow">in</span> <span class="n">available_methods</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">subdict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
    <span class="p">]</span>

    <span class="n">var_type</span> <span class="o">=</span> <span class="n">get_dataset_type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">supported_methods</span> <span class="o">=</span> <span class="n">available_methods</span><span class="p">[</span><span class="n">var_type</span><span class="p">]</span> <span class="o">|</span> <span class="n">available_methods</span><span class="p">[</span><span class="s2">&quot;mixed&quot;</span><span class="p">]</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scoring_method</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">scoring_method</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="s2">&quot;k2score&quot;</span><span class="p">,</span>
            <span class="s2">&quot;bdeuscore&quot;</span><span class="p">,</span>
            <span class="s2">&quot;bdsscore&quot;</span><span class="p">,</span>
            <span class="s2">&quot;bicscore&quot;</span><span class="p">,</span>
            <span class="s2">&quot;aicscore&quot;</span><span class="p">,</span>
        <span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The scoring method names have been changed. Please refer the documentation.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">scoring_method</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">all_available_methods</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Unknown scoring method. Please refer documentation for a list of supported score metrics.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">scoring_method</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">supported_methods</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Incorrect scoring method for </span><span class="si">{</span><span class="n">var_type</span><span class="si">}</span><span class="s2">, scoring_method should be one of&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">supported_methods</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">, received </span><span class="si">{</span><span class="n">scoring_method</span><span class="si">}</span><span class="s2">. </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scoring_method</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">)):</span>
        <span class="c1"># automatically determine scoring method, pick first one</span>
        <span class="n">scoring_method</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">available_methods</span><span class="p">[</span><span class="n">var_type</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scoring_method</span><span class="p">,</span> <span class="n">StructureScore</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;scoring_method should either be one of </span><span class="si">{</span><span class="n">all_available_methods</span><span class="si">}</span><span class="s2"> or an instance of StructureScore&quot;</span>
        <span class="p">)</span>

    <span class="n">score</span><span class="p">:</span> <span class="n">StructureScore</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scoring_method</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">supported_methods</span><span class="p">[</span><span class="n">scoring_method</span><span class="o">.</span><span class="n">lower</span><span class="p">()](</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">scoring_method</span>

    <span class="k">if</span> <span class="n">use_cache</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">pgmpy.estimators.ScoreCache</span><span class="w"> </span><span class="kn">import</span> <span class="n">ScoreCache</span>

        <span class="n">score_c</span> <span class="o">=</span> <span class="n">ScoreCache</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">score_c</span> <span class="o">=</span> <span class="n">score</span>

    <span class="k">return</span> <span class="n">score</span><span class="p">,</span> <span class="n">score_c</span>


<span class="k">class</span><span class="w"> </span><span class="nc">StructureScore</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract base class for structure scoring in pgmpy.</span>

<span class="sd">    Structure scores are used to evaluate how well a given Bayesian network structure</span>
<span class="sd">    fits observed data. This class should not be used directly. Use one of the derived</span>
<span class="sd">    classes such as `K2`, `BDeu`, `BIC`, or `AIC` for concrete scoring methods.</span>

<span class="sd">    Structure scores are central to model selection in Bayesian networks and are</span>
<span class="sd">    particularly useful when comparing candidate network structures in discrete data scenarios.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame in which each column represents a variable. Missing values should</span>
<span class="sd">        be marked as `numpy.nan`. Note: Columns with `numpy.nan` will have dtype `float`.</span>

<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping each variable name to the set of its discrete states.</span>
<span class="sd">        If not specified, the observed values in the data are used as possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import K2</span>
<span class="sd">    &gt;&gt;&gt; # Create random data sample with 3 variables, where B and C are identical:</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(np.random.randint(0, 5, size=(5000, 2)), columns=list(&quot;AB&quot;))</span>
<span class="sd">    &gt;&gt;&gt; data[&quot;C&quot;] = data[&quot;B&quot;]</span>
<span class="sd">    &gt;&gt;&gt; model1 = DiscreteBayesianNetwork([[&quot;A&quot;, &quot;B&quot;], [&quot;A&quot;, &quot;C&quot;]])</span>
<span class="sd">    &gt;&gt;&gt; model2 = DiscreteBayesianNetwork([[&quot;A&quot;, &quot;B&quot;], [&quot;B&quot;, &quot;C&quot;]])</span>
<span class="sd">    &gt;&gt;&gt; K2(data).score(model1)</span>
<span class="sd">    -24242.367348745247</span>
<span class="sd">    &gt;&gt;&gt; K2(data).score(model2)</span>
<span class="sd">    -16273.793897051042</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - Use this class as a base for implementing custom structure scores.</span>
<span class="sd">    - Use derived classes (`K2`, `BDeu`, `BIC`, `AIC`) for standard scoring approaches.</span>
<span class="sd">    - If you provide data with continuous variables or incompatible states, a `ValueError` may be raised.</span>
<span class="sd">    - For best results, ensure all variables are discrete and states are correctly specified.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If data contains unsupported (non-discrete) types, or if the variables</span>
<span class="sd">        in the model do not match the data columns.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Koller &amp; Friedman, Probabilistic Graphical Models: Principles and Techniques, 2009, Section 18.3.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StructureScore</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes a structure score for a given Bayesian network model.</span>

<span class="sd">        This method evaluates how well the specified `DiscreteBayesianNetwork`</span>
<span class="sd">        fits the observed data, using the structure score metric implemented in the subclass.</span>
<span class="sd">        The higher (or less negative) the score, the better the fit between the model and the data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : DiscreteBayesianNetwork</span>
<span class="sd">            The Bayesian network whose structure is to be scored. All nodes in the</span>
<span class="sd">            model must correspond to columns in the input data.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The computed structure score representing the model&#39;s fit to the data.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.estimators import K2</span>
<span class="sd">        &gt;&gt;&gt; # create random data sample with 3 variables, where B and C are identical:</span>
<span class="sd">        &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">        ...     np.random.randint(0, 5, size=(5000, 2)), columns=list(&quot;AB&quot;)</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; data[&quot;C&quot;] = data[&quot;B&quot;]</span>
<span class="sd">        &gt;&gt;&gt; K2(data).score(DiscreteBayesianNetwork([[&quot;A&quot;, &quot;B&quot;], [&quot;A&quot;, &quot;C&quot;]]))</span>
<span class="sd">        -24242.367348745247</span>
<span class="sd">        &gt;&gt;&gt; K2(data).score(DiscreteBayesianNetwork([[&quot;A&quot;, &quot;B&quot;], [&quot;B&quot;, &quot;C&quot;]]))</span>
<span class="sd">        -16273.793897051042</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the model contains nodes not present in the data columns, or if the</span>
<span class="sd">            data contains unsupported variable types.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">score</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">nodes</span><span class="p">():</span>
            <span class="n">score</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_score</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predecessors</span><span class="p">(</span><span class="n">node</span><span class="p">)))</span>
        <span class="n">score</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">structure_prior</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">score</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">structure_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the (log) prior distribution over Bayesian network structures.</span>

<span class="sd">        This method returns a uniform prior by default and is currently unused in scoring.</span>
<span class="sd">        Override this method in subclasses to implement custom prior distributions</span>
<span class="sd">        over network structures.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : DiscreteBayesianNetwork</span>
<span class="sd">            The Bayesian network model for which the structure prior is to be computed.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        prior : float</span>
<span class="sd">            The log prior probability of the given model structure. By default, returns 0.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.estimators import K2</span>
<span class="sd">        &gt;&gt;&gt; model = DiscreteBayesianNetwork([(&quot;A&quot;, &quot;B&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; score = K2(data)</span>
<span class="sd">        &gt;&gt;&gt; prior = score.structure_prior(model)</span>
<span class="sd">        &gt;&gt;&gt; print(prior)</span>
<span class="sd">        0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">structure_prior_ratio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">operation</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the log ratio of prior probabilities for a proposed change to the model structure.</span>

<span class="sd">        This method returns the log prior probability ratio for a structural operation</span>
<span class="sd">        (e.g., adding, removing, or reversing an edge) in the Bayesian network. By default,</span>
<span class="sd">        it assumes a uniform prior and returns 0, meaning no structural operation is favored.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        operation : tuple or object</span>
<span class="sd">            The proposed operation on the Directed Acyclic Graph (DAG), typically represented as a tuple</span>
<span class="sd">            describing the change (such as (&#39;add&#39;, &#39;A&#39;, &#39;B&#39;) for adding an edge from A to B).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        prior_ratio : float</span>
<span class="sd">            The log ratio of the prior probabilities for the proposed operation. By default, returns 0.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.estimators import K2</span>
<span class="sd">        &gt;&gt;&gt; op = (&quot;add&quot;, &quot;A&quot;, &quot;B&quot;)  # Example operation</span>
<span class="sd">        &gt;&gt;&gt; score = K2(data)</span>
<span class="sd">        &gt;&gt;&gt; ratio = score.structure_prior_ratio(op)</span>
<span class="sd">        &gt;&gt;&gt; print(ratio)</span>
<span class="sd">        0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">0</span>


<div class="viewcode-block" id="K2">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.K2">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">K2</span><span class="p">(</span><span class="n">StructureScore</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    K2 structure score for discrete Bayesian networks using Dirichlet priors.</span>

<span class="sd">    The K2 score is commonly used to evaluate the fit of a Bayesian network structure</span>
<span class="sd">    on fully discrete data, assuming all Dirichlet hyperparameters (pseudo-counts) are set to 1.</span>
<span class="sd">    This metric is suitable for structure learning when variables are categorical and no</span>
<span class="sd">    prior preference for particular parameterizations is assumed.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where each column represents a discrete variable. Missing values</span>
<span class="sd">        should be set to `numpy.nan`. (Note: pandas will convert columns with `numpy.nan` to dtype float.)</span>
<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping each variable to its discrete states. If not specified, the unique</span>
<span class="sd">        values observed in the data are used as possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import K2</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame({&quot;A&quot;: [0, 1, 1, 0], &quot;B&quot;: [1, 0, 1, 0], &quot;C&quot;: [1, 1, 1, 0]})</span>
<span class="sd">    &gt;&gt;&gt; model = DiscreteBayesianNetwork([(&quot;A&quot;, &quot;B&quot;), (&quot;A&quot;, &quot;C&quot;)])</span>
<span class="sd">    &gt;&gt;&gt; k2_score = K2(data)</span>
<span class="sd">    &gt;&gt;&gt; print(k2_score.score(model))</span>
<span class="sd">    -356.1785</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the data contains continuous variables, or if the model variables are not present in the data.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Koller &amp; Friedman, Probabilistic Graphical Models - Principles and Techniques, 2009,</span>
<span class="sd">        Section 18.3.4â€“18.3.6 (esp. page 806).</span>
<span class="sd">    [2] AM Carvalho, Scoring functions for learning Bayesian networks,</span>
<span class="sd">        http://www.lx.it.pt/~asmc/pub/talks/09-TA/ta_pres.pdf</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">K2</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="K2.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.K2.local_score">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local K2 score for a discrete variable and its parent variables.</span>

<span class="sd">        The K2 local score measures how well the conditional probability distribution</span>
<span class="sd">        of `variable` given its parents fits the observed data, assuming uniform Dirichlet</span>
<span class="sd">        priors (all hyperparameters set to 1). The calculation is based on marginal and</span>
<span class="sd">        conditional counts, and is suitable for fully discrete Bayesian networks.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the target variable (child node).</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of parent variable names (categorical/discrete).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local K2 score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; variable = &quot;B&quot;</span>
<span class="sd">        &gt;&gt;&gt; parents = [&quot;A&quot;]</span>
<span class="sd">        &gt;&gt;&gt; s = k2_score.local_score(variable, parents)</span>
<span class="sd">        &gt;&gt;&gt; print(s)</span>
<span class="sd">        -42.18</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If `variable` or any parent is not present in `state_names` or data, or if the data</span>
<span class="sd">            is not fully discrete.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Koller &amp; Friedman, Probabilistic Graphical Models - Principles and Techniques, 2009,</span>
<span class="sd">            Section 18.3.4â€“18.3.6 (esp. page 806).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">var_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span>
        <span class="n">var_cardinality</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">var_states</span><span class="p">)</span>
        <span class="n">parents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span>
        <span class="n">state_counts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_counts</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">,</span> <span class="n">reindex</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">num_parents_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">var</span><span class="p">])</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">parents</span><span class="p">])</span>

        <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">state_counts</span><span class="p">)</span>
        <span class="n">log_gamma_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

        <span class="c1"># Compute log(gamma(counts + 1))</span>
        <span class="n">gammaln</span><span class="p">(</span><span class="n">counts</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_gamma_counts</span><span class="p">)</span>

        <span class="c1"># Compute the log-gamma conditional sample size</span>
        <span class="n">log_gamma_conds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">gammaln</span><span class="p">(</span><span class="n">log_gamma_conds</span> <span class="o">+</span> <span class="n">var_cardinality</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_gamma_conds</span><span class="p">)</span>

        <span class="c1"># TODO: Check why is this needed</span>
        <span class="c1">#</span>
        <span class="c1"># Adjustments when using reindex=False as it drops columns of 0 state counts</span>
        <span class="c1"># gamma_counts_adj = (</span>
        <span class="c1">#     (num_parents_states - counts.shape[1]) * var_cardinality * gammaln(1)</span>
        <span class="c1"># )</span>
        <span class="c1"># gamma_conds_adj = (num_parents_states - counts.shape[1]) * gammaln(</span>
        <span class="c1">#     var_cardinality</span>
        <span class="c1"># )</span>
        <span class="c1"># log_gamma_counts += gamma_counts_adj</span>
        <span class="c1"># log_gamma_conds += gamma_conds_adj</span>

        <span class="n">score</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_gamma_counts</span><span class="p">)</span>
            <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_gamma_conds</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">num_parents_states</span> <span class="o">*</span> <span class="n">lgamma</span><span class="p">(</span><span class="n">var_cardinality</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">score</span></div>
</div>



<div class="viewcode-block" id="BDeu">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BDeu">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BDeu</span><span class="p">(</span><span class="n">StructureScore</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BDeu structure score for discrete Bayesian networks with Dirichlet priors.</span>

<span class="sd">    The BDeu score evaluates Bayesian network structures using an &quot;equivalent sample size&quot;</span>
<span class="sd">    to define Dirichlet prior hyperparameters, making it flexible for various data sizes</span>
<span class="sd">    and uncertainty levels. Use this score when you want to control the influence of your prior</span>
<span class="sd">    belief through the equivalent sample size.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where each column represents a discrete variable.</span>
<span class="sd">        Missing values should be set as `numpy.nan`.</span>
<span class="sd">        Note: pandas converts such columns to dtype float.</span>

<span class="sd">    equivalent_sample_size : int, optional (default: 10)</span>
<span class="sd">        The equivalent (imaginary) sample size for the Dirichlet hyperparameters.</span>
<span class="sd">        The score is sensitive to this value; experiment with different values as needed.</span>

<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping variable names to their discrete states.</span>
<span class="sd">        If not specified, unique values observed in the data are used as possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import BDeu</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame({&quot;A&quot;: [0, 1, 1, 0], &quot;B&quot;: [1, 0, 1, 0], &quot;C&quot;: [1, 1, 1, 0]})</span>
<span class="sd">    &gt;&gt;&gt; model = DiscreteBayesianNetwork([(&quot;A&quot;, &quot;B&quot;), (&quot;A&quot;, &quot;C&quot;)])</span>
<span class="sd">    &gt;&gt;&gt; bdeu_score = BDeu(data, equivalent_sample_size=5)</span>
<span class="sd">    &gt;&gt;&gt; print(bdeu_score.score(model))</span>
<span class="sd">    -241.872</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the data contains continuous variables, or if the model variables are not present in the data.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Koller &amp; Friedman, Probabilistic Graphical Models - Principles and Techniques, 2009,</span>
<span class="sd">        Section 18.3.4â€“18.3.6 (esp. page 806).</span>
<span class="sd">    [2] AM Carvalho, Scoring functions for learning Bayesian networks,</span>
<span class="sd">        http://www.lx.it.pt/~asmc/pub/talks/09-TA/ta_pres.pdf</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">equivalent_sample_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">equivalent_sample_size</span> <span class="o">=</span> <span class="n">equivalent_sample_size</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BDeu</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="BDeu.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BDeu.local_score">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local BDeu score for a given variable and its parent variables.</span>

<span class="sd">        This method calculates how well a given variable is explained by its parents</span>
<span class="sd">        according to the BDeu scoring metric, incorporating the equivalent sample size</span>
<span class="sd">        as the Dirichlet prior.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local BDeu score for the specified variable and parent configuration.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If `variable` or any parent is not found in state_names or data.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">parents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span>
        <span class="n">state_counts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_counts</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">,</span> <span class="n">reindex</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">num_parents_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">var</span><span class="p">])</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">parents</span><span class="p">])</span>

        <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">state_counts</span><span class="p">)</span>
        <span class="c1"># The counts_size reflects the full possible table, including dropped zero-count columns.</span>
        <span class="n">counts_size</span> <span class="o">=</span> <span class="n">num_parents_states</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">variable</span><span class="p">])</span>
        <span class="n">log_gamma_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">equivalent_sample_size</span> <span class="o">/</span> <span class="n">num_parents_states</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">equivalent_sample_size</span> <span class="o">/</span> <span class="n">counts_size</span>
        <span class="c1"># Compute log(gamma(counts + beta)) for the observed state counts.</span>
        <span class="n">gammaln</span><span class="p">(</span><span class="n">counts</span> <span class="o">+</span> <span class="n">beta</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_gamma_counts</span><span class="p">)</span>

        <span class="c1"># Compute the log-gamma of the conditional sample size.</span>
        <span class="n">log_gamma_conds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">gammaln</span><span class="p">(</span><span class="n">log_gamma_conds</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_gamma_conds</span><span class="p">)</span>

        <span class="c1"># Adjustment for missing zero-count columns (when using reindex=False to save memory).</span>
        <span class="n">gamma_counts_adj</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">num_parents_states</span> <span class="o">-</span> <span class="n">counts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">variable</span><span class="p">])</span>
            <span class="o">*</span> <span class="n">gammaln</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">gamma_conds_adj</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_parents_states</span> <span class="o">-</span> <span class="n">counts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">gammaln</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>

        <span class="c1"># Final BDeu local score calculation.</span>
        <span class="n">score</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_gamma_counts</span><span class="p">)</span> <span class="o">+</span> <span class="n">gamma_counts_adj</span><span class="p">)</span>
            <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_gamma_conds</span><span class="p">)</span> <span class="o">+</span> <span class="n">gamma_conds_adj</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">num_parents_states</span> <span class="o">*</span> <span class="n">lgamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
            <span class="o">-</span> <span class="n">counts_size</span> <span class="o">*</span> <span class="n">lgamma</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">score</span></div>
</div>



<div class="viewcode-block" id="BDs">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BDs">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BDs</span><span class="p">(</span><span class="n">BDeu</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BDs (Bayesian Dirichlet sparse) structure score for discrete Bayesian networks.</span>

<span class="sd">    The BDs score is a variant of the BDeu score that sets Dirichlet hyperparameters</span>
<span class="sd">    (pseudo-counts) proportional to the number of observed parent configurations,</span>
<span class="sd">    leading to improved scoring in sparse or partially observed data scenarios.</span>

<span class="sd">    Use this score when you expect many possible parent configurations in your data</span>
<span class="sd">    to be unobserved (common in sparse or high-dimensional discrete datasets).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where each column represents a discrete variable.</span>
<span class="sd">        Missing values should be set as `numpy.nan`.</span>
<span class="sd">        Note: pandas converts such columns to dtype float.</span>
<span class="sd">    equivalent_sample_size : int, optional (default: 10)</span>
<span class="sd">        The equivalent (imaginary) sample size for the Dirichlet hyperparameters.</span>
<span class="sd">        The score is sensitive to this value; try different values if needed.</span>
<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping variable names to their discrete states.</span>
<span class="sd">        If not specified, unique values observed in the data are used as possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import BDs</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame({&quot;A&quot;: [0, 1, 1, 0], &quot;B&quot;: [1, 0, 1, 0], &quot;C&quot;: [1, 1, 1, 0]})</span>
<span class="sd">    &gt;&gt;&gt; model = DiscreteBayesianNetwork([(&quot;A&quot;, &quot;B&quot;), (&quot;A&quot;, &quot;C&quot;)])</span>
<span class="sd">    &gt;&gt;&gt; bds_score = BDs(data, equivalent_sample_size=5)</span>
<span class="sd">    &gt;&gt;&gt; print(bds_score.score(model))</span>
<span class="sd">    -210.314</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the data contains continuous variables, or if the model variables are not present in the data.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Scutari, Marco. An Empirical-Bayes Score for Discrete Bayesian Networks.</span>
<span class="sd">        Journal of Machine Learning Research, 2016, pp. 438â€“48</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">equivalent_sample_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BDs</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">equivalent_sample_size</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="BDs.structure_prior_ratio">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BDs.structure_prior_ratio">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">structure_prior_ratio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">operation</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the log ratio of prior probabilities for a proposed change to the DAG structure.</span>

<span class="sd">        This method implements the marginal uniform prior for the graph structure, where the</span>
<span class="sd">        log prior probability ratio is -log(2) for adding an edge, log(2) for removing an edge,</span>
<span class="sd">        and 0 otherwise.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        operation : str</span>
<span class="sd">            The proposed operation on the Directed Acyclic Graph (DAG).</span>
<span class="sd">            Use &quot;+&quot; for adding an edge, &quot;-&quot; for removing an edge, or other values for no change.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        prior_ratio : float</span>
<span class="sd">            The log ratio of the prior probabilities for the proposed operation.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.estimators import BDs</span>
<span class="sd">        &gt;&gt;&gt; score = BDs(data)</span>
<span class="sd">        &gt;&gt;&gt; score.structure_prior_ratio(&quot;+&quot;)</span>
<span class="sd">        -0.6931471805599453</span>
<span class="sd">        &gt;&gt;&gt; score.structure_prior_ratio(&quot;-&quot;)</span>
<span class="sd">        0.6931471805599453</span>
<span class="sd">        &gt;&gt;&gt; score.structure_prior_ratio(&quot;noop&quot;)</span>
<span class="sd">        0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;+&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;-&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
        <span class="k">return</span> <span class="mi">0</span></div>


<div class="viewcode-block" id="BDs.structure_prior">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BDs.structure_prior">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">structure_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the marginal uniform prior for a Bayesian network structure.</span>

<span class="sd">        This method assigns a marginal uniform prior to the graph structure, where</span>
<span class="sd">        the probability of an arc (edge) between any two nodes (in either direction) is 1/4,</span>
<span class="sd">        and the probability of no arc between any two nodes is 1/2. The returned value</span>
<span class="sd">        is the log prior probability for the given model structure.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : DiscreteBayesianNetwork</span>
<span class="sd">            The Bayesian network model for which to compute the structure prior.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The log prior probability of the given network structure under the marginal uniform prior.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.estimators import BDs</span>
<span class="sd">        &gt;&gt;&gt; model = DiscreteBayesianNetwork([(&quot;A&quot;, &quot;B&quot;), (&quot;C&quot;, &quot;D&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; score = BDs(data)</span>
<span class="sd">        &gt;&gt;&gt; prior = score.structure_prior(model)</span>
<span class="sd">        &gt;&gt;&gt; print(prior)</span>
<span class="sd">        -4.1588830833596715</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nedges</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">edges</span><span class="p">()))</span>
        <span class="n">nnodes</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">nodes</span><span class="p">()))</span>
        <span class="n">possible_edges</span> <span class="o">=</span> <span class="n">nnodes</span> <span class="o">*</span> <span class="p">(</span><span class="n">nnodes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span>
        <span class="n">score</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">nedges</span> <span class="o">+</span> <span class="n">possible_edges</span><span class="p">)</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">score</span></div>


<div class="viewcode-block" id="BDs.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BDs.local_score">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local BDs score for a variable and its parent variables.</span>

<span class="sd">        The BDs local score quantifies how well the given variable is explained by its</span>
<span class="sd">        specified parent set, using a Bayesian Dirichlet sparse prior. The hyperparameters</span>
<span class="sd">        are adjusted based on the number of observed parent configurations, making the score</span>
<span class="sd">        more robust in sparse data scenarios.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local BDs score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; variable = &quot;B&quot;</span>
<span class="sd">        &gt;&gt;&gt; parents = [&quot;A&quot;]</span>
<span class="sd">        &gt;&gt;&gt; score = bds_score.local_score(variable, parents)</span>
<span class="sd">        &gt;&gt;&gt; print(score)</span>
<span class="sd">        -38.215</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If `variable` or any parent is not present in `state_names` or data, or if</span>
<span class="sd">            the data contains unsupported types (e.g., continuous values).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">parents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span>
        <span class="n">state_counts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_counts</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">,</span> <span class="n">reindex</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">num_parents_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">var</span><span class="p">])</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">parents</span><span class="p">])</span>

        <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">state_counts</span><span class="p">)</span>
        <span class="c1"># counts size is different because reindex=False is dropping columns.</span>
        <span class="n">counts_size</span> <span class="o">=</span> <span class="n">num_parents_states</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">variable</span><span class="p">])</span>
        <span class="n">log_gamma_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">equivalent_sample_size</span> <span class="o">/</span> <span class="n">state_counts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">equivalent_sample_size</span> <span class="o">/</span> <span class="n">counts_size</span>
        <span class="c1"># Compute log(gamma(counts + beta))</span>
        <span class="n">gammaln</span><span class="p">(</span><span class="n">counts</span> <span class="o">+</span> <span class="n">beta</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_gamma_counts</span><span class="p">)</span>

        <span class="c1"># Compute the log-gamma conditional sample size</span>
        <span class="n">log_gamma_conds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">gammaln</span><span class="p">(</span><span class="n">log_gamma_conds</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_gamma_conds</span><span class="p">)</span>

        <span class="c1"># Adjustment because of missing 0 columns when using reindex=False for computing state_counts to save memory.</span>
        <span class="n">gamma_counts_adj</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">num_parents_states</span> <span class="o">-</span> <span class="n">counts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">variable</span><span class="p">])</span>
            <span class="o">*</span> <span class="n">gammaln</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">gamma_conds_adj</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_parents_states</span> <span class="o">-</span> <span class="n">counts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">gammaln</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>

        <span class="n">score</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_gamma_counts</span><span class="p">)</span> <span class="o">+</span> <span class="n">gamma_counts_adj</span><span class="p">)</span>
            <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_gamma_conds</span><span class="p">)</span> <span class="o">+</span> <span class="n">gamma_conds_adj</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">state_counts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">lgamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
            <span class="o">-</span> <span class="n">counts_size</span> <span class="o">*</span> <span class="n">lgamma</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">score</span></div>
</div>



<span class="k">class</span><span class="w"> </span><span class="nc">LogLikeliHood</span><span class="p">(</span><span class="n">StructureScore</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Log-likelihood structure score for Discrete Bayesian networks.</span>

<span class="sd">    This score evaluates the fit of a Discrete Bayesian network structure</span>
<span class="sd">    by computing the (unpenalized) log-likelihood of the observed data given the model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data: pandas DataFrame object</span>
<span class="sd">        dataframe object where each column represents one variable.</span>
<span class="sd">        (If some values in the data are missing the data cells should be set to `numpy.nan`.</span>
<span class="sd">        Note that pandas converts each column containing `numpy.nan`s to dtype `float`.)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LogLikeliHood</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>

        <span class="n">var_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span>
        <span class="n">var_cardinality</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">var_states</span><span class="p">)</span>
        <span class="n">parents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span>
        <span class="n">state_counts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_counts</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">,</span> <span class="n">reindex</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">num_parents_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">var</span><span class="p">])</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">parents</span><span class="p">])</span>

        <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">state_counts</span><span class="p">)</span>
        <span class="n">log_likelihoods</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

        <span class="c1"># Compute the log-counts</span>
        <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_likelihoods</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="n">counts</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Compute the log-conditional sample size</span>
        <span class="n">log_conditionals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">log_conditionals</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_conditionals</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="n">log_conditionals</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Compute the log-likelihoods</span>
        <span class="n">log_likelihoods</span> <span class="o">-=</span> <span class="n">log_conditionals</span>
        <span class="n">log_likelihoods</span> <span class="o">*=</span> <span class="n">counts</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_likelihoods</span><span class="p">),</span> <span class="n">num_parents_states</span><span class="p">,</span> <span class="n">var_cardinality</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
        <span class="n">ll</span><span class="p">,</span> <span class="n">num_parents_states</span><span class="p">,</span> <span class="n">var_cardinality</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span><span class="p">(</span>
            <span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">ll</span>


<div class="viewcode-block" id="BIC">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BIC">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BIC</span><span class="p">(</span><span class="n">LogLikeliHood</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BIC (Bayesian Information Criterion) structure score for discrete Bayesian networks.</span>

<span class="sd">    The BIC score, also known as the Minimal Descriptive Length (MDL) score, evaluates</span>
<span class="sd">    Bayesian network structures using a log-likelihood term with a complexity penalty to</span>
<span class="sd">    discourage overfitting. Use this score for structure learning when you want to balance</span>
<span class="sd">    model fit with simplicity.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where each column represents a discrete variable.</span>
<span class="sd">        Missing values should be set as `numpy.nan`.</span>
<span class="sd">        Note: pandas converts such columns to dtype float.</span>
<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping variable names to their discrete states.</span>
<span class="sd">        If not specified, unique values observed in the data are used as possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import BIC</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame({&quot;A&quot;: [0, 1, 1, 0], &quot;B&quot;: [1, 0, 1, 0], &quot;C&quot;: [1, 1, 1, 0]})</span>
<span class="sd">    &gt;&gt;&gt; model = DiscreteBayesianNetwork([(&quot;A&quot;, &quot;B&quot;), (&quot;A&quot;, &quot;C&quot;)])</span>
<span class="sd">    &gt;&gt;&gt; bic_score = BIC(data)</span>
<span class="sd">    &gt;&gt;&gt; print(bic_score.score(model))</span>
<span class="sd">    -151.47</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the data contains continuous variables, or if the model variables are not present in the data.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Koller &amp; Friedman, Probabilistic Graphical Models - Principles and Techniques, 2009,</span>
<span class="sd">        Section 18.3.4â€“18.3.6 (esp. page 802).</span>
<span class="sd">    [2] AM Carvalho, Scoring functions for learning Bayesian networks,</span>
<span class="sd">        http://www.lx.it.pt/~asmc/pub/talks/09-TA/ta_pres.pdf</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BIC</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="BIC.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BIC.local_score">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local BIC/MDL score for a variable and its parent variables.</span>

<span class="sd">        This method quantifies the fit of a variable to its parent set in the network,</span>
<span class="sd">        balancing log-likelihood with a complexity penalty to discourage overfitting.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local BIC score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; variable = &quot;B&quot;</span>
<span class="sd">        &gt;&gt;&gt; parents = [&quot;A&quot;]</span>
<span class="sd">        &gt;&gt;&gt; score = bic_score.local_score(variable, parents)</span>
<span class="sd">        &gt;&gt;&gt; print(score)</span>
<span class="sd">        -19.315</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If `variable` or any parent is not present in `state_names` or data, or if</span>
<span class="sd">            the data contains unsupported types (e.g., continuous values).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">sample_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="n">ll</span><span class="p">,</span> <span class="n">num_parents_states</span><span class="p">,</span> <span class="n">var_cardinality</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span><span class="p">(</span>
            <span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span>
        <span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">ll</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="n">sample_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_parents_states</span> <span class="o">*</span> <span class="p">(</span><span class="n">var_cardinality</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">score</span></div>
</div>



<div class="viewcode-block" id="AIC">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.AIC">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">AIC</span><span class="p">(</span><span class="n">LogLikeliHood</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    AIC (Akaike Information Criterion) structure score for discrete Bayesian networks.</span>

<span class="sd">    The AIC score evaluates Bayesian network structures using a log-likelihood term</span>
<span class="sd">    with a penalty for model complexity to discourage overfitting. Unlike BIC,</span>
<span class="sd">    the penalty term is independent of sample size, making AIC more sensitive to</span>
<span class="sd">    goodness of fit in smaller datasets.</span>

<span class="sd">    Use this score when you want to select a network structure that balances model</span>
<span class="sd">    fit with simplicity, especially in contexts with moderate or small sample sizes.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where each column represents a discrete variable.</span>
<span class="sd">        Missing values should be set as `numpy.nan`.</span>
<span class="sd">        Note: pandas converts such columns to dtype float.</span>
<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping variable names to their discrete states.</span>
<span class="sd">        If not specified, unique values observed in the data are used as possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import AIC</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame({&quot;A&quot;: [0, 1, 1, 0], &quot;B&quot;: [1, 0, 1, 0], &quot;C&quot;: [1, 1, 1, 0]})</span>
<span class="sd">    &gt;&gt;&gt; model = DiscreteBayesianNetwork([(&quot;A&quot;, &quot;B&quot;), (&quot;A&quot;, &quot;C&quot;)])</span>
<span class="sd">    &gt;&gt;&gt; aic_score = AIC(data)</span>
<span class="sd">    &gt;&gt;&gt; print(aic_score.score(model))</span>
<span class="sd">    -140.12</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the data contains continuous variables, or if the model variables are not present in the data.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Koller &amp; Friedman, Probabilistic Graphical Models - Principles and Techniques, 2009,</span>
<span class="sd">        Section 18.3.4â€“18.3.6 (esp. page 802).</span>
<span class="sd">    [2] AM Carvalho, Scoring functions for learning Bayesian networks,</span>
<span class="sd">        http://www.lx.it.pt/~asmc/pub/talks/09-TA/ta_pres.pdf</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AIC</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="AIC.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.AIC.local_score">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local AIC score for a variable and its parent variables.</span>

<span class="sd">        This method quantifies the fit of a variable to its parent set in the network,</span>
<span class="sd">        balancing log-likelihood with a complexity penalty to avoid overfitting.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local AIC score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; variable = &quot;B&quot;</span>
<span class="sd">        &gt;&gt;&gt; parents = [&quot;A&quot;]</span>
<span class="sd">        &gt;&gt;&gt; score = aic_score.local_score(variable, parents)</span>
<span class="sd">        &gt;&gt;&gt; print(score)</span>
<span class="sd">        -17.032</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If `variable` or any parent is not present in `state_names` or data, or if</span>
<span class="sd">            the data contains unsupported types (e.g., continuous values).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">ll</span><span class="p">,</span> <span class="n">num_parents_states</span><span class="p">,</span> <span class="n">var_cardinality</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span><span class="p">(</span>
            <span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span>
        <span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">ll</span> <span class="o">-</span> <span class="n">num_parents_states</span> <span class="o">*</span> <span class="p">(</span><span class="n">var_cardinality</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">score</span></div>
</div>



<div class="viewcode-block" id="LogLikelihoodGauss">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.LogLikelihoodGauss">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LogLikelihoodGauss</span><span class="p">(</span><span class="n">StructureScore</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Log-likelihood structure score for Gaussian Bayesian networks.</span>

<span class="sd">    This score evaluates the fit of a continuous (Gaussian) Bayesian network structure</span>
<span class="sd">    by computing the (unpenalized) log-likelihood of the observed data given the model,</span>
<span class="sd">    using generalized linear modeling. It is suitable for networks with continuous variables.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where each column represents a continuous variable.</span>

<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping variable names to possible states. Not typically used for Gaussian networks.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import LogLikelihoodGauss</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">    ...     {</span>
<span class="sd">    ...         &quot;A&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;B&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;C&quot;: np.random.randn(100),</span>
<span class="sd">    ...     }</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; score = LogLikelihoodGauss(data)</span>
<span class="sd">    &gt;&gt;&gt; ll = score.local_score(&quot;B&quot;, [&quot;A&quot;, &quot;C&quot;])</span>
<span class="sd">    &gt;&gt;&gt; print(ll)</span>
<span class="sd">    -142.125</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the data contains discrete or non-numeric variables.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LogLikelihoodGauss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the log-likelihood and degrees of freedom for a Gaussian model.</span>

<span class="sd">        This internal method fits a generalized linear model (GLM) for the specified variable</span>
<span class="sd">        as a function of its parent variables, using the statsmodels library, and returns the</span>
<span class="sd">        log-likelihood and degrees of freedom of the fitted model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) to be predicted.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names to be used as predictors (parents). If empty, fits an intercept-only model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        llf : float</span>
<span class="sd">            The log-likelihood of the fitted model.</span>
<span class="sd">        df_model : int</span>
<span class="sd">            The degrees of freedom of the fitted model (number of model parameters estimated).</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; llf, df = score._log_likelihood(&quot;B&quot;, [&quot;A&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; print(llf, df)</span>
<span class="sd">        -142.125 2</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the GLM cannot be fitted due to missing or non-numeric data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">glm_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">glm</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">variable</span><span class="si">}</span><span class="s2"> ~ 1&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">glm_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">glm</span><span class="p">(</span>
                <span class="n">formula</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">variable</span><span class="si">}</span><span class="s2"> ~ </span><span class="si">{</span><span class="s1">&#39; + &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span>
            <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">glm_model</span><span class="o">.</span><span class="n">llf</span><span class="p">,</span> <span class="n">glm_model</span><span class="o">.</span><span class="n">df_model</span><span class="p">)</span>

<div class="viewcode-block" id="LogLikelihoodGauss.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.LogLikelihoodGauss.local_score">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the log-likelihood score for a variable given its parent variables.</span>

<span class="sd">        Fits a generalized linear model (GLM) for the variable as a function of its parents,</span>
<span class="sd">        and returns the resulting log-likelihood as the structure score.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The log-likelihood score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; ll = score.local_score(&quot;B&quot;, [&quot;A&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; print(ll)</span>
<span class="sd">        -142.125</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the GLM cannot be fitted due to non-numeric data or missing columns.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ll</span><span class="p">,</span> <span class="n">df_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ll</span></div>
</div>



<div class="viewcode-block" id="BICGauss">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BICGauss">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BICGauss</span><span class="p">(</span><span class="n">LogLikelihoodGauss</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BIC (Bayesian Information Criterion) structure score for Gaussian Bayesian networks.</span>

<span class="sd">    The BICGauss score evaluates continuous Bayesian network structures by penalizing</span>
<span class="sd">    the log-likelihood with a term proportional to the number of model parameters,</span>
<span class="sd">    discouraging overfitting. This is the Gaussian version of the BIC/MDL score,</span>
<span class="sd">    suitable for networks where all variables are continuous.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where each column represents a continuous variable.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import BICGauss</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">    ...     {</span>
<span class="sd">    ...         &quot;A&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;B&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;C&quot;: np.random.randn(100),</span>
<span class="sd">    ...     }</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; score = BICGauss(data)</span>
<span class="sd">    &gt;&gt;&gt; s = score.local_score(&quot;B&quot;, [&quot;A&quot;, &quot;C&quot;])</span>
<span class="sd">    &gt;&gt;&gt; print(s)</span>
<span class="sd">    -111.42</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the GLM cannot be fitted due to missing or non-numeric data.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BICGauss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="BICGauss.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BICGauss.local_score">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local BIC/MDL score for a variable and its parent variables</span>
<span class="sd">        in a Gaussian Bayesian network.</span>

<span class="sd">        The score is the log-likelihood minus a penalty term that increases</span>
<span class="sd">        with the number of model parameters and sample size.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local BICGauss score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; s = score.local_score(&quot;B&quot;, [&quot;A&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; print(s)</span>
<span class="sd">        -111.42</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the GLM cannot be fitted due to missing or non-numeric data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ll</span><span class="p">,</span> <span class="n">df_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>

        <span class="c1"># Adding +2 to model df to compute the likelihood df.</span>
        <span class="k">return</span> <span class="n">ll</span> <span class="o">-</span> <span class="p">(((</span><span class="n">df_model</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span></div>
</div>



<div class="viewcode-block" id="AICGauss">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.AICGauss">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">AICGauss</span><span class="p">(</span><span class="n">LogLikelihoodGauss</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    AIC (Akaike Information Criterion) structure score for Gaussian Bayesian networks.</span>

<span class="sd">    The AICGauss score evaluates continuous Bayesian network structures by penalizing</span>
<span class="sd">    the log-likelihood with a term proportional to the number of model parameters.</span>
<span class="sd">    The penalty is less severe than BIC and does not depend on sample size, making AIC</span>
<span class="sd">    preferable for model selection with smaller datasets.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where each column represents a continuous variable.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import AICGauss</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">    ...     {</span>
<span class="sd">    ...         &quot;A&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;B&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;C&quot;: np.random.randn(100),</span>
<span class="sd">    ...     }</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; score = AICGauss(data)</span>
<span class="sd">    &gt;&gt;&gt; s = score.local_score(&quot;B&quot;, [&quot;A&quot;, &quot;C&quot;])</span>
<span class="sd">    &gt;&gt;&gt; print(s)</span>
<span class="sd">    -97.53</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the GLM cannot be fitted due to missing or non-numeric data.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AICGauss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="AICGauss.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.AICGauss.local_score">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local AIC score for a variable and its parent variables</span>
<span class="sd">        in a Gaussian Bayesian network.</span>

<span class="sd">        The score is the log-likelihood minus a penalty term that increases with</span>
<span class="sd">        the number of model parameters (but not sample size).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local AICGauss score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; s = score.local_score(&quot;B&quot;, [&quot;A&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; print(s)</span>
<span class="sd">        -97.53</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the GLM cannot be fitted due to missing or non-numeric data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ll</span><span class="p">,</span> <span class="n">df_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>

        <span class="c1"># Adding +2 to model df to compute the likelihood df.</span>
        <span class="k">return</span> <span class="n">ll</span> <span class="o">-</span> <span class="p">(</span><span class="n">df_model</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="LogLikelihoodCondGauss">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.LogLikelihoodCondGauss">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LogLikelihoodCondGauss</span><span class="p">(</span><span class="n">StructureScore</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Log-likelihood score for Bayesian networks with mixed discrete and continuous variables.</span>

<span class="sd">    This score is based on conditional Gaussian distributions and supports networks</span>
<span class="sd">    with both discrete and continuous variables, using the methodology described in [1].</span>
<span class="sd">    The local score computes the log-likelihood of the observed data given the</span>
<span class="sd">    network structure, handling mixed parent sets as described in the reference.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where columns can be discrete or continuous variables.</span>
<span class="sd">        Variable types should be consistent with the structure.</span>

<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping discrete variable names to their possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import LogLikelihoodCondGauss</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">    ...     {</span>
<span class="sd">    ...         &quot;A&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;B&quot;: np.random.randint(0, 2, 100),</span>
<span class="sd">    ...         &quot;C&quot;: np.random.randn(100),</span>
<span class="sd">    ...     }</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; score = LogLikelihoodCondGauss(data)</span>
<span class="sd">    &gt;&gt;&gt; ll = score.local_score(&quot;A&quot;, [&quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">    &gt;&gt;&gt; print(ll)</span>
<span class="sd">    -98.452</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the data or variable types are not suitable for conditional Gaussian modeling.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Andrews, B., Ramsey, J., &amp; Cooper, G. F. (2018). Scoring Bayesian</span>
<span class="sd">        Networks of Mixed Variables. International journal of data science and</span>
<span class="sd">        analytics, 6(1), 3â€“18. https://doi.org/10.1007/s41060-017-0085-7</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LogLikelihoodCondGauss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_adjusted_cov</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes an adjusted covariance matrix from the given DataFrame.</span>

<span class="sd">        This method returns the sample covariance matrix for the columns in `df`, making sure</span>
<span class="sd">        the result is always positive semi-definite. If there are not enough rows to estimate</span>
<span class="sd">        covariance (i.e., fewer rows than variables), the identity matrix is returned. If the</span>
<span class="sd">        covariance matrix is not positive semi-definite, a small value is added to the diagonal.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        df : pandas.DataFrame</span>
<span class="sd">            DataFrame whose columns are the variables for which the covariance matrix is computed.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        cov_matrix : pandas.DataFrame</span>
<span class="sd">            The adjusted covariance matrix. If not enough data, returns the identity matrix.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; df = pd.DataFrame(np.random.randn(5, 3), columns=[&quot;A&quot;, &quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; cov = LogLikelihoodCondGauss._adjusted_cov(df)</span>
<span class="sd">        &gt;&gt;&gt; print(cov)</span>
<span class="sd">                A         B         C</span>
<span class="sd">        A  0.802359  0.100722 -0.006956</span>
<span class="sd">        B  0.100722  0.818795  0.154614</span>
<span class="sd">        C -0.006956  0.154614  0.540758</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># If a number of rows less than number of variables, return variance 1 with no covariance.</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)):</span>
            <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span>
            <span class="p">)</span>

        <span class="c1"># If the matrix is not positive semidefinite, add a small error to make it.</span>
        <span class="n">df_cov</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">cov</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">df_cov</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">df_cov</span> <span class="o">=</span> <span class="n">df_cov</span> <span class="o">+</span> <span class="mf">1e-6</span>
        <span class="k">return</span> <span class="n">df_cov</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_cat_parents_product</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the product of the number of unique states for each categorical parent.</span>

<span class="sd">        For each parent in `parents` that is discrete (not continuous), this method multiplies</span>
<span class="sd">        the number of observed unique states. Parents with only one unique value are ignored</span>
<span class="sd">        (i.e., do not contribute to the product).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of parent variable names to consider.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        k : int</span>
<span class="sd">            The product of unique state counts for each discrete parent in `parents`.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; score._cat_parents_product([&quot;A&quot;, &quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">        6</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">pa</span> <span class="ow">in</span> <span class="n">parents</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">pa</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;N&quot;</span><span class="p">:</span>
                <span class="n">n_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">pa</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">n_states</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">k</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">pa</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">k</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_num_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the number of free parameters required for the conditional distribution</span>
<span class="sd">        of a variable given its parents in a mixed (discrete and continuous) Bayesian network.</span>

<span class="sd">        For a continuous variable, the number of parameters depends on the number of continuous</span>
<span class="sd">        parents and the number of configurations of discrete parents. For a discrete variable,</span>
<span class="sd">        it depends on the number of categories and parent configurations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the target variable (child node).</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of parent variable names.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        k : int</span>
<span class="sd">            The number of free parameters for the conditional distribution of `variable`</span>
<span class="sd">            given its parents.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; score._get_num_parameters(&quot;A&quot;, [&quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">        12</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">parent_dtypes</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">pa</span><span class="p">]</span> <span class="k">for</span> <span class="n">pa</span> <span class="ow">in</span> <span class="n">parents</span><span class="p">]</span>
        <span class="n">n_cont_parents</span> <span class="o">=</span> <span class="n">parent_dtypes</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;N&quot;</span><span class="p">:</span>
            <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cat_parents_product</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">n_cont_parents</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">n_cont_parents</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cat_parents_product</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">k</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_cat_parents_product</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>
                    <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="o">*</span> <span class="p">(</span><span class="n">n_cont_parents</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
                <span class="p">)</span>

        <span class="k">return</span> <span class="n">k</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the conditional log-likelihood for a variable given its parent set,</span>
<span class="sd">        supporting both continuous and discrete variables (mixed Bayesian networks).</span>

<span class="sd">        For a continuous variable, computes the log-likelihood using conditional Gaussian</span>
<span class="sd">        distributions as described in [1]. For a discrete variable, computes the</span>
<span class="sd">        log-likelihood based on the joint and marginal probabilities involving both</span>
<span class="sd">        discrete and continuous parents.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The variable (node) for which the log-likelihood is computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of parent variable names.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        log_like : float</span>
<span class="sd">            The log-likelihood value for the specified variable and parent set.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; ll = score._log_likelihood(&quot;A&quot;, [&quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; print(ll)</span>
<span class="sd">        -99.242</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If data is not suitable for log-likelihood computation (e.g., unsupported variable types).</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Andrews, B., Ramsey, J., &amp; Cooper, G. F. (2018). Scoring Bayesian</span>
<span class="sd">            Networks of Mixed Variables. International journal of data science and</span>
<span class="sd">            analytics, 6(1), 3â€“18. https://doi.org/10.1007/s41060-017-0085-7</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="n">variable</span><span class="p">]</span> <span class="o">+</span> <span class="n">parents</span><span class="p">]</span>

        <span class="c1"># If variable is continuous, the probability is computed as:</span>
        <span class="c1"># P(C1 | C2, D) = p(C1, C2 | D) / p(C2 | D)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;N&quot;</span><span class="p">:</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">variable</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">parents</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;N&quot;</span><span class="p">]</span>
            <span class="n">d</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">c2</span><span class="p">))</span>

            <span class="c1"># If D = {}, p(C1, C2 | D) = p(C1, C2) and p(C2 | D) = p(C2)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># If C2 = {}, p(C1, C2 | D) = p(C1) and p(C2 | D) = 1.</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">c2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">p_c1c2_d</span> <span class="o">=</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
                        <span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
                        <span class="n">mean</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                        <span class="n">cov</span><span class="o">=</span><span class="n">LogLikelihoodCondGauss</span><span class="o">.</span><span class="n">_adjusted_cov</span><span class="p">(</span><span class="n">df</span><span class="p">),</span>
                        <span class="n">allow_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_c1c2_d</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">p_c1c2_d</span> <span class="o">=</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
                        <span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
                        <span class="n">mean</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                        <span class="n">cov</span><span class="o">=</span><span class="n">LogLikelihoodCondGauss</span><span class="o">.</span><span class="n">_adjusted_cov</span><span class="p">(</span><span class="n">df</span><span class="p">),</span>
                        <span class="n">allow_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">df_c2</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c2</span><span class="p">]</span>
                    <span class="n">p_c2_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span>
                        <span class="mf">1e-8</span><span class="p">,</span>
                        <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
                            <span class="n">x</span><span class="o">=</span><span class="n">df_c2</span><span class="p">,</span>
                            <span class="n">mean</span><span class="o">=</span><span class="n">df_c2</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                            <span class="n">cov</span><span class="o">=</span><span class="n">LogLikelihoodCondGauss</span><span class="o">.</span><span class="n">_adjusted_cov</span><span class="p">(</span><span class="n">df_c2</span><span class="p">),</span>
                            <span class="n">allow_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="p">),</span>
                    <span class="p">)</span>

                    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_c1c2_d</span> <span class="o">/</span> <span class="n">p_c2_d</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">log_like</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">for</span> <span class="n">d_states</span><span class="p">,</span> <span class="n">df_d</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                    <span class="n">p_c1c2_d</span> <span class="o">=</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
                        <span class="n">x</span><span class="o">=</span><span class="n">df_d</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="n">c1</span><span class="p">]</span> <span class="o">+</span> <span class="n">c2</span><span class="p">],</span>
                        <span class="n">mean</span><span class="o">=</span><span class="n">df_d</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="n">c1</span><span class="p">]</span> <span class="o">+</span> <span class="n">c2</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                        <span class="n">cov</span><span class="o">=</span><span class="n">LogLikelihoodCondGauss</span><span class="o">.</span><span class="n">_adjusted_cov</span><span class="p">(</span>
                            <span class="n">df_d</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="n">c1</span><span class="p">]</span> <span class="o">+</span> <span class="n">c2</span><span class="p">]</span>
                        <span class="p">),</span>
                        <span class="n">allow_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">c2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">p_c2_d</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">p_c2_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span>
                            <span class="mf">1e-8</span><span class="p">,</span>
                            <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
                                <span class="n">x</span><span class="o">=</span><span class="n">df_d</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c2</span><span class="p">],</span>
                                <span class="n">mean</span><span class="o">=</span><span class="n">df_d</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c2</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                                <span class="n">cov</span><span class="o">=</span><span class="n">LogLikelihoodCondGauss</span><span class="o">.</span><span class="n">_adjusted_cov</span><span class="p">(</span>
                                    <span class="n">df_d</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c2</span><span class="p">]</span>
                                <span class="p">),</span>
                                <span class="n">allow_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="p">),</span>
                        <span class="p">)</span>

                    <span class="n">log_like</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_c1c2_d</span> <span class="o">/</span> <span class="n">p_c2_d</span><span class="p">))</span>
                <span class="k">return</span> <span class="n">log_like</span>

        <span class="c1"># If variable is discrete, the probability is computed as:</span>
        <span class="c1"># P(D1 | C, D2) = (p(C| D1, D2) p(D1, D2)) / (p(C| D2) p(D2))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">d1</span> <span class="o">=</span> <span class="n">variable</span>
            <span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">parents</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;N&quot;</span><span class="p">]</span>
            <span class="n">d2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>

            <span class="n">log_like</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">d_states</span><span class="p">,</span> <span class="n">df_d1d2</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="n">d1</span><span class="p">]</span> <span class="o">+</span> <span class="n">d2</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                <span class="c1"># Check if df_d1d2 also has the discrete variables.</span>
                <span class="c1"># If C={}, p(C | D1, D2) = 1.</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">p_c_d1d2</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">p_c_d1d2</span> <span class="o">=</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
                        <span class="n">x</span><span class="o">=</span><span class="n">df_d1d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">],</span>
                        <span class="n">mean</span><span class="o">=</span><span class="n">df_d1d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                        <span class="n">cov</span><span class="o">=</span><span class="n">LogLikelihoodCondGauss</span><span class="o">.</span><span class="n">_adjusted_cov</span><span class="p">(</span><span class="n">df_d1d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">]),</span>
                        <span class="n">allow_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>

                <span class="c1"># P(D1, D2)</span>
                <span class="n">p_d1d2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">df_d1d2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">df_d1d2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

                <span class="c1"># If D2 = {}, p(D1 | C, D2) = (p(C | D1, D2) p(D1, D2)) / p(C)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">d2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">p_c_d2</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">p_c_d2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span>
                            <span class="mf">1e-8</span><span class="p">,</span>
                            <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
                                <span class="n">x</span><span class="o">=</span><span class="n">df_d1d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">],</span>
                                <span class="n">mean</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                                <span class="n">cov</span><span class="o">=</span><span class="n">LogLikelihoodCondGauss</span><span class="o">.</span><span class="n">_adjusted_cov</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">]),</span>
                                <span class="n">allow_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="p">),</span>
                        <span class="p">)</span>

                    <span class="n">log_like</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_c_d1d2</span> <span class="o">*</span> <span class="n">p_d1d2</span> <span class="o">/</span> <span class="n">p_c_d2</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">p_c_d2</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">df_d2</span> <span class="o">=</span> <span class="n">df</span>
                        <span class="k">for</span> <span class="n">var</span><span class="p">,</span> <span class="n">state</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">d2</span><span class="p">,</span> <span class="n">d_states</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
                            <span class="n">df_d2</span> <span class="o">=</span> <span class="n">df_d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_d2</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">==</span> <span class="n">state</span><span class="p">]</span>

                        <span class="n">p_c_d2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span>
                            <span class="mf">1e-8</span><span class="p">,</span>
                            <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
                                <span class="n">x</span><span class="o">=</span><span class="n">df_d1d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">],</span>
                                <span class="n">mean</span><span class="o">=</span><span class="n">df_d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                                <span class="n">cov</span><span class="o">=</span><span class="n">LogLikelihoodCondGauss</span><span class="o">.</span><span class="n">_adjusted_cov</span><span class="p">(</span>
                                    <span class="n">df_d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">]</span>
                                <span class="p">),</span>
                                <span class="n">allow_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="p">),</span>
                        <span class="p">)</span>

                    <span class="n">p_d2</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">d2</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> <span class="o">/</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">var</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">d2</span><span class="p">,</span> <span class="n">d_states</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
                        <span class="n">p_d2</span> <span class="o">=</span> <span class="n">p_d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">p_d2</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">get_level_values</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="o">==</span> <span class="n">value</span><span class="p">]</span>

                    <span class="n">log_like</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="n">p_c_d1d2</span> <span class="o">*</span> <span class="n">p_d1d2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">p_c_d2</span> <span class="o">*</span> <span class="n">p_d2</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">()[</span><span class="mi">0</span><span class="p">]))</span>
                    <span class="p">)</span>
            <span class="k">return</span> <span class="n">log_like</span>

<div class="viewcode-block" id="LogLikelihoodCondGauss.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.LogLikelihoodCondGauss.local_score">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local log-likelihood score for a variable given its parent variables</span>
<span class="sd">        in a mixed (discrete and continuous) Bayesian network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local conditional Gaussian log-likelihood score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; ll = score.local_score(&quot;A&quot;, [&quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; print(ll)</span>
<span class="sd">        -98.452</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the log-likelihood cannot be computed due to incompatible data or variable types.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ll</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ll</span></div>
</div>



<div class="viewcode-block" id="BICCondGauss">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BICCondGauss">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BICCondGauss</span><span class="p">(</span><span class="n">LogLikelihoodCondGauss</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BIC (Bayesian Information Criterion) score for Bayesian networks with mixed (discrete and continuous) variables.</span>

<span class="sd">    The BICCondGauss score evaluates network structures by penalizing the conditional log-likelihood</span>
<span class="sd">    with a term proportional to the number of free parameters and the logarithm of sample size.</span>
<span class="sd">    This approach generalizes the classic BIC to handle mixed discrete/continuous data as</span>
<span class="sd">    described in [1].</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where columns may be discrete or continuous variables.</span>

<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping discrete variable names to possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import BICCondGauss</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">    ...     {</span>
<span class="sd">    ...         &quot;A&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;B&quot;: np.random.randint(0, 2, 100),</span>
<span class="sd">    ...         &quot;C&quot;: np.random.randn(100),</span>
<span class="sd">    ...     }</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; score = BICCondGauss(data)</span>
<span class="sd">    &gt;&gt;&gt; s = score.local_score(&quot;A&quot;, [&quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">    &gt;&gt;&gt; print(s)</span>
<span class="sd">    -115.37</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the log-likelihood or number of parameters cannot be computed for the provided variables.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Andrews, B., Ramsey, J., &amp; Cooper, G. F. (2018). Scoring Bayesian</span>
<span class="sd">        Networks of Mixed Variables. International journal of data science and</span>
<span class="sd">        analytics, 6(1), 3â€“18. https://doi.org/10.1007/s41060-017-0085-7</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BICCondGauss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="BICCondGauss.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BICCondGauss.local_score">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local BIC score for a variable and its parent set in a mixed Bayesian network.</span>

<span class="sd">        The score is calculated as the log-likelihood minus a complexity penalty, which</span>
<span class="sd">        is proportional to the number of free parameters and the log of the sample size.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local BICCondGauss score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; s = score.local_score(&quot;A&quot;, [&quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; print(s)</span>
<span class="sd">        -115.37</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the log-likelihood or parameter count cannot be computed for the given configuration.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">ll</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_num_parameters</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ll</span> <span class="o">-</span> <span class="p">((</span><span class="n">k</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span></div>
</div>



<div class="viewcode-block" id="AICCondGauss">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.AICCondGauss">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">AICCondGauss</span><span class="p">(</span><span class="n">LogLikelihoodCondGauss</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    AIC (Akaike Information Criterion) score for Bayesian networks with mixed (discrete and continuous) variables.</span>

<span class="sd">    The AICCondGauss score evaluates network structures by penalizing the conditional log-likelihood</span>
<span class="sd">    with a term equal to the number of free parameters. This generalizes the classic AIC</span>
<span class="sd">    to handle Bayesian networks with both discrete and continuous variables [1].</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where columns may be discrete or continuous variables.</span>

<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping discrete variable names to possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import AICCondGauss</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">    ...     {</span>
<span class="sd">    ...         &quot;A&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;B&quot;: np.random.randint(0, 2, 100),</span>
<span class="sd">    ...         &quot;C&quot;: np.random.randn(100),</span>
<span class="sd">    ...     }</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; score = AICCondGauss(data)</span>
<span class="sd">    &gt;&gt;&gt; s = score.local_score(&quot;A&quot;, [&quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">    &gt;&gt;&gt; print(s)</span>
<span class="sd">    -99.75</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the log-likelihood or number of parameters cannot be computed for the provided variables.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Andrews, B., Ramsey, J., &amp; Cooper, G. F. (2018). Scoring Bayesian</span>
<span class="sd">        Networks of Mixed Variables. International journal of data science and</span>
<span class="sd">        analytics, 6(1), 3â€“18. https://doi.org/10.1007/s41060-017-0085-7</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AICCondGauss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="AICCondGauss.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.AICCondGauss.local_score">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local AIC score for a variable and its parent set in a mixed Bayesian network.</span>

<span class="sd">        The score is calculated as the log-likelihood minus the number of free parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local AICCondGauss score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; s = score.local_score(&quot;A&quot;, [&quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; print(s)</span>
<span class="sd">        -99.75</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the log-likelihood or parameter count cannot be computed for the given configuration.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ll</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_num_parameters</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ll</span> <span class="o">-</span> <span class="n">k</span></div>
</div>

</code></pre></div>







  
  






                
  <div data-ea-publisher="pgmpyorg" data-ea-type="image" data-ea-style="stickybox"></div>
  <script>
    (function() {
      var nav = document.querySelector('.md-header__inner');
      if (!nav) return;

      var socialDiv = document.createElement('div');
      socialDiv.className = 'md-header__social';

      socialDiv.innerHTML =
        '<a href="https://github.com/pgmpy/pgmpy" target="_blank" rel="noopener" title="GitHub">' +
          '<svg viewBox="0 0 496 512" xmlns="http://www.w3.org/2000/svg">' +
            '<path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.8-14.9-112.8-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/>' +
          '</svg>' +
        '</a>' +
        '<a href="https://discord.gg/DRkdKaumBs" target="_blank" rel="noopener" title="Discord">' +
          '<svg viewBox="0 0 640 512" xmlns="http://www.w3.org/2000/svg">' +
            '<path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485.065 485.065 0 0 0 404.081 32.03a1.816 1.816 0 0 0-1.923.91 337.461 337.461 0 0 0-14.9 30.6 447.848 447.848 0 0 0-134.426 0 309.541 309.541 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91A483.689 483.689 0 0 0 116.085 69.137a1.712 1.712 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.016 2.016 0 0 0 .765 1.375A487.666 487.666 0 0 0 176.02 479.918a1.9 1.9 0 0 0 2.063-.676A348.2 348.2 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321.173 321.173 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126c3.082-2.309 6.166-4.711 9.109-7.137a1.819 1.819 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.812 1.812 0 0 1 1.924.233c2.944 2.426 6.027 4.851 9.132 7.16a1.884 1.884 0 0 1-.162 3.126 301.407 301.407 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391.055 391.055 0 0 0 30.014 48.815 1.864 1.864 0 0 0 2.063.7A486.048 486.048 0 0 0 610.7 405.729a1.882 1.882 0 0 0 .765-1.352C623.729 277.594 590.933 167.465 524.531 69.836zM222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239S193.056 219.1 222.491 219.1c29.665 0 53.306 26.82 52.843 59.239C275.334 310.993 251.924 337.58 222.491 337.58zm195.38 0c-28.971 0-52.843-26.587-52.843-59.239S388.437 219.1 417.871 219.1c29.667 0 53.307 26.82 52.844 59.239C470.715 310.993 447.538 337.58 417.871 337.58z"/>' +
          '</svg>' +
        '</a>' +
        '<a href="https://www.linkedin.com/company/pgmpy/" target="_blank" rel="noopener" title="LinkedIn">' +
          '<svg viewBox="0 0 448 512" xmlns="http://www.w3.org/2000/svg">' +
            '<path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/>' +
          '</svg>' +
        '</a>';

      nav.appendChild(socialDiv);
    })();
  </script>

              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  
  
  <div class="md-footer-meta md-typeset">
    
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-footer-copyright__highlight">
        &#169; Copyright 2025, Ankur Ankan.
        
    </div>
  
    Created using
    <a href="https://www.sphinx-doc.org/" target="_blank" rel="noopener">Sphinx</a>
    9.1.0.
     and
    <a href="https://github.com/jbms/sphinx-immaterial/" target="_blank" rel="noopener">Sphinx-Immaterial</a>
  
</div>
      
    </div>
    
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.top", "search.highlight", "search.share", "toc.follow", "content.tabs.link"], "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike", "staticVersions": [{"aliases": [], "title": "1.0.0 (stable)", "version": "https://pgmpy.org"}, {"aliases": [], "title": "dev", "version": "https://pgmpy.org/dev"}], "versionPath": null}}</script>
    
      
        <script src="../../../_static/sphinx_immaterial_theme.32136f45f91ae6956.min.js?v=a7a9472a"></script>
        <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../../_static/copybutton.js?v=f281be69"></script>
        <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
  </body>
</html>